{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "def plot_corr(df,size=10):\n",
    "    '''Function plots a graphical correlation matrix for each pair of columns in the dataframe.\n",
    "\n",
    "    Input:\n",
    "        df: pandas DataFrame\n",
    "        size: vertical and horizontal size of the plot'''\n",
    "\n",
    "    corr = df.corr()\n",
    "    print(corr)\n",
    "    fig, ax = plt.subplots(figsize=(size, size))\n",
    "    ax.matshow(corr)\n",
    "    plt.xticks(range(len(corr.columns)), corr.columns, rotation=90)\n",
    "    plt.yticks(range(len(corr.columns)), corr.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 읽기\n",
    "data = pd.read_csv('[regression]Bike-sharing/day.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.344167</td>\n",
       "      <td>0.363625</td>\n",
       "      <td>0.805833</td>\n",
       "      <td>0.160446</td>\n",
       "      <td>331</td>\n",
       "      <td>654</td>\n",
       "      <td>985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2011-01-02</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.363478</td>\n",
       "      <td>0.353739</td>\n",
       "      <td>0.696087</td>\n",
       "      <td>0.248539</td>\n",
       "      <td>131</td>\n",
       "      <td>670</td>\n",
       "      <td>801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2011-01-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.196364</td>\n",
       "      <td>0.189405</td>\n",
       "      <td>0.437273</td>\n",
       "      <td>0.248309</td>\n",
       "      <td>120</td>\n",
       "      <td>1229</td>\n",
       "      <td>1349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2011-01-04</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.212122</td>\n",
       "      <td>0.590435</td>\n",
       "      <td>0.160296</td>\n",
       "      <td>108</td>\n",
       "      <td>1454</td>\n",
       "      <td>1562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2011-01-05</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.226957</td>\n",
       "      <td>0.229270</td>\n",
       "      <td>0.436957</td>\n",
       "      <td>0.186900</td>\n",
       "      <td>82</td>\n",
       "      <td>1518</td>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.344167</td>\n",
       "      <td>0.363625</td>\n",
       "      <td>0.805833</td>\n",
       "      <td>0.160446</td>\n",
       "      <td>331</td>\n",
       "      <td>654</td>\n",
       "      <td>985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2011-01-02</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.363478</td>\n",
       "      <td>0.353739</td>\n",
       "      <td>0.696087</td>\n",
       "      <td>0.248539</td>\n",
       "      <td>131</td>\n",
       "      <td>670</td>\n",
       "      <td>801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2011-01-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.196364</td>\n",
       "      <td>0.189405</td>\n",
       "      <td>0.437273</td>\n",
       "      <td>0.248309</td>\n",
       "      <td>120</td>\n",
       "      <td>1229</td>\n",
       "      <td>1349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2011-01-04</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.212122</td>\n",
       "      <td>0.590435</td>\n",
       "      <td>0.160296</td>\n",
       "      <td>108</td>\n",
       "      <td>1454</td>\n",
       "      <td>1562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2011-01-05</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.226957</td>\n",
       "      <td>0.229270</td>\n",
       "      <td>0.436957</td>\n",
       "      <td>0.186900</td>\n",
       "      <td>82</td>\n",
       "      <td>1518</td>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터셋 앞부분 출력해보기\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y값 세팅\n",
    "y = data['cnt'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# y값 분포 그려보기\n",
    "# Distribution of target (Y)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "sns.distplot(data['cnt'], bins=30, ax=ax)\n",
    "ax.set_title('Distribution of Y (cnt)')\n",
    "plt.grid(True)\n",
    "plt.show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x720 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 변수들의 상관관계 알아보기\n",
    "corr_matrix = data.corr()\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 10))\n",
    "sns.heatmap(data=corr_matrix, cmap=plt.cm.RdBu, annot=True, fmt='.1f', ax=ax)\n",
    "ax.set_title('Correlation matrix')\n",
    "plt.show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['instant', 'yr', 'holiday', 'workingday', 'temp', 'atemp', 'hum',\n       'windspeed', 'cnt'],\n      dtype='object')"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 카테고리형 컬럼 분류하기 season, mnth, weekday, weathersit\n",
    "# casual과 registered는 빼야 하지 않을까?\n",
    "# dteday는 빼버리자\n",
    "# casual과 registered는 빼보자\n",
    "data_numeric = data.drop(columns=['season','mnth','weekday', 'weathersit', 'dteday', 'casual', 'registered'], axis=1)\n",
    "data_numeric.head()\n",
    "data_numeric.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['season_2', 'season_3', 'season_4', 'mnth_2', 'mnth_3', 'mnth_4',\n       'mnth_5', 'mnth_6', 'mnth_7', 'mnth_8', 'mnth_9', 'mnth_10', 'mnth_11',\n       'mnth_12', 'weekday_1', 'weekday_2', 'weekday_3', 'weekday_4',\n       'weekday_5', 'weekday_6', 'weathersit_2', 'weathersit_3'],\n      dtype='object')"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 더미변수 만들기\n",
    "data_category = data.loc[:, ['season', 'mnth', 'weekday', 'weathersit']]\n",
    "data_dummy = pd.get_dummies(data_category, columns=['season', 'mnth', 'weekday', 'weathersit'], drop_first=True) # 더미에서 하나는 빼야된다\n",
    "data_dummy.head()\n",
    "data_dummy.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['instant', 'yr', 'holiday', 'workingday', 'temp', 'atemp', 'hum',\n       'windspeed', 'cnt', 'season_2', 'season_3', 'season_4', 'mnth_2',\n       'mnth_3', 'mnth_4', 'mnth_5', 'mnth_6', 'mnth_7', 'mnth_8', 'mnth_9',\n       'mnth_10', 'mnth_11', 'mnth_12', 'weekday_1', 'weekday_2', 'weekday_3',\n       'weekday_4', 'weekday_5', 'weekday_6', 'weathersit_2', 'weathersit_3'],\n      dtype='object')"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 두개 합치기\n",
    "data_numeric = pd.concat([data_numeric, data_dummy], axis=1)\n",
    "data_numeric.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([731, 30]) torch.float32\ntorch.Size([731, 1]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "# pandas dataframe -> numpy array\n",
    "X = data_numeric.drop('cnt', axis=1).values\n",
    "y = data_numeric['cnt'].values\n",
    "\n",
    "# Change dtype\n",
    "X = X.astype(np.float32)\n",
    "y = y.astype(np.float32).reshape(-1, 1)\n",
    "\n",
    "# numpy array -> torch float tensor\n",
    "X = torch.from_numpy(X)\n",
    "y = torch.from_numpy(y)\n",
    "\n",
    "print(X.size(), X.dtype)\n",
    "print(y.size(), y.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train & test sets\n",
    "split_idx = 500\n",
    "X_train, y_train = X[:split_idx], y[:split_idx]\n",
    "X_test, y_test = X[split_idx:], y[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "class LinearRegressionModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_features):\n",
    "     \n",
    "        super(LinearRegressionModel, self).__init__()\n",
    "        self.linear = nn.Linear(in_features, 1, bias=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        y_pred = self.linear(x)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model\n",
    "model = LinearRegressionModel(in_features=X.shape[1])\n",
    "\n",
    "# Construct loss criterion & optimizer\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 00200 | Training Loss: 3939320.000 | Test loss: 4298105.000\nIteration: 00400 | Training Loss: 3847427.250 | Test loss: 4223806.500\nIteration: 00600 | Training Loss: 3760657.250 | Test loss: 4169430.750\nIteration: 00800 | Training Loss: 3678938.000 | Test loss: 4134438.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 01000 | Training Loss: 3602188.500 | Test loss: 4118245.750\nIteration: 01200 | Training Loss: 3530325.000 | Test loss: 4120223.750\nIteration: 01400 | Training Loss: 3463257.250 | Test loss: 4139691.500\nIteration: 01600 | Training Loss: 3400889.750 | Test loss: 4175909.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 01800 | Training Loss: 3343115.750 | Test loss: 4228081.500\nIteration: 02000 | Training Loss: 3289823.750 | Test loss: 4295340.000\nIteration: 02200 | Training Loss: 3240893.250 | Test loss: 4376744.000\nIteration: 02400 | Training Loss: 3196193.250 | Test loss: 4471274.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 02600 | Training Loss: 3155580.750 | Test loss: 4577827.000\nIteration: 02800 | Training Loss: 3118904.750 | Test loss: 4695201.500\nIteration: 03000 | Training Loss: 3086001.500 | Test loss: 4822104.500\nIteration: 03200 | Training Loss: 3056695.750 | Test loss: 4957141.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 03400 | Training Loss: 3030798.750 | Test loss: 5098834.000\nIteration: 03600 | Training Loss: 3008114.500 | Test loss: 5245586.000\nIteration: 03800 | Training Loss: 2988432.250 | Test loss: 5395726.500\nIteration: 04000 | Training Loss: 2971532.000 | Test loss: 5547475.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 04200 | Training Loss: 2957180.500 | Test loss: 5698962.000\nIteration: 04400 | Training Loss: 2945136.250 | Test loss: 5848240.000\nIteration: 04600 | Training Loss: 2935146.750 | Test loss: 5993327.000\nIteration: 04800 | Training Loss: 2926956.250 | Test loss: 6132240.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 05000 | Training Loss: 2920305.750 | Test loss: 6263060.000\nIteration: 05200 | Training Loss: 2914941.000 | Test loss: 6384025.000\nIteration: 05400 | Training Loss: 2910619.000 | Test loss: 6493568.000\nIteration: 05600 | Training Loss: 2907112.750 | Test loss: 6590493.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 05800 | Training Loss: 2904218.250 | Test loss: 6673994.000\nIteration: 06000 | Training Loss: 2901760.250 | Test loss: 6743779.000\nIteration: 06200 | Training Loss: 2899596.000 | Test loss: 6800061.000\nIteration: 06400 | Training Loss: 2897614.750 | Test loss: 6843601.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 06600 | Training Loss: 2895737.250 | Test loss: 6875629.500\nIteration: 06800 | Training Loss: 2893910.750 | Test loss: 6897707.000\nIteration: 07000 | Training Loss: 2892103.250 | Test loss: 6911608.500\nIteration: 07200 | Training Loss: 2890297.000 | Test loss: 6919136.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 07400 | Training Loss: 2888485.500 | Test loss: 6921981.500\nIteration: 07600 | Training Loss: 2886664.250 | Test loss: 6921584.000\nIteration: 07800 | Training Loss: 2884834.750 | Test loss: 6919115.500\nIteration: 08000 | Training Loss: 2882997.750 | Test loss: 6915412.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 08200 | Training Loss: 2881153.750 | Test loss: 6911017.500\nIteration: 08400 | Training Loss: 2879304.250 | Test loss: 6906411.000\nIteration: 08600 | Training Loss: 2877451.000 | Test loss: 6901539.500\nIteration: 08800 | Training Loss: 2875594.000 | Test loss: 6896723.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 09000 | Training Loss: 2873734.250 | Test loss: 6891953.000\nIteration: 09200 | Training Loss: 2871873.000 | Test loss: 6887216.000\nIteration: 09400 | Training Loss: 2870010.000 | Test loss: 6882523.000\nIteration: 09600 | Training Loss: 2868146.000 | Test loss: 6877853.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 09800 | Training Loss: 2866281.500 | Test loss: 6873222.000\nIteration: 10000 | Training Loss: 2864416.500 | Test loss: 6868619.500\nIteration: 10200 | Training Loss: 2862551.500 | Test loss: 6864043.000\nIteration: 10400 | Training Loss: 2860686.500 | Test loss: 6859490.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10600 | Training Loss: 2858821.750 | Test loss: 6854956.500\nIteration: 10800 | Training Loss: 2856957.500 | Test loss: 6850450.000\nIteration: 11000 | Training Loss: 2855093.000 | Test loss: 6845956.000\nIteration: 11200 | Training Loss: 2853229.750 | Test loss: 6841486.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 11400 | Training Loss: 2851367.250 | Test loss: 6837029.500\nIteration: 11600 | Training Loss: 2849505.500 | Test loss: 6832580.000\nIteration: 11800 | Training Loss: 2847644.750 | Test loss: 6828137.500\nIteration: 12000 | Training Loss: 2845784.500 | Test loss: 6823696.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 12200 | Training Loss: 2843925.500 | Test loss: 6819290.500\nIteration: 12400 | Training Loss: 2842067.250 | Test loss: 6814899.500\nIteration: 12600 | Training Loss: 2840210.000 | Test loss: 6810524.000\nIteration: 12800 | Training Loss: 2838353.250 | Test loss: 6806158.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 13000 | Training Loss: 2836497.750 | Test loss: 6801795.000\nIteration: 13200 | Training Loss: 2834643.000 | Test loss: 6797446.000\nIteration: 13400 | Training Loss: 2832789.500 | Test loss: 6793100.500\nIteration: 13600 | Training Loss: 2830937.000 | Test loss: 6788766.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 13800 | Training Loss: 2829085.000 | Test loss: 6784435.500\nIteration: 14000 | Training Loss: 2827234.250 | Test loss: 6780105.500\nIteration: 14200 | Training Loss: 2825384.250 | Test loss: 6775785.500\nIteration: 14400 | Training Loss: 2823535.250 | Test loss: 6771466.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 14600 | Training Loss: 2821687.250 | Test loss: 6767162.500\nIteration: 14800 | Training Loss: 2819840.500 | Test loss: 6762855.000\nIteration: 15000 | Training Loss: 2817995.000 | Test loss: 6758553.500\nIteration: 15200 | Training Loss: 2816149.500 | Test loss: 6754258.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 15400 | Training Loss: 2814305.750 | Test loss: 6749963.000\nIteration: 15600 | Training Loss: 2812462.750 | Test loss: 6745676.500\nIteration: 15800 | Training Loss: 2810621.000 | Test loss: 6741391.500\nIteration: 16000 | Training Loss: 2808780.500 | Test loss: 6737108.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 16200 | Training Loss: 2806940.250 | Test loss: 6732828.000\nIteration: 16400 | Training Loss: 2805101.250 | Test loss: 6728551.000\nIteration: 16600 | Training Loss: 2803263.500 | Test loss: 6724283.000\nIteration: 16800 | Training Loss: 2801426.750 | Test loss: 6720015.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 17000 | Training Loss: 2799591.000 | Test loss: 6715745.000\nIteration: 17200 | Training Loss: 2797755.750 | Test loss: 6711487.000\nIteration: 17400 | Training Loss: 2795922.000 | Test loss: 6707221.000\nIteration: 17600 | Training Loss: 2794089.000 | Test loss: 6702964.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 17800 | Training Loss: 2792257.250 | Test loss: 6698707.500\nIteration: 18000 | Training Loss: 2790426.750 | Test loss: 6694458.000\nIteration: 18200 | Training Loss: 2788596.750 | Test loss: 6690211.500\nIteration: 18400 | Training Loss: 2786768.000 | Test loss: 6685961.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 18600 | Training Loss: 2784940.500 | Test loss: 6681719.500\nIteration: 18800 | Training Loss: 2783114.000 | Test loss: 6677477.500\nIteration: 19000 | Training Loss: 2781288.750 | Test loss: 6673237.500\nIteration: 19200 | Training Loss: 2779464.000 | Test loss: 6669002.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 19400 | Training Loss: 2777640.250 | Test loss: 6664766.500\nIteration: 19600 | Training Loss: 2775817.750 | Test loss: 6660536.500\nIteration: 19800 | Training Loss: 2773996.250 | Test loss: 6656308.500\nIteration: 20000 | Training Loss: 2772176.000 | Test loss: 6652081.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 20200 | Training Loss: 2770356.250 | Test loss: 6647853.500\nIteration: 20400 | Training Loss: 2768537.500 | Test loss: 6643629.000\nIteration: 20600 | Training Loss: 2766719.750 | Test loss: 6639412.000\nIteration: 20800 | Training Loss: 2764903.250 | Test loss: 6635195.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 21000 | Training Loss: 2763087.750 | Test loss: 6630977.000\nIteration: 21200 | Training Loss: 2761273.250 | Test loss: 6626765.000\nIteration: 21400 | Training Loss: 2759460.000 | Test loss: 6622551.500\nIteration: 21600 | Training Loss: 2757647.000 | Test loss: 6618342.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 21800 | Training Loss: 2755835.750 | Test loss: 6614139.000\nIteration: 22000 | Training Loss: 2754025.000 | Test loss: 6609934.500\nIteration: 22200 | Training Loss: 2752215.750 | Test loss: 6605727.500\nIteration: 22400 | Training Loss: 2750407.250 | Test loss: 6601527.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 22600 | Training Loss: 2748599.500 | Test loss: 6597332.500\nIteration: 22800 | Training Loss: 2746792.750 | Test loss: 6593137.000\nIteration: 23000 | Training Loss: 2744987.000 | Test loss: 6588942.500\nIteration: 23200 | Training Loss: 2743182.250 | Test loss: 6584751.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 23400 | Training Loss: 2741378.250 | Test loss: 6580555.000\nIteration: 23600 | Training Loss: 2739574.750 | Test loss: 6576369.500\nIteration: 23800 | Training Loss: 2737772.250 | Test loss: 6572181.000\nIteration: 24000 | Training Loss: 2735970.750 | Test loss: 6567999.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 24200 | Training Loss: 2734170.500 | Test loss: 6563815.500\nIteration: 24400 | Training Loss: 2732371.750 | Test loss: 6559641.000\nIteration: 24600 | Training Loss: 2730573.500 | Test loss: 6555462.000\nIteration: 24800 | Training Loss: 2728776.500 | Test loss: 6551286.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 25000 | Training Loss: 2726980.750 | Test loss: 6547111.500\nIteration: 25200 | Training Loss: 2725185.750 | Test loss: 6542946.000\nIteration: 25400 | Training Loss: 2723392.250 | Test loss: 6538773.000\nIteration: 25600 | Training Loss: 2721598.750 | Test loss: 6534602.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 25800 | Training Loss: 2719807.000 | Test loss: 6530445.500\nIteration: 26000 | Training Loss: 2718016.250 | Test loss: 6526287.000\nIteration: 26200 | Training Loss: 2716226.250 | Test loss: 6522121.000\nIteration: 26400 | Training Loss: 2714437.500 | Test loss: 6518004.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 26600 | Training Loss: 2712649.250 | Test loss: 6513768.500\nIteration: 26800 | Training Loss: 2710862.000 | Test loss: 6509677.500\nIteration: 27000 | Training Loss: 2709076.500 | Test loss: 6505508.000\nIteration: 27200 | Training Loss: 2707291.500 | Test loss: 6501348.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 27400 | Training Loss: 2705507.750 | Test loss: 6497150.500\nIteration: 27600 | Training Loss: 2703724.750 | Test loss: 6493075.500\nIteration: 27800 | Training Loss: 2701942.750 | Test loss: 6488818.500\nIteration: 28000 | Training Loss: 2700161.750 | Test loss: 6484717.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 28200 | Training Loss: 2698381.750 | Test loss: 6480632.500\nIteration: 28400 | Training Loss: 2696603.000 | Test loss: 6476532.000\nIteration: 28600 | Training Loss: 2694825.250 | Test loss: 6472412.500\nIteration: 28800 | Training Loss: 2693048.000 | Test loss: 6468348.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 29000 | Training Loss: 2691272.250 | Test loss: 6464079.500\nIteration: 29200 | Training Loss: 2689497.250 | Test loss: 6460041.000\nIteration: 29400 | Training Loss: 2687723.500 | Test loss: 6455825.000\nIteration: 29600 | Training Loss: 2685950.750 | Test loss: 6451747.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 29800 | Training Loss: 2684178.500 | Test loss: 6447674.000\nIteration: 30000 | Training Loss: 2682407.500 | Test loss: 6443421.000\nIteration: 30200 | Training Loss: 2680637.500 | Test loss: 6439328.000\nIteration: 30400 | Training Loss: 2678868.750 | Test loss: 6435211.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 30600 | Training Loss: 2677101.000 | Test loss: 6431144.000\nIteration: 30800 | Training Loss: 2675334.250 | Test loss: 6427074.500\nIteration: 31000 | Training Loss: 2673567.750 | Test loss: 6422986.000\nIteration: 31200 | Training Loss: 2671803.000 | Test loss: 6418912.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 31400 | Training Loss: 2670039.250 | Test loss: 6414741.500\nIteration: 31600 | Training Loss: 2668276.250 | Test loss: 6410611.000\nIteration: 31800 | Training Loss: 2666514.500 | Test loss: 6406513.000\nIteration: 32000 | Training Loss: 2664753.250 | Test loss: 6402501.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 32200 | Training Loss: 2662993.250 | Test loss: 6398341.500\nIteration: 32400 | Training Loss: 2661234.750 | Test loss: 6394254.000\nIteration: 32600 | Training Loss: 2659477.250 | Test loss: 6390132.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 32800 | Training Loss: 2657721.000 | Test loss: 6386039.500\nIteration: 33000 | Training Loss: 2655965.000 | Test loss: 6381956.500\nIteration: 33200 | Training Loss: 2654210.500 | Test loss: 6377871.000\nIteration: 33400 | Training Loss: 2652457.250 | Test loss: 6373630.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 33600 | Training Loss: 2650704.750 | Test loss: 6369657.500\nIteration: 33800 | Training Loss: 2648953.500 | Test loss: 6365594.500\nIteration: 34000 | Training Loss: 2647203.000 | Test loss: 6361557.500\nIteration: 34200 | Training Loss: 2645453.500 | Test loss: 6357451.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 34400 | Training Loss: 2643705.250 | Test loss: 6353489.000\nIteration: 34600 | Training Loss: 2641957.750 | Test loss: 6349270.000\nIteration: 34800 | Training Loss: 2640211.500 | Test loss: 6345327.500\nIteration: 35000 | Training Loss: 2638466.250 | Test loss: 6341229.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 35200 | Training Loss: 2636721.750 | Test loss: 6337143.000\nIteration: 35400 | Training Loss: 2634978.250 | Test loss: 6333049.500\nIteration: 35600 | Training Loss: 2633236.000 | Test loss: 6328920.500\nIteration: 35800 | Training Loss: 2631494.750 | Test loss: 6325013.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 36000 | Training Loss: 2629754.500 | Test loss: 6320953.500\nIteration: 36200 | Training Loss: 2628014.750 | Test loss: 6316894.500\nIteration: 36400 | Training Loss: 2626276.250 | Test loss: 6312835.000\nIteration: 36600 | Training Loss: 2624539.000 | Test loss: 6308774.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 36800 | Training Loss: 2622802.750 | Test loss: 6304757.000\nIteration: 37000 | Training Loss: 2621067.250 | Test loss: 6300606.500\nIteration: 37200 | Training Loss: 2619333.000 | Test loss: 6296593.000\nIteration: 37400 | Training Loss: 2617599.250 | Test loss: 6292519.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 37600 | Training Loss: 2615866.750 | Test loss: 6288664.000\nIteration: 37800 | Training Loss: 2614135.500 | Test loss: 6284469.500\nIteration: 38000 | Training Loss: 2612404.750 | Test loss: 6280524.500\nIteration: 38200 | Training Loss: 2610675.750 | Test loss: 6276494.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 38400 | Training Loss: 2608947.000 | Test loss: 6272500.000\nIteration: 38600 | Training Loss: 2607219.500 | Test loss: 6268336.000\nIteration: 38800 | Training Loss: 2605493.250 | Test loss: 6264367.500\nIteration: 39000 | Training Loss: 2603767.500 | Test loss: 6260429.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 39200 | Training Loss: 2602043.500 | Test loss: 6256327.500\nIteration: 39400 | Training Loss: 2600319.500 | Test loss: 6252174.000\nIteration: 39600 | Training Loss: 2598597.000 | Test loss: 6248295.000\nIteration: 39800 | Training Loss: 2596876.000 | Test loss: 6244278.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 40000 | Training Loss: 2595155.250 | Test loss: 6240343.000\nIteration: 40200 | Training Loss: 2593436.000 | Test loss: 6236104.500\nIteration: 40400 | Training Loss: 2591717.500 | Test loss: 6232243.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 40600 | Training Loss: 2590000.000 | Test loss: 6228204.000\nIteration: 40800 | Training Loss: 2588283.500 | Test loss: 6224229.500\nIteration: 41000 | Training Loss: 2586568.000 | Test loss: 6220218.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 41200 | Training Loss: 2584853.500 | Test loss: 6216222.500\nIteration: 41400 | Training Loss: 2583140.250 | Test loss: 6212160.500\nIteration: 41600 | Training Loss: 2581427.500 | Test loss: 6208198.500\nIteration: 41800 | Training Loss: 2579716.250 | Test loss: 6204209.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 42000 | Training Loss: 2578005.500 | Test loss: 6200317.000\nIteration: 42200 | Training Loss: 2576296.250 | Test loss: 6196304.500\nIteration: 42400 | Training Loss: 2574587.750 | Test loss: 6192293.500\nIteration: 42600 | Training Loss: 2572880.000 | Test loss: 6188244.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 42800 | Training Loss: 2571173.500 | Test loss: 6184311.500\nIteration: 43000 | Training Loss: 2569468.250 | Test loss: 6180322.500\nIteration: 43200 | Training Loss: 2567763.750 | Test loss: 6176291.500\nIteration: 43400 | Training Loss: 2566060.500 | Test loss: 6172207.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 43600 | Training Loss: 2564358.000 | Test loss: 6168427.000\nIteration: 43800 | Training Loss: 2562656.250 | Test loss: 6164373.000\nIteration: 44000 | Training Loss: 2560956.250 | Test loss: 6160349.500\nIteration: 44200 | Training Loss: 2559256.750 | Test loss: 6156500.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 44400 | Training Loss: 2557558.500 | Test loss: 6152525.500\nIteration: 44600 | Training Loss: 2555861.500 | Test loss: 6148598.500\nIteration: 44800 | Training Loss: 2554164.750 | Test loss: 6144566.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 45000 | Training Loss: 2552469.250 | Test loss: 6140600.500\nIteration: 45200 | Training Loss: 2550775.250 | Test loss: 6136647.500\nIteration: 45400 | Training Loss: 2549081.750 | Test loss: 6132687.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 45600 | Training Loss: 2547389.500 | Test loss: 6128756.500\nIteration: 45800 | Training Loss: 2545698.000 | Test loss: 6124802.000\nIteration: 46000 | Training Loss: 2544007.500 | Test loss: 6120908.500\nIteration: 46200 | Training Loss: 2542318.500 | Test loss: 6116941.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 46400 | Training Loss: 2540630.000 | Test loss: 6113042.500\nIteration: 46600 | Training Loss: 2538942.750 | Test loss: 6109000.500\nIteration: 46800 | Training Loss: 2537256.500 | Test loss: 6105050.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 47000 | Training Loss: 2535570.500 | Test loss: 6101071.000\nIteration: 47200 | Training Loss: 2533886.500 | Test loss: 6097200.500\nIteration: 47400 | Training Loss: 2532203.250 | Test loss: 6093260.000\nIteration: 47600 | Training Loss: 2530520.750 | Test loss: 6089409.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 47800 | Training Loss: 2528839.500 | Test loss: 6085522.500\nIteration: 48000 | Training Loss: 2527158.750 | Test loss: 6081472.000\nIteration: 48200 | Training Loss: 2525479.500 | Test loss: 6077542.500\nIteration: 48400 | Training Loss: 2523801.250 | Test loss: 6073603.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 48600 | Training Loss: 2522123.750 | Test loss: 6069721.500\nIteration: 48800 | Training Loss: 2520447.500 | Test loss: 6065821.000\nIteration: 49000 | Training Loss: 2518771.750 | Test loss: 6061818.000\nIteration: 49200 | Training Loss: 2517097.250 | Test loss: 6057978.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 49400 | Training Loss: 2515424.250 | Test loss: 6054125.000\nIteration: 49600 | Training Loss: 2513752.000 | Test loss: 6050252.500\nIteration: 49800 | Training Loss: 2512080.500 | Test loss: 6046269.000\nIteration: 50000 | Training Loss: 2510410.250 | Test loss: 6042196.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 50200 | Training Loss: 2508740.500 | Test loss: 6038394.500\nIteration: 50400 | Training Loss: 2507072.250 | Test loss: 6034595.000\nIteration: 50600 | Training Loss: 2505404.750 | Test loss: 6030519.000\nIteration: 50800 | Training Loss: 2503738.500 | Test loss: 6026714.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 51000 | Training Loss: 2502073.250 | Test loss: 6022833.000\nIteration: 51200 | Training Loss: 2500408.500 | Test loss: 6018911.500\nIteration: 51400 | Training Loss: 2498745.000 | Test loss: 6015056.000\nIteration: 51600 | Training Loss: 2497082.750 | Test loss: 6011204.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 51800 | Training Loss: 2495421.500 | Test loss: 6007251.500\nIteration: 52000 | Training Loss: 2493761.250 | Test loss: 6003331.500\nIteration: 52200 | Training Loss: 2492101.250 | Test loss: 5999473.500\nIteration: 52400 | Training Loss: 2490442.750 | Test loss: 5995583.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 52600 | Training Loss: 2488785.750 | Test loss: 5991731.500\nIteration: 52800 | Training Loss: 2487129.500 | Test loss: 5987903.000\nIteration: 53000 | Training Loss: 2485474.000 | Test loss: 5983976.000\nIteration: 53200 | Training Loss: 2483819.750 | Test loss: 5980098.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 53400 | Training Loss: 2482165.750 | Test loss: 5976249.000\nIteration: 53600 | Training Loss: 2480513.750 | Test loss: 5972363.000\nIteration: 53800 | Training Loss: 2478862.250 | Test loss: 5968459.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 54000 | Training Loss: 2477211.750 | Test loss: 5964655.500\nIteration: 54200 | Training Loss: 2475562.500 | Test loss: 5960763.500\nIteration: 54400 | Training Loss: 2473913.750 | Test loss: 5956878.500\nIteration: 54600 | Training Loss: 2472266.500 | Test loss: 5953062.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 54800 | Training Loss: 2470620.000 | Test loss: 5949152.500\nIteration: 55000 | Training Loss: 2468974.500 | Test loss: 5945323.000\nIteration: 55200 | Training Loss: 2467330.250 | Test loss: 5941470.500\nIteration: 55400 | Training Loss: 2465686.250 | Test loss: 5937656.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 55600 | Training Loss: 2464043.250 | Test loss: 5933765.000\nIteration: 55800 | Training Loss: 2462401.500 | Test loss: 5929937.000\nIteration: 56000 | Training Loss: 2460760.000 | Test loss: 5926119.000\nIteration: 56200 | Training Loss: 2459118.750 | Test loss: 5922260.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 56400 | Training Loss: 2457478.250 | Test loss: 5918421.500\nIteration: 56600 | Training Loss: 2455837.750 | Test loss: 5914606.000\nIteration: 56800 | Training Loss: 2454198.500 | Test loss: 5910662.000\nIteration: 57000 | Training Loss: 2452560.250 | Test loss: 5906868.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 57200 | Training Loss: 2450923.000 | Test loss: 5903109.500\nIteration: 57400 | Training Loss: 2449286.500 | Test loss: 5899197.000\nIteration: 57600 | Training Loss: 2447651.500 | Test loss: 5895392.000\nIteration: 57800 | Training Loss: 2446017.250 | Test loss: 5891541.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 58000 | Training Loss: 2444384.250 | Test loss: 5887714.000\nIteration: 58200 | Training Loss: 2442752.000 | Test loss: 5883872.500\nIteration: 58400 | Training Loss: 2441120.500 | Test loss: 5880039.500\nIteration: 58600 | Training Loss: 2439490.500 | Test loss: 5876246.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 58800 | Training Loss: 2437861.250 | Test loss: 5872406.500\nIteration: 59000 | Training Loss: 2436233.000 | Test loss: 5868554.000\nIteration: 59200 | Training Loss: 2434606.000 | Test loss: 5864804.500\nIteration: 59400 | Training Loss: 2432979.750 | Test loss: 5860990.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 59600 | Training Loss: 2431354.750 | Test loss: 5857148.000\nIteration: 59800 | Training Loss: 2429730.250 | Test loss: 5853352.500\nIteration: 60000 | Training Loss: 2428107.000 | Test loss: 5849540.500\nIteration: 60200 | Training Loss: 2426485.250 | Test loss: 5845693.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 60400 | Training Loss: 2424864.000 | Test loss: 5841904.000\nIteration: 60600 | Training Loss: 2423243.500 | Test loss: 5838161.000\nIteration: 60800 | Training Loss: 2421624.500 | Test loss: 5834352.000\nIteration: 61000 | Training Loss: 2420006.250 | Test loss: 5830519.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 61200 | Training Loss: 2418389.250 | Test loss: 5826722.000\nIteration: 61400 | Training Loss: 2416773.000 | Test loss: 5822897.500\nIteration: 61600 | Training Loss: 2415157.500 | Test loss: 5819027.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 61800 | Training Loss: 2413543.750 | Test loss: 5815256.000\nIteration: 62000 | Training Loss: 2411930.500 | Test loss: 5811605.000\nIteration: 62200 | Training Loss: 2410318.250 | Test loss: 5807813.500\nIteration: 62400 | Training Loss: 2408707.250 | Test loss: 5804039.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 62600 | Training Loss: 2407097.000 | Test loss: 5800065.500\nIteration: 62800 | Training Loss: 2405488.000 | Test loss: 5796441.000\nIteration: 63000 | Training Loss: 2403879.500 | Test loss: 5792665.000\nIteration: 63200 | Training Loss: 2402272.500 | Test loss: 5788985.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 63400 | Training Loss: 2400666.500 | Test loss: 5785236.000\nIteration: 63600 | Training Loss: 2399061.250 | Test loss: 5781326.500\nIteration: 63800 | Training Loss: 2397457.000 | Test loss: 5777576.000\nIteration: 64000 | Training Loss: 2395854.000 | Test loss: 5773904.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 64200 | Training Loss: 2394251.750 | Test loss: 5770215.500\nIteration: 64400 | Training Loss: 2392650.750 | Test loss: 5766309.000\nIteration: 64600 | Training Loss: 2391050.500 | Test loss: 5762508.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 64800 | Training Loss: 2389451.250 | Test loss: 5758752.000\nIteration: 65000 | Training Loss: 2387853.250 | Test loss: 5754984.000\nIteration: 65200 | Training Loss: 2386256.000 | Test loss: 5751271.500\nIteration: 65400 | Training Loss: 2384659.750 | Test loss: 5747500.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 65600 | Training Loss: 2383064.750 | Test loss: 5743789.000\nIteration: 65800 | Training Loss: 2381470.500 | Test loss: 5740056.500\nIteration: 66000 | Training Loss: 2379877.750 | Test loss: 5736278.000\nIteration: 66200 | Training Loss: 2378285.500 | Test loss: 5732494.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 66400 | Training Loss: 2376694.500 | Test loss: 5728807.000\nIteration: 66600 | Training Loss: 2375104.750 | Test loss: 5725180.000\nIteration: 66800 | Training Loss: 2373515.750 | Test loss: 5721341.500\nIteration: 67000 | Training Loss: 2371927.500 | Test loss: 5717653.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 67200 | Training Loss: 2370340.750 | Test loss: 5713885.000\nIteration: 67400 | Training Loss: 2368754.750 | Test loss: 5710156.000\nIteration: 67600 | Training Loss: 2367170.000 | Test loss: 5706429.500\nIteration: 67800 | Training Loss: 2365586.000 | Test loss: 5702698.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 68000 | Training Loss: 2364002.750 | Test loss: 5698915.000\nIteration: 68200 | Training Loss: 2362421.000 | Test loss: 5695241.000\nIteration: 68400 | Training Loss: 2360840.000 | Test loss: 5691486.500\nIteration: 68600 | Training Loss: 2359260.000 | Test loss: 5687849.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 68800 | Training Loss: 2357681.250 | Test loss: 5684089.500\nIteration: 69000 | Training Loss: 2356103.250 | Test loss: 5680344.000\nIteration: 69200 | Training Loss: 2354526.500 | Test loss: 5676647.500\nIteration: 69400 | Training Loss: 2352950.250 | Test loss: 5672966.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 69600 | Training Loss: 2351375.500 | Test loss: 5669258.000\nIteration: 69800 | Training Loss: 2349801.750 | Test loss: 5665426.500\nIteration: 70000 | Training Loss: 2348228.500 | Test loss: 5661882.000\nIteration: 70200 | Training Loss: 2346656.500 | Test loss: 5658271.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 70400 | Training Loss: 2345085.750 | Test loss: 5654496.500\nIteration: 70600 | Training Loss: 2343515.750 | Test loss: 5650725.000\nIteration: 70800 | Training Loss: 2341947.000 | Test loss: 5647133.500\nIteration: 71000 | Training Loss: 2340379.000 | Test loss: 5643313.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 71200 | Training Loss: 2338811.750 | Test loss: 5639657.500\nIteration: 71400 | Training Loss: 2337246.000 | Test loss: 5635962.000\nIteration: 71600 | Training Loss: 2335681.000 | Test loss: 5632370.000\nIteration: 71800 | Training Loss: 2334117.000 | Test loss: 5628642.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 72000 | Training Loss: 2332554.500 | Test loss: 5624967.500\nIteration: 72200 | Training Loss: 2330992.500 | Test loss: 5621270.500\nIteration: 72400 | Training Loss: 2329431.750 | Test loss: 5617599.500\nIteration: 72600 | Training Loss: 2327871.500 | Test loss: 5613920.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 72800 | Training Loss: 2326312.500 | Test loss: 5610276.500\nIteration: 73000 | Training Loss: 2324755.000 | Test loss: 5606613.500\nIteration: 73200 | Training Loss: 2323198.000 | Test loss: 5602882.500\nIteration: 73400 | Training Loss: 2321641.750 | Test loss: 5599188.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 73600 | Training Loss: 2320087.000 | Test loss: 5595607.500\nIteration: 73800 | Training Loss: 2318533.000 | Test loss: 5592025.500\nIteration: 74000 | Training Loss: 2316980.500 | Test loss: 5588319.000\nIteration: 74200 | Training Loss: 2315428.500 | Test loss: 5584516.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 74400 | Training Loss: 2313877.250 | Test loss: 5580940.000\nIteration: 74600 | Training Loss: 2312327.750 | Test loss: 5577182.000\nIteration: 74800 | Training Loss: 2310778.750 | Test loss: 5573693.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 75000 | Training Loss: 2309230.750 | Test loss: 5570001.000\nIteration: 75200 | Training Loss: 2307684.000 | Test loss: 5566406.000\nIteration: 75400 | Training Loss: 2306138.000 | Test loss: 5562692.500\nIteration: 75600 | Training Loss: 2304593.250 | Test loss: 5559102.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 75800 | Training Loss: 2303049.000 | Test loss: 5555417.000\nIteration: 76000 | Training Loss: 2301505.750 | Test loss: 5551802.000\nIteration: 76200 | Training Loss: 2299964.000 | Test loss: 5548235.000\nIteration: 76400 | Training Loss: 2298422.750 | Test loss: 5544547.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 76600 | Training Loss: 2296882.250 | Test loss: 5540934.000\nIteration: 76800 | Training Loss: 2295343.500 | Test loss: 5537308.000\nIteration: 77000 | Training Loss: 2293805.250 | Test loss: 5533629.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 77200 | Training Loss: 2292268.250 | Test loss: 5529949.500\nIteration: 77400 | Training Loss: 2290732.250 | Test loss: 5526402.000\nIteration: 77600 | Training Loss: 2289196.750 | Test loss: 5522776.000\nIteration: 77800 | Training Loss: 2287663.000 | Test loss: 5519061.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 78000 | Training Loss: 2286130.000 | Test loss: 5515555.000\nIteration: 78200 | Training Loss: 2284597.500 | Test loss: 5511874.000\nIteration: 78400 | Training Loss: 2283066.750 | Test loss: 5508330.000\nIteration: 78600 | Training Loss: 2281536.500 | Test loss: 5504774.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 78800 | Training Loss: 2280007.500 | Test loss: 5501273.000\nIteration: 79000 | Training Loss: 2278479.500 | Test loss: 5497499.000\nIteration: 79200 | Training Loss: 2276952.000 | Test loss: 5493892.500\nIteration: 79400 | Training Loss: 2275426.250 | Test loss: 5490213.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 79600 | Training Loss: 2273901.250 | Test loss: 5486697.000\nIteration: 79800 | Training Loss: 2272376.750 | Test loss: 5483086.000\nIteration: 80000 | Training Loss: 2270854.000 | Test loss: 5479520.000\nIteration: 80200 | Training Loss: 2269332.000 | Test loss: 5475904.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 80400 | Training Loss: 2267811.000 | Test loss: 5472342.500\nIteration: 80600 | Training Loss: 2266291.000 | Test loss: 5468624.500\nIteration: 80800 | Training Loss: 2264771.750 | Test loss: 5465052.000\nIteration: 81000 | Training Loss: 2263254.500 | Test loss: 5461570.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 81200 | Training Loss: 2261738.500 | Test loss: 5458004.000\nIteration: 81400 | Training Loss: 2260223.000 | Test loss: 5454408.000\nIteration: 81600 | Training Loss: 2258709.250 | Test loss: 5450869.500\nIteration: 81800 | Training Loss: 2257196.250 | Test loss: 5447193.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 82000 | Training Loss: 2255684.500 | Test loss: 5443532.000\nIteration: 82200 | Training Loss: 2254173.250 | Test loss: 5440098.000\nIteration: 82400 | Training Loss: 2252663.250 | Test loss: 5436552.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 82600 | Training Loss: 2251154.500 | Test loss: 5433077.500\nIteration: 82800 | Training Loss: 2249646.500 | Test loss: 5429425.500\nIteration: 83000 | Training Loss: 2248139.250 | Test loss: 5425896.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 83200 | Training Loss: 2246633.500 | Test loss: 5422332.000\nIteration: 83400 | Training Loss: 2245128.500 | Test loss: 5418828.500\nIteration: 83600 | Training Loss: 2243624.750 | Test loss: 5415184.500\nIteration: 83800 | Training Loss: 2242121.750 | Test loss: 5411662.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 84000 | Training Loss: 2240619.750 | Test loss: 5408105.500\nIteration: 84200 | Training Loss: 2239119.000 | Test loss: 5404652.000\nIteration: 84400 | Training Loss: 2237619.000 | Test loss: 5401018.000\nIteration: 84600 | Training Loss: 2236119.750 | Test loss: 5397493.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 84800 | Training Loss: 2234622.000 | Test loss: 5393906.000\nIteration: 85000 | Training Loss: 2233125.000 | Test loss: 5390369.000\nIteration: 85200 | Training Loss: 2231629.250 | Test loss: 5386857.000\nIteration: 85400 | Training Loss: 2230134.000 | Test loss: 5383245.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 85600 | Training Loss: 2228640.000 | Test loss: 5379779.000\nIteration: 85800 | Training Loss: 2227147.250 | Test loss: 5376225.500\nIteration: 86000 | Training Loss: 2225655.250 | Test loss: 5372696.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 86200 | Training Loss: 2224164.000 | Test loss: 5369227.500\nIteration: 86400 | Training Loss: 2222674.250 | Test loss: 5365689.500\nIteration: 86600 | Training Loss: 2221185.250 | Test loss: 5362137.500\nIteration: 86800 | Training Loss: 2219697.500 | Test loss: 5358639.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 87000 | Training Loss: 2218210.250 | Test loss: 5355114.000\nIteration: 87200 | Training Loss: 2216724.250 | Test loss: 5351625.000\nIteration: 87400 | Training Loss: 2215239.500 | Test loss: 5348098.000\nIteration: 87600 | Training Loss: 2213755.500 | Test loss: 5344555.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 87800 | Training Loss: 2212272.250 | Test loss: 5341005.000\nIteration: 88000 | Training Loss: 2210790.500 | Test loss: 5337625.500\nIteration: 88200 | Training Loss: 2209309.500 | Test loss: 5334053.000\nIteration: 88400 | Training Loss: 2207829.750 | Test loss: 5330603.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 88600 | Training Loss: 2206350.500 | Test loss: 5327124.000\nIteration: 88800 | Training Loss: 2204872.500 | Test loss: 5323508.500\nIteration: 89000 | Training Loss: 2203395.500 | Test loss: 5320087.000\nIteration: 89200 | Training Loss: 2201919.750 | Test loss: 5316595.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 89400 | Training Loss: 2200444.500 | Test loss: 5313084.500\nIteration: 89600 | Training Loss: 2198970.750 | Test loss: 5309580.500\nIteration: 89800 | Training Loss: 2197497.750 | Test loss: 5306151.500\nIteration: 90000 | Training Loss: 2196025.750 | Test loss: 5302639.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 90200 | Training Loss: 2194554.750 | Test loss: 5299149.000\nIteration: 90400 | Training Loss: 2193084.500 | Test loss: 5295649.000\nIteration: 90600 | Training Loss: 2191615.750 | Test loss: 5292193.000\nIteration: 90800 | Training Loss: 2190148.000 | Test loss: 5288671.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 91000 | Training Loss: 2188680.500 | Test loss: 5285180.500\nIteration: 91200 | Training Loss: 2187214.750 | Test loss: 5281780.500\nIteration: 91400 | Training Loss: 2185749.750 | Test loss: 5278328.000\nIteration: 91600 | Training Loss: 2184286.000 | Test loss: 5274852.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 91800 | Training Loss: 2182822.750 | Test loss: 5271418.000\nIteration: 92000 | Training Loss: 2181360.750 | Test loss: 5267837.500\nIteration: 92200 | Training Loss: 2179899.750 | Test loss: 5264429.000\nIteration: 92400 | Training Loss: 2178440.000 | Test loss: 5261003.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 92600 | Training Loss: 2176980.500 | Test loss: 5257520.000\nIteration: 92800 | Training Loss: 2175523.000 | Test loss: 5254066.000\nIteration: 93000 | Training Loss: 2174065.750 | Test loss: 5250616.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 93200 | Training Loss: 2172610.000 | Test loss: 5247302.500\nIteration: 93400 | Training Loss: 2171154.750 | Test loss: 5243646.500\nIteration: 93600 | Training Loss: 2169700.750 | Test loss: 5240247.500\nIteration: 93800 | Training Loss: 2168248.000 | Test loss: 5236775.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 94000 | Training Loss: 2166796.000 | Test loss: 5233413.500\nIteration: 94200 | Training Loss: 2165344.500 | Test loss: 5229976.500\nIteration: 94400 | Training Loss: 2163894.750 | Test loss: 5226514.500\nIteration: 94600 | Training Loss: 2162445.750 | Test loss: 5223039.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 94800 | Training Loss: 2160998.000 | Test loss: 5219625.000\nIteration: 95000 | Training Loss: 2159550.750 | Test loss: 5216235.000\nIteration: 95200 | Training Loss: 2158104.750 | Test loss: 5212794.500\nIteration: 95400 | Training Loss: 2156659.750 | Test loss: 5209338.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 95600 | Training Loss: 2155216.000 | Test loss: 5205883.500\nIteration: 95800 | Training Loss: 2153772.750 | Test loss: 5202486.000\nIteration: 96000 | Training Loss: 2152331.250 | Test loss: 5199048.500\nIteration: 96200 | Training Loss: 2150890.500 | Test loss: 5195637.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 96400 | Training Loss: 2149451.000 | Test loss: 5192258.000\nIteration: 96600 | Training Loss: 2148012.000 | Test loss: 5188742.000\nIteration: 96800 | Training Loss: 2146574.250 | Test loss: 5185366.500\nIteration: 97000 | Training Loss: 2145137.750 | Test loss: 5181908.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 97200 | Training Loss: 2143702.000 | Test loss: 5178543.500\nIteration: 97400 | Training Loss: 2142267.000 | Test loss: 5175165.000\nIteration: 97600 | Training Loss: 2140833.500 | Test loss: 5171816.500\nIteration: 97800 | Training Loss: 2139400.750 | Test loss: 5168359.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 98000 | Training Loss: 2137969.250 | Test loss: 5165018.500\nIteration: 98200 | Training Loss: 2136538.500 | Test loss: 5161516.500\nIteration: 98400 | Training Loss: 2135108.750 | Test loss: 5158113.500\nIteration: 98600 | Training Loss: 2133680.500 | Test loss: 5154760.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 98800 | Training Loss: 2132253.000 | Test loss: 5151386.500\nIteration: 99000 | Training Loss: 2130826.000 | Test loss: 5147943.000\nIteration: 99200 | Training Loss: 2129400.750 | Test loss: 5144577.500\nIteration: 99400 | Training Loss: 2127976.000 | Test loss: 5141224.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 99600 | Training Loss: 2126552.750 | Test loss: 5137825.000\nIteration: 99800 | Training Loss: 2125130.000 | Test loss: 5134522.500\nIteration: 100000 | Training Loss: 2123708.250 | Test loss: 5131052.000\nIteration: 100200 | Training Loss: 2122288.000 | Test loss: 5127651.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 100400 | Training Loss: 2120868.500 | Test loss: 5124339.500\nIteration: 100600 | Training Loss: 2119449.500 | Test loss: 5120962.000\nIteration: 100800 | Training Loss: 2118032.250 | Test loss: 5117588.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 101000 | Training Loss: 2116615.500 | Test loss: 5114187.500\nIteration: 101200 | Training Loss: 2115200.000 | Test loss: 5110838.000\nIteration: 101400 | Training Loss: 2113785.250 | Test loss: 5107474.000\nIteration: 101600 | Training Loss: 2112371.750 | Test loss: 5104180.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 101800 | Training Loss: 2110959.250 | Test loss: 5100646.500\nIteration: 102000 | Training Loss: 2109547.750 | Test loss: 5097427.000\nIteration: 102200 | Training Loss: 2108136.750 | Test loss: 5093943.500\nIteration: 102400 | Training Loss: 2106727.250 | Test loss: 5090688.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 102600 | Training Loss: 2105318.750 | Test loss: 5087341.500\nIteration: 102800 | Training Loss: 2103911.250 | Test loss: 5084029.000\nIteration: 103000 | Training Loss: 2102504.500 | Test loss: 5080635.000\nIteration: 103200 | Training Loss: 2101098.750 | Test loss: 5077322.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 103400 | Training Loss: 2099694.250 | Test loss: 5073953.000\nIteration: 103600 | Training Loss: 2098290.750 | Test loss: 5070588.000\nIteration: 103800 | Training Loss: 2096887.750 | Test loss: 5067287.500\nIteration: 104000 | Training Loss: 2095486.375 | Test loss: 5063902.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 104200 | Training Loss: 2094085.750 | Test loss: 5060687.000\nIteration: 104400 | Training Loss: 2092686.375 | Test loss: 5057355.000\nIteration: 104600 | Training Loss: 2091287.500 | Test loss: 5053944.500\nIteration: 104800 | Training Loss: 2089890.000 | Test loss: 5050627.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 105000 | Training Loss: 2088493.500 | Test loss: 5047307.000\nIteration: 105200 | Training Loss: 2087098.000 | Test loss: 5043989.000\nIteration: 105400 | Training Loss: 2085703.125 | Test loss: 5040691.500\nIteration: 105600 | Training Loss: 2084309.750 | Test loss: 5037311.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 105800 | Training Loss: 2082917.125 | Test loss: 5034006.500\nIteration: 106000 | Training Loss: 2081525.625 | Test loss: 5030734.500\nIteration: 106200 | Training Loss: 2080134.875 | Test loss: 5027341.000\nIteration: 106400 | Training Loss: 2078745.250 | Test loss: 5023994.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 106600 | Training Loss: 2077356.750 | Test loss: 5020766.500\nIteration: 106800 | Training Loss: 2075969.250 | Test loss: 5017457.000\nIteration: 107000 | Training Loss: 2074582.375 | Test loss: 5014133.500\nIteration: 107200 | Training Loss: 2073196.875 | Test loss: 5010936.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 107400 | Training Loss: 2071812.250 | Test loss: 5007614.000\nIteration: 107600 | Training Loss: 2070428.875 | Test loss: 5004322.000\nIteration: 107800 | Training Loss: 2069046.125 | Test loss: 5001027.500\nIteration: 108000 | Training Loss: 2067664.500 | Test loss: 4997687.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 108200 | Training Loss: 2066284.125 | Test loss: 4994399.000\nIteration: 108400 | Training Loss: 2064904.750 | Test loss: 4991019.000\nIteration: 108600 | Training Loss: 2063525.875 | Test loss: 4987846.500\nIteration: 108800 | Training Loss: 2062148.625 | Test loss: 4984586.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 109000 | Training Loss: 2060772.000 | Test loss: 4981291.500\nIteration: 109200 | Training Loss: 2059396.625 | Test loss: 4977988.500\nIteration: 109400 | Training Loss: 2058022.000 | Test loss: 4974678.500\nIteration: 109600 | Training Loss: 2056648.875 | Test loss: 4971418.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 109800 | Training Loss: 2055277.125 | Test loss: 4968144.000\nIteration: 110000 | Training Loss: 2053906.500 | Test loss: 4964843.000\nIteration: 110200 | Training Loss: 2052536.375 | Test loss: 4961532.500\nIteration: 110400 | Training Loss: 2051167.750 | Test loss: 4958308.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 110600 | Training Loss: 2049799.875 | Test loss: 4955131.000\nIteration: 110800 | Training Loss: 2048433.250 | Test loss: 4951844.000\nIteration: 111000 | Training Loss: 2047067.125 | Test loss: 4948523.000\nIteration: 111200 | Training Loss: 2045702.250 | Test loss: 4945294.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 111400 | Training Loss: 2044338.625 | Test loss: 4942037.000\nIteration: 111600 | Training Loss: 2042975.750 | Test loss: 4938812.000\nIteration: 111800 | Training Loss: 2041613.625 | Test loss: 4935536.000\nIteration: 112000 | Training Loss: 2040253.000 | Test loss: 4932284.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 112200 | Training Loss: 2038893.000 | Test loss: 4929067.000\nIteration: 112400 | Training Loss: 2037534.250 | Test loss: 4925798.500\nIteration: 112600 | Training Loss: 2036176.250 | Test loss: 4922554.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 112800 | Training Loss: 2034819.250 | Test loss: 4919323.000\nIteration: 113000 | Training Loss: 2033463.500 | Test loss: 4916065.500\nIteration: 113200 | Training Loss: 2032108.750 | Test loss: 4912867.000\nIteration: 113400 | Training Loss: 2030754.625 | Test loss: 4909606.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 113600 | Training Loss: 2029401.875 | Test loss: 4906459.500\nIteration: 113800 | Training Loss: 2028050.000 | Test loss: 4903133.000\nIteration: 114000 | Training Loss: 2026699.250 | Test loss: 4899915.000\nIteration: 114200 | Training Loss: 2025349.250 | Test loss: 4896687.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 114400 | Training Loss: 2024000.250 | Test loss: 4893542.000\nIteration: 114600 | Training Loss: 2022652.375 | Test loss: 4890225.000\nIteration: 114800 | Training Loss: 2021305.500 | Test loss: 4886967.500\nIteration: 115000 | Training Loss: 2019959.375 | Test loss: 4883852.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 115200 | Training Loss: 2018614.625 | Test loss: 4880586.500\nIteration: 115400 | Training Loss: 2017270.625 | Test loss: 4877295.500\nIteration: 115600 | Training Loss: 2015927.875 | Test loss: 4874187.500\nIteration: 115800 | Training Loss: 2014585.875 | Test loss: 4870974.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 116000 | Training Loss: 2013244.750 | Test loss: 4867709.500\nIteration: 116200 | Training Loss: 2011905.000 | Test loss: 4864550.500\nIteration: 116400 | Training Loss: 2010566.125 | Test loss: 4861335.500\nIteration: 116600 | Training Loss: 2009228.000 | Test loss: 4858153.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 116800 | Training Loss: 2007891.375 | Test loss: 4854939.500\nIteration: 117000 | Training Loss: 2006555.625 | Test loss: 4851719.500\nIteration: 117200 | Training Loss: 2005221.000 | Test loss: 4848523.500\nIteration: 117400 | Training Loss: 2003887.000 | Test loss: 4845387.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 117600 | Training Loss: 2002554.250 | Test loss: 4842234.500\nIteration: 117800 | Training Loss: 2001222.625 | Test loss: 4838988.000\nIteration: 118000 | Training Loss: 1999891.875 | Test loss: 4835900.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 118200 | Training Loss: 1998561.750 | Test loss: 4832635.000\nIteration: 118400 | Training Loss: 1997233.250 | Test loss: 4829428.000\nIteration: 118600 | Training Loss: 1995905.375 | Test loss: 4826286.500\nIteration: 118800 | Training Loss: 1994579.000 | Test loss: 4823102.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 119000 | Training Loss: 1993253.500 | Test loss: 4819931.500\nIteration: 119200 | Training Loss: 1991929.750 | Test loss: 4816764.500\nIteration: 119400 | Training Loss: 1990608.125 | Test loss: 4813581.000\nIteration: 119600 | Training Loss: 1989288.000 | Test loss: 4810420.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 119800 | Training Loss: 1987969.500 | Test loss: 4807244.000\nIteration: 120000 | Training Loss: 1986653.875 | Test loss: 4804129.000\nIteration: 120200 | Training Loss: 1985339.250 | Test loss: 4800937.500\nIteration: 120400 | Training Loss: 1984026.125 | Test loss: 4797819.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 120600 | Training Loss: 1982714.625 | Test loss: 4794687.500\nIteration: 120800 | Training Loss: 1981404.500 | Test loss: 4791540.500\nIteration: 121000 | Training Loss: 1980095.000 | Test loss: 4788346.500\nIteration: 121200 | Training Loss: 1978786.750 | Test loss: 4785223.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 121400 | Training Loss: 1977479.125 | Test loss: 4782153.500\nIteration: 121600 | Training Loss: 1976173.000 | Test loss: 4778989.000\nIteration: 121800 | Training Loss: 1974867.500 | Test loss: 4775869.000\nIteration: 122000 | Training Loss: 1973563.125 | Test loss: 4772752.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 122200 | Training Loss: 1972259.500 | Test loss: 4769651.500\nIteration: 122400 | Training Loss: 1970957.250 | Test loss: 4766495.000\nIteration: 122600 | Training Loss: 1969655.625 | Test loss: 4763297.500\nIteration: 122800 | Training Loss: 1968355.125 | Test loss: 4760240.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 123000 | Training Loss: 1967055.500 | Test loss: 4757152.000\nIteration: 123200 | Training Loss: 1965757.250 | Test loss: 4754023.000\nIteration: 123400 | Training Loss: 1964459.500 | Test loss: 4750893.500\nIteration: 123600 | Training Loss: 1963163.000 | Test loss: 4747805.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 123800 | Training Loss: 1961867.250 | Test loss: 4744705.000\nIteration: 124000 | Training Loss: 1960573.000 | Test loss: 4741535.000\nIteration: 124200 | Training Loss: 1959279.250 | Test loss: 4738480.500\nIteration: 124400 | Training Loss: 1957986.625 | Test loss: 4735363.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 124600 | Training Loss: 1956694.750 | Test loss: 4732122.000\nIteration: 124800 | Training Loss: 1955404.375 | Test loss: 4729162.500\nIteration: 125000 | Training Loss: 1954114.625 | Test loss: 4726097.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 125200 | Training Loss: 1952826.000 | Test loss: 4722936.000\nIteration: 125400 | Training Loss: 1951538.125 | Test loss: 4719897.000\nIteration: 125600 | Training Loss: 1950251.625 | Test loss: 4716780.500\nIteration: 125800 | Training Loss: 1948965.625 | Test loss: 4713694.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 126000 | Training Loss: 1947681.000 | Test loss: 4710617.500\nIteration: 126200 | Training Loss: 1946397.125 | Test loss: 4707550.500\nIteration: 126400 | Training Loss: 1945114.500 | Test loss: 4704470.000\nIteration: 126600 | Training Loss: 1943832.625 | Test loss: 4701368.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 126800 | Training Loss: 1942551.750 | Test loss: 4698241.000\nIteration: 127000 | Training Loss: 1941271.750 | Test loss: 4695344.000\nIteration: 127200 | Training Loss: 1939993.125 | Test loss: 4692184.500\nIteration: 127400 | Training Loss: 1938715.000 | Test loss: 4689059.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 127600 | Training Loss: 1937438.250 | Test loss: 4685992.500\nIteration: 127800 | Training Loss: 1936162.000 | Test loss: 4683027.500\nIteration: 128000 | Training Loss: 1934887.375 | Test loss: 4679893.500\nIteration: 128200 | Training Loss: 1933613.250 | Test loss: 4676707.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 128400 | Training Loss: 1932340.250 | Test loss: 4673764.500\nIteration: 128600 | Training Loss: 1931068.000 | Test loss: 4670731.000\nIteration: 128800 | Training Loss: 1929797.125 | Test loss: 4667696.500\nIteration: 129000 | Training Loss: 1928526.625 | Test loss: 4664649.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 129200 | Training Loss: 1927257.500 | Test loss: 4661581.500\nIteration: 129400 | Training Loss: 1925988.875 | Test loss: 4658489.000\nIteration: 129600 | Training Loss: 1924721.875 | Test loss: 4655451.500\nIteration: 129800 | Training Loss: 1923455.375 | Test loss: 4652415.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 130000 | Training Loss: 1922189.875 | Test loss: 4649288.000\nIteration: 130200 | Training Loss: 1920925.375 | Test loss: 4646295.000\nIteration: 130400 | Training Loss: 1919662.125 | Test loss: 4643326.500\nIteration: 130600 | Training Loss: 1918399.375 | Test loss: 4640259.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 130800 | Training Loss: 1917138.000 | Test loss: 4637179.500\nIteration: 131000 | Training Loss: 1915877.125 | Test loss: 4634165.000\nIteration: 131200 | Training Loss: 1914617.750 | Test loss: 4631043.500\nIteration: 131400 | Training Loss: 1913359.000 | Test loss: 4628148.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 131600 | Training Loss: 1912101.250 | Test loss: 4625115.000\nIteration: 131800 | Training Loss: 1910844.250 | Test loss: 4622120.500\nIteration: 132000 | Training Loss: 1909588.625 | Test loss: 4619074.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 132200 | Training Loss: 1908333.500 | Test loss: 4616043.500\nIteration: 132400 | Training Loss: 1907079.625 | Test loss: 4613085.500\nIteration: 132600 | Training Loss: 1905826.250 | Test loss: 4610098.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 132800 | Training Loss: 1904574.625 | Test loss: 4607087.000\nIteration: 133000 | Training Loss: 1903323.250 | Test loss: 4604069.000\nIteration: 133200 | Training Loss: 1902073.000 | Test loss: 4601098.500\nIteration: 133400 | Training Loss: 1900823.500 | Test loss: 4598138.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 133600 | Training Loss: 1899575.125 | Test loss: 4595113.500\nIteration: 133800 | Training Loss: 1898327.250 | Test loss: 4592114.000\nIteration: 134000 | Training Loss: 1897080.375 | Test loss: 4589249.000\nIteration: 134200 | Training Loss: 1895834.000 | Test loss: 4586285.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 134400 | Training Loss: 1894588.875 | Test loss: 4583235.500\nIteration: 134600 | Training Loss: 1893344.125 | Test loss: 4580258.500\nIteration: 134800 | Training Loss: 1892100.250 | Test loss: 4577312.000\nIteration: 135000 | Training Loss: 1890857.125 | Test loss: 4574372.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 135200 | Training Loss: 1889615.125 | Test loss: 4571416.500\nIteration: 135400 | Training Loss: 1888373.500 | Test loss: 4568450.000\nIteration: 135600 | Training Loss: 1887133.000 | Test loss: 4565533.000\nIteration: 135800 | Training Loss: 1885892.875 | Test loss: 4562503.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 136000 | Training Loss: 1884654.125 | Test loss: 4559611.000\nIteration: 136200 | Training Loss: 1883415.625 | Test loss: 4556659.500\nIteration: 136400 | Training Loss: 1882178.250 | Test loss: 4553733.000\nIteration: 136600 | Training Loss: 1880941.500 | Test loss: 4550768.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 136800 | Training Loss: 1879705.875 | Test loss: 4547865.000\nIteration: 137000 | Training Loss: 1878470.625 | Test loss: 4544861.500\nIteration: 137200 | Training Loss: 1877236.500 | Test loss: 4541934.000\nIteration: 137400 | Training Loss: 1876002.875 | Test loss: 4539027.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 137600 | Training Loss: 1874770.375 | Test loss: 4536046.500\nIteration: 137800 | Training Loss: 1873538.500 | Test loss: 4533171.500\nIteration: 138000 | Training Loss: 1872307.375 | Test loss: 4530214.500\nIteration: 138200 | Training Loss: 1871077.125 | Test loss: 4527341.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 138400 | Training Loss: 1869847.875 | Test loss: 4524363.500\nIteration: 138600 | Training Loss: 1868619.125 | Test loss: 4521398.500\nIteration: 138800 | Training Loss: 1867391.375 | Test loss: 4518505.500\nIteration: 139000 | Training Loss: 1866164.125 | Test loss: 4515594.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 139200 | Training Loss: 1864938.250 | Test loss: 4512685.000\nIteration: 139400 | Training Loss: 1863712.625 | Test loss: 4509742.500\nIteration: 139600 | Training Loss: 1862488.000 | Test loss: 4506821.500\nIteration: 139800 | Training Loss: 1861264.500 | Test loss: 4503910.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 140000 | Training Loss: 1860042.250 | Test loss: 4500980.500\nIteration: 140200 | Training Loss: 1858820.375 | Test loss: 4498100.000\nIteration: 140400 | Training Loss: 1857599.500 | Test loss: 4495277.500\nIteration: 140600 | Training Loss: 1856379.250 | Test loss: 4492322.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 140800 | Training Loss: 1855160.125 | Test loss: 4489342.500\nIteration: 141000 | Training Loss: 1853941.375 | Test loss: 4486459.000\nIteration: 141200 | Training Loss: 1852723.750 | Test loss: 4483541.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 141400 | Training Loss: 1851506.750 | Test loss: 4480712.500\nIteration: 141600 | Training Loss: 1850290.875 | Test loss: 4477763.500\nIteration: 141800 | Training Loss: 1849075.500 | Test loss: 4474846.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 142000 | Training Loss: 1847861.125 | Test loss: 4471913.500\nIteration: 142200 | Training Loss: 1846647.250 | Test loss: 4469082.000\nIteration: 142400 | Training Loss: 1845434.625 | Test loss: 4466102.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 142600 | Training Loss: 1844222.500 | Test loss: 4463317.000\nIteration: 142800 | Training Loss: 1843011.375 | Test loss: 4460353.000\nIteration: 143000 | Training Loss: 1841800.750 | Test loss: 4457519.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 143200 | Training Loss: 1840591.375 | Test loss: 4454587.000\nIteration: 143400 | Training Loss: 1839382.500 | Test loss: 4451749.000\nIteration: 143600 | Training Loss: 1838174.625 | Test loss: 4448776.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 143800 | Training Loss: 1836967.250 | Test loss: 4445965.000\nIteration: 144000 | Training Loss: 1835761.125 | Test loss: 4443080.500\nIteration: 144200 | Training Loss: 1834555.375 | Test loss: 4440157.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 144400 | Training Loss: 1833350.750 | Test loss: 4437231.000\nIteration: 144600 | Training Loss: 1832146.625 | Test loss: 4434471.500\nIteration: 144800 | Training Loss: 1830943.625 | Test loss: 4431542.000\nIteration: 145000 | Training Loss: 1829741.250 | Test loss: 4428619.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 145200 | Training Loss: 1828539.750 | Test loss: 4425769.500\nIteration: 145400 | Training Loss: 1827338.875 | Test loss: 4422968.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 145600 | Training Loss: 1826139.125 | Test loss: 4420063.500\nIteration: 145800 | Training Loss: 1824939.875 | Test loss: 4417224.500\nIteration: 146000 | Training Loss: 1823741.625 | Test loss: 4414391.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 146200 | Training Loss: 1822543.875 | Test loss: 4411432.500\nIteration: 146400 | Training Loss: 1821347.375 | Test loss: 4408611.000\nIteration: 146600 | Training Loss: 1820151.375 | Test loss: 4405764.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 146800 | Training Loss: 1818956.375 | Test loss: 4402934.000\nIteration: 147000 | Training Loss: 1817761.875 | Test loss: 4399925.500\nIteration: 147200 | Training Loss: 1816568.625 | Test loss: 4397186.000\nIteration: 147400 | Training Loss: 1815375.875 | Test loss: 4394329.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 147600 | Training Loss: 1814184.125 | Test loss: 4391493.500\nIteration: 147800 | Training Loss: 1812992.750 | Test loss: 4388660.500\nIteration: 148000 | Training Loss: 1811802.875 | Test loss: 4385810.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 148200 | Training Loss: 1810613.250 | Test loss: 4382967.500\nIteration: 148400 | Training Loss: 1809424.625 | Test loss: 4380117.000\nIteration: 148600 | Training Loss: 1808236.625 | Test loss: 4377261.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 148800 | Training Loss: 1807049.750 | Test loss: 4374403.000\nIteration: 149000 | Training Loss: 1805863.375 | Test loss: 4371586.000\nIteration: 149200 | Training Loss: 1804678.000 | Test loss: 4368776.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 149400 | Training Loss: 1803493.250 | Test loss: 4365892.000\nIteration: 149600 | Training Loss: 1802309.750 | Test loss: 4363115.000\nIteration: 149800 | Training Loss: 1801126.625 | Test loss: 4360274.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 150000 | Training Loss: 1799944.500 | Test loss: 4357403.500\nIteration: 150200 | Training Loss: 1798762.875 | Test loss: 4354522.500\nIteration: 150400 | Training Loss: 1797582.500 | Test loss: 4351750.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 150600 | Training Loss: 1796402.625 | Test loss: 4348967.500\nIteration: 150800 | Training Loss: 1795223.625 | Test loss: 4346245.000\nIteration: 151000 | Training Loss: 1794045.375 | Test loss: 4343342.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 151200 | Training Loss: 1792868.250 | Test loss: 4340444.500\nIteration: 151400 | Training Loss: 1791691.500 | Test loss: 4337752.000\nIteration: 151600 | Training Loss: 1790515.750 | Test loss: 4334850.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 151800 | Training Loss: 1789340.750 | Test loss: 4332007.500\nIteration: 152000 | Training Loss: 1788166.875 | Test loss: 4329153.000\nIteration: 152200 | Training Loss: 1786993.375 | Test loss: 4326412.000\nIteration: 152400 | Training Loss: 1785820.875 | Test loss: 4323621.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 152600 | Training Loss: 1784649.000 | Test loss: 4320796.500\nIteration: 152800 | Training Loss: 1783478.375 | Test loss: 4317982.000\nIteration: 153000 | Training Loss: 1782308.000 | Test loss: 4315138.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 153200 | Training Loss: 1781138.875 | Test loss: 4312424.500\nIteration: 153400 | Training Loss: 1779970.250 | Test loss: 4309570.000\nIteration: 153600 | Training Loss: 1778802.750 | Test loss: 4306800.500\nIteration: 153800 | Training Loss: 1777635.750 | Test loss: 4304037.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 154000 | Training Loss: 1776469.750 | Test loss: 4301194.500\nIteration: 154200 | Training Loss: 1775304.375 | Test loss: 4298406.500\nIteration: 154400 | Training Loss: 1774140.000 | Test loss: 4295501.500\nIteration: 154600 | Training Loss: 1772976.250 | Test loss: 4292761.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 154800 | Training Loss: 1771813.500 | Test loss: 4289984.500\nIteration: 155000 | Training Loss: 1770651.375 | Test loss: 4287331.500\nIteration: 155200 | Training Loss: 1769490.250 | Test loss: 4284421.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 155400 | Training Loss: 1768329.750 | Test loss: 4281677.500\nIteration: 155600 | Training Loss: 1767170.125 | Test loss: 4278891.000\nIteration: 155800 | Training Loss: 1766011.125 | Test loss: 4276097.000\nIteration: 156000 | Training Loss: 1764853.375 | Test loss: 4273334.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 156200 | Training Loss: 1763696.125 | Test loss: 4270565.000\nIteration: 156400 | Training Loss: 1762539.750 | Test loss: 4267772.000\nIteration: 156600 | Training Loss: 1761384.000 | Test loss: 4264986.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 156800 | Training Loss: 1760229.375 | Test loss: 4262240.500\nIteration: 157000 | Training Loss: 1759075.375 | Test loss: 4259530.500\nIteration: 157200 | Training Loss: 1757922.125 | Test loss: 4256646.000\nIteration: 157400 | Training Loss: 1756769.625 | Test loss: 4253976.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 157600 | Training Loss: 1755618.250 | Test loss: 4251159.000\nIteration: 157800 | Training Loss: 1754467.500 | Test loss: 4248448.000\nIteration: 158000 | Training Loss: 1753317.625 | Test loss: 4245620.500\nIteration: 158200 | Training Loss: 1752168.375 | Test loss: 4242907.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 158400 | Training Loss: 1751020.125 | Test loss: 4240131.500\nIteration: 158600 | Training Loss: 1749872.500 | Test loss: 4237329.000\nIteration: 158800 | Training Loss: 1748725.875 | Test loss: 4234598.500\nIteration: 159000 | Training Loss: 1747579.875 | Test loss: 4231887.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 159200 | Training Loss: 1746435.000 | Test loss: 4229131.500\nIteration: 159400 | Training Loss: 1745290.500 | Test loss: 4226383.500\nIteration: 159600 | Training Loss: 1744147.125 | Test loss: 4223632.000\nIteration: 159800 | Training Loss: 1743004.250 | Test loss: 4220872.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 160000 | Training Loss: 1741862.625 | Test loss: 4218167.000\nIteration: 160200 | Training Loss: 1740721.500 | Test loss: 4215391.000\nIteration: 160400 | Training Loss: 1739581.250 | Test loss: 4212621.000\nIteration: 160600 | Training Loss: 1738441.625 | Test loss: 4209926.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 160800 | Training Loss: 1737303.125 | Test loss: 4207176.000\nIteration: 161000 | Training Loss: 1736165.250 | Test loss: 4204577.000\nIteration: 161200 | Training Loss: 1735028.250 | Test loss: 4201729.000\nIteration: 161400 | Training Loss: 1733891.875 | Test loss: 4198991.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 161600 | Training Loss: 1732756.625 | Test loss: 4196253.000\nIteration: 161800 | Training Loss: 1731621.875 | Test loss: 4193504.250\nIteration: 162000 | Training Loss: 1730488.125 | Test loss: 4190815.500\nIteration: 162200 | Training Loss: 1729355.000 | Test loss: 4188074.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 162400 | Training Loss: 1728223.000 | Test loss: 4185377.500\nIteration: 162600 | Training Loss: 1727091.500 | Test loss: 4182635.750\nIteration: 162800 | Training Loss: 1725960.875 | Test loss: 4179972.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 163000 | Training Loss: 1724831.000 | Test loss: 4177218.250\nIteration: 163200 | Training Loss: 1723702.250 | Test loss: 4174479.000\nIteration: 163400 | Training Loss: 1722574.000 | Test loss: 4171779.250\nIteration: 163600 | Training Loss: 1721446.625 | Test loss: 4169057.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 163800 | Training Loss: 1720320.000 | Test loss: 4166372.500\nIteration: 164000 | Training Loss: 1719194.500 | Test loss: 4163643.750\nIteration: 164200 | Training Loss: 1718069.375 | Test loss: 4160946.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 164400 | Training Loss: 1716945.375 | Test loss: 4158253.250\nIteration: 164600 | Training Loss: 1715821.875 | Test loss: 4155534.750\nIteration: 164800 | Training Loss: 1714699.625 | Test loss: 4152830.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 165000 | Training Loss: 1713577.875 | Test loss: 4150177.750\nIteration: 165200 | Training Loss: 1712457.000 | Test loss: 4147375.750\nIteration: 165400 | Training Loss: 1711336.750 | Test loss: 4144730.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 165600 | Training Loss: 1710217.625 | Test loss: 4142083.750\nIteration: 165800 | Training Loss: 1709099.125 | Test loss: 4139344.750\nIteration: 166000 | Training Loss: 1707981.500 | Test loss: 4136657.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 166200 | Training Loss: 1706864.500 | Test loss: 4133915.500\nIteration: 166400 | Training Loss: 1705748.625 | Test loss: 4131260.750\nIteration: 166600 | Training Loss: 1704633.250 | Test loss: 4128611.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 166800 | Training Loss: 1703518.875 | Test loss: 4125920.500\nIteration: 167000 | Training Loss: 1702405.125 | Test loss: 4123209.000\nIteration: 167200 | Training Loss: 1701292.500 | Test loss: 4120525.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 167400 | Training Loss: 1700180.375 | Test loss: 4117852.750\nIteration: 167600 | Training Loss: 1699069.375 | Test loss: 4115160.500\nIteration: 167800 | Training Loss: 1697958.875 | Test loss: 4112556.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 168000 | Training Loss: 1696849.625 | Test loss: 4109826.750\nIteration: 168200 | Training Loss: 1695740.750 | Test loss: 4107166.750\nIteration: 168400 | Training Loss: 1694632.875 | Test loss: 4104463.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 168600 | Training Loss: 1693525.750 | Test loss: 4101758.750\nIteration: 168800 | Training Loss: 1692419.625 | Test loss: 4099220.250\nIteration: 169000 | Training Loss: 1691314.000 | Test loss: 4096461.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 169200 | Training Loss: 1690209.375 | Test loss: 4093842.250\nIteration: 169400 | Training Loss: 1689105.375 | Test loss: 4091164.250\nIteration: 169600 | Training Loss: 1688002.500 | Test loss: 4088484.000\nIteration: 169800 | Training Loss: 1686900.125 | Test loss: 4085791.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 170000 | Training Loss: 1685798.750 | Test loss: 4083197.000\nIteration: 170200 | Training Loss: 1684698.000 | Test loss: 4080572.250\nIteration: 170400 | Training Loss: 1683598.250 | Test loss: 4077911.750\nIteration: 170600 | Training Loss: 1682499.125 | Test loss: 4075221.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 170800 | Training Loss: 1681401.000 | Test loss: 4072601.000\nIteration: 171000 | Training Loss: 1680303.375 | Test loss: 4069894.250\nIteration: 171200 | Training Loss: 1679207.000 | Test loss: 4067298.500\nIteration: 171400 | Training Loss: 1678111.000 | Test loss: 4064660.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 171600 | Training Loss: 1677016.000 | Test loss: 4062015.000\nIteration: 171800 | Training Loss: 1675921.750 | Test loss: 4059428.000\nIteration: 172000 | Training Loss: 1674828.625 | Test loss: 4056743.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 172200 | Training Loss: 1673735.875 | Test loss: 4054114.500\nIteration: 172400 | Training Loss: 1672644.250 | Test loss: 4051521.000\nIteration: 172600 | Training Loss: 1671553.125 | Test loss: 4048835.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 172800 | Training Loss: 1670463.125 | Test loss: 4046209.250\nIteration: 173000 | Training Loss: 1669373.750 | Test loss: 4043540.250\nIteration: 173200 | Training Loss: 1668285.250 | Test loss: 4041009.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 173400 | Training Loss: 1667197.375 | Test loss: 4038346.250\nIteration: 173600 | Training Loss: 1666110.625 | Test loss: 4035691.500\nIteration: 173800 | Training Loss: 1665024.500 | Test loss: 4033105.750\nIteration: 174000 | Training Loss: 1663939.125 | Test loss: 4030464.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 174200 | Training Loss: 1662854.625 | Test loss: 4027839.250\nIteration: 174400 | Training Loss: 1661771.000 | Test loss: 4025245.750\nIteration: 174600 | Training Loss: 1660688.000 | Test loss: 4022597.750\nIteration: 174800 | Training Loss: 1659606.000 | Test loss: 4019980.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 175000 | Training Loss: 1658524.625 | Test loss: 4017351.750\nIteration: 175200 | Training Loss: 1657444.375 | Test loss: 4014783.500\nIteration: 175400 | Training Loss: 1656364.500 | Test loss: 4012176.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 175600 | Training Loss: 1655285.750 | Test loss: 4009535.500\nIteration: 175800 | Training Loss: 1654207.625 | Test loss: 4006944.250\nIteration: 176000 | Training Loss: 1653130.625 | Test loss: 4004322.750\nIteration: 176200 | Training Loss: 1652054.125 | Test loss: 4001754.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 176400 | Training Loss: 1650978.625 | Test loss: 3999148.000\nIteration: 176600 | Training Loss: 1649903.750 | Test loss: 3996543.500\nIteration: 176800 | Training Loss: 1648830.000 | Test loss: 3993960.750\nIteration: 177000 | Training Loss: 1647756.750 | Test loss: 3991379.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 177200 | Training Loss: 1646684.375 | Test loss: 3988788.750\nIteration: 177400 | Training Loss: 1645612.750 | Test loss: 3986159.000\nIteration: 177600 | Training Loss: 1644542.250 | Test loss: 3983611.250\nIteration: 177800 | Training Loss: 1643472.250 | Test loss: 3980950.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 178000 | Training Loss: 1642403.125 | Test loss: 3978440.000\nIteration: 178200 | Training Loss: 1641334.750 | Test loss: 3975867.500\nIteration: 178400 | Training Loss: 1640267.375 | Test loss: 3973258.750\nIteration: 178600 | Training Loss: 1639200.625 | Test loss: 3970616.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 178800 | Training Loss: 1638134.750 | Test loss: 3968099.750\nIteration: 179000 | Training Loss: 1637069.625 | Test loss: 3965553.250\nIteration: 179200 | Training Loss: 1636005.500 | Test loss: 3962934.750\nIteration: 179400 | Training Loss: 1634941.875 | Test loss: 3960373.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 179600 | Training Loss: 1633879.250 | Test loss: 3957794.250\nIteration: 179800 | Training Loss: 1632817.250 | Test loss: 3955207.000\nIteration: 180000 | Training Loss: 1631756.375 | Test loss: 3952663.000\nIteration: 180200 | Training Loss: 1630696.125 | Test loss: 3950129.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 180400 | Training Loss: 1629636.750 | Test loss: 3947580.750\nIteration: 180600 | Training Loss: 1628578.000 | Test loss: 3944987.000\nIteration: 180800 | Training Loss: 1627520.250 | Test loss: 3942398.000\nIteration: 181000 | Training Loss: 1626463.125 | Test loss: 3939884.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 181200 | Training Loss: 1625407.000 | Test loss: 3937292.000\nIteration: 181400 | Training Loss: 1624351.500 | Test loss: 3934748.250\nIteration: 181600 | Training Loss: 1623297.000 | Test loss: 3932194.000\nIteration: 181800 | Training Loss: 1622243.125 | Test loss: 3929665.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 182000 | Training Loss: 1621190.125 | Test loss: 3927076.500\nIteration: 182200 | Training Loss: 1620137.875 | Test loss: 3924530.750\nIteration: 182400 | Training Loss: 1619086.625 | Test loss: 3922010.750\nIteration: 182600 | Training Loss: 1618035.875 | Test loss: 3919430.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 182800 | Training Loss: 1616986.250 | Test loss: 3916909.250\nIteration: 183000 | Training Loss: 1615937.125 | Test loss: 3914356.500\nIteration: 183200 | Training Loss: 1614889.125 | Test loss: 3911772.000\nIteration: 183400 | Training Loss: 1613841.625 | Test loss: 3909309.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 183600 | Training Loss: 1612795.125 | Test loss: 3906753.500\nIteration: 183800 | Training Loss: 1611749.375 | Test loss: 3904223.000\nIteration: 184000 | Training Loss: 1610704.500 | Test loss: 3901672.750\nIteration: 184200 | Training Loss: 1609660.375 | Test loss: 3899132.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 184400 | Training Loss: 1608617.000 | Test loss: 3896609.000\nIteration: 184600 | Training Loss: 1607574.375 | Test loss: 3894080.000\nIteration: 184800 | Training Loss: 1606532.750 | Test loss: 3891512.750\nIteration: 185000 | Training Loss: 1605491.875 | Test loss: 3889074.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 185200 | Training Loss: 1604451.750 | Test loss: 3886528.250\nIteration: 185400 | Training Loss: 1603412.375 | Test loss: 3883923.750\nIteration: 185600 | Training Loss: 1602374.000 | Test loss: 3881462.500\nIteration: 185800 | Training Loss: 1601336.125 | Test loss: 3878971.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 186000 | Training Loss: 1600299.250 | Test loss: 3876429.750\nIteration: 186200 | Training Loss: 1599263.125 | Test loss: 3873919.750\nIteration: 186400 | Training Loss: 1598228.000 | Test loss: 3871388.750\nIteration: 186600 | Training Loss: 1597193.500 | Test loss: 3868906.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 186800 | Training Loss: 1596159.875 | Test loss: 3866401.000\nIteration: 187000 | Training Loss: 1595126.875 | Test loss: 3863875.500\nIteration: 187200 | Training Loss: 1594095.000 | Test loss: 3861385.750\nIteration: 187400 | Training Loss: 1593063.625 | Test loss: 3858865.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 187600 | Training Loss: 1592033.250 | Test loss: 3856374.250\nIteration: 187800 | Training Loss: 1591003.625 | Test loss: 3853908.250\nIteration: 188000 | Training Loss: 1589974.875 | Test loss: 3851394.750\nIteration: 188200 | Training Loss: 1588946.875 | Test loss: 3848839.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 188400 | Training Loss: 1587919.750 | Test loss: 3846389.750\nIteration: 188600 | Training Loss: 1586893.250 | Test loss: 3843907.750\nIteration: 188800 | Training Loss: 1585867.875 | Test loss: 3841459.500\nIteration: 189000 | Training Loss: 1584843.000 | Test loss: 3838878.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 189200 | Training Loss: 1583819.125 | Test loss: 3836425.750\nIteration: 189400 | Training Loss: 1582795.875 | Test loss: 3833953.500\nIteration: 189600 | Training Loss: 1581773.625 | Test loss: 3831445.500\nIteration: 189800 | Training Loss: 1580752.000 | Test loss: 3828940.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 190000 | Training Loss: 1579731.375 | Test loss: 3826448.250\nIteration: 190200 | Training Loss: 1578711.375 | Test loss: 3824028.750\nIteration: 190400 | Training Loss: 1577692.375 | Test loss: 3821545.250\nIteration: 190600 | Training Loss: 1576673.875 | Test loss: 3819063.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 190800 | Training Loss: 1575656.500 | Test loss: 3816584.000\nIteration: 191000 | Training Loss: 1574639.750 | Test loss: 3814108.750\nIteration: 191200 | Training Loss: 1573624.000 | Test loss: 3811687.000\nIteration: 191400 | Training Loss: 1572608.750 | Test loss: 3809205.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 191600 | Training Loss: 1571594.500 | Test loss: 3806728.000\nIteration: 191800 | Training Loss: 1570581.000 | Test loss: 3804215.250\nIteration: 192000 | Training Loss: 1569568.500 | Test loss: 3801737.500\nIteration: 192200 | Training Loss: 1568556.500 | Test loss: 3799326.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 192400 | Training Loss: 1567545.500 | Test loss: 3796879.000\nIteration: 192600 | Training Loss: 1566535.125 | Test loss: 3794340.750\nIteration: 192800 | Training Loss: 1565525.875 | Test loss: 3791953.250\nIteration: 193000 | Training Loss: 1564517.125 | Test loss: 3789516.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 193200 | Training Loss: 1563509.375 | Test loss: 3787059.250\nIteration: 193400 | Training Loss: 1562502.250 | Test loss: 3784569.000\nIteration: 193600 | Training Loss: 1561496.125 | Test loss: 3782127.000\nIteration: 193800 | Training Loss: 1560490.625 | Test loss: 3779682.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 194000 | Training Loss: 1559486.000 | Test loss: 3777235.250\nIteration: 194200 | Training Loss: 1558482.250 | Test loss: 3774728.500\nIteration: 194400 | Training Loss: 1557479.250 | Test loss: 3772268.750\nIteration: 194600 | Training Loss: 1556477.125 | Test loss: 3769967.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 194800 | Training Loss: 1555475.750 | Test loss: 3767451.250\nIteration: 195000 | Training Loss: 1554475.125 | Test loss: 3765065.000\nIteration: 195200 | Training Loss: 1553475.375 | Test loss: 3762582.500\nIteration: 195400 | Training Loss: 1552476.375 | Test loss: 3760162.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 195600 | Training Loss: 1551478.250 | Test loss: 3757715.250\nIteration: 195800 | Training Loss: 1550480.875 | Test loss: 3755316.000\nIteration: 196000 | Training Loss: 1549484.375 | Test loss: 3752868.500\nIteration: 196200 | Training Loss: 1548488.500 | Test loss: 3750463.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 196400 | Training Loss: 1547493.625 | Test loss: 3748077.000\nIteration: 196600 | Training Loss: 1546499.500 | Test loss: 3745601.750\nIteration: 196800 | Training Loss: 1545506.250 | Test loss: 3743163.750\nIteration: 197000 | Training Loss: 1544513.625 | Test loss: 3740767.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 197200 | Training Loss: 1543522.000 | Test loss: 3738348.750\nIteration: 197400 | Training Loss: 1542531.000 | Test loss: 3735919.750\nIteration: 197600 | Training Loss: 1541541.000 | Test loss: 3733498.750\nIteration: 197800 | Training Loss: 1540551.625 | Test loss: 3731089.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 198000 | Training Loss: 1539563.125 | Test loss: 3728657.750\nIteration: 198200 | Training Loss: 1538575.375 | Test loss: 3726282.750\nIteration: 198400 | Training Loss: 1537588.625 | Test loss: 3723890.500\nIteration: 198600 | Training Loss: 1536602.500 | Test loss: 3721444.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 198800 | Training Loss: 1535617.375 | Test loss: 3719053.500\nIteration: 199000 | Training Loss: 1534632.875 | Test loss: 3716616.750\nIteration: 199200 | Training Loss: 1533649.375 | Test loss: 3714237.500\nIteration: 199400 | Training Loss: 1532666.500 | Test loss: 3711862.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 199600 | Training Loss: 1531684.500 | Test loss: 3709462.250\nIteration: 199800 | Training Loss: 1530703.250 | Test loss: 3707043.000\nIteration: 200000 | Training Loss: 1529723.000 | Test loss: 3704659.000\nIteration: 200200 | Training Loss: 1528743.375 | Test loss: 3702268.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 200400 | Training Loss: 1527764.625 | Test loss: 3699875.000\nIteration: 200600 | Training Loss: 1526786.625 | Test loss: 3697491.250\nIteration: 200800 | Training Loss: 1525809.500 | Test loss: 3695104.250\nIteration: 201000 | Training Loss: 1524833.000 | Test loss: 3692682.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 201200 | Training Loss: 1523857.500 | Test loss: 3690330.250\nIteration: 201400 | Training Loss: 1522882.750 | Test loss: 3687996.750\nIteration: 201600 | Training Loss: 1521908.875 | Test loss: 3685579.000\nIteration: 201800 | Training Loss: 1520935.625 | Test loss: 3683185.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 202000 | Training Loss: 1519963.375 | Test loss: 3680881.500\nIteration: 202200 | Training Loss: 1518991.750 | Test loss: 3678479.000\nIteration: 202400 | Training Loss: 1518021.125 | Test loss: 3676105.000\nIteration: 202600 | Training Loss: 1517051.125 | Test loss: 3673766.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 202800 | Training Loss: 1516082.000 | Test loss: 3671317.750\nIteration: 203000 | Training Loss: 1515113.625 | Test loss: 3668971.750\nIteration: 203200 | Training Loss: 1514146.250 | Test loss: 3666623.000\nIteration: 203400 | Training Loss: 1513179.500 | Test loss: 3664240.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 203600 | Training Loss: 1512213.625 | Test loss: 3661836.000\nIteration: 203800 | Training Loss: 1511248.500 | Test loss: 3659482.500\nIteration: 204000 | Training Loss: 1510284.375 | Test loss: 3657167.250\nIteration: 204200 | Training Loss: 1509320.750 | Test loss: 3654793.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 204400 | Training Loss: 1508358.125 | Test loss: 3652450.000\nIteration: 204600 | Training Loss: 1507396.250 | Test loss: 3650098.750\nIteration: 204800 | Training Loss: 1506435.250 | Test loss: 3647732.000\nIteration: 205000 | Training Loss: 1505475.000 | Test loss: 3645374.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 205200 | Training Loss: 1504515.625 | Test loss: 3643046.500\nIteration: 205400 | Training Loss: 1503557.000 | Test loss: 3640718.750\nIteration: 205600 | Training Loss: 1502599.375 | Test loss: 3638349.750\nIteration: 205800 | Training Loss: 1501642.375 | Test loss: 3636013.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 206000 | Training Loss: 1500686.125 | Test loss: 3633706.000\nIteration: 206200 | Training Loss: 1499730.750 | Test loss: 3631277.250\nIteration: 206400 | Training Loss: 1498776.250 | Test loss: 3628969.000\nIteration: 206600 | Training Loss: 1497822.500 | Test loss: 3626679.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 206800 | Training Loss: 1496869.625 | Test loss: 3624353.750\nIteration: 207000 | Training Loss: 1495917.375 | Test loss: 3622006.250\nIteration: 207200 | Training Loss: 1494966.125 | Test loss: 3619675.750\nIteration: 207400 | Training Loss: 1494015.625 | Test loss: 3617357.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 207600 | Training Loss: 1493065.875 | Test loss: 3614997.750\nIteration: 207800 | Training Loss: 1492117.000 | Test loss: 3612660.000\nIteration: 208000 | Training Loss: 1491169.000 | Test loss: 3610398.750\nIteration: 208200 | Training Loss: 1490221.625 | Test loss: 3608068.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 208400 | Training Loss: 1489275.250 | Test loss: 3605730.750\nIteration: 208600 | Training Loss: 1488329.500 | Test loss: 3603422.500\nIteration: 208800 | Training Loss: 1487384.625 | Test loss: 3601108.000\nIteration: 209000 | Training Loss: 1486440.500 | Test loss: 3598777.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 209200 | Training Loss: 1485497.375 | Test loss: 3596477.750\nIteration: 209400 | Training Loss: 1484554.875 | Test loss: 3594193.750\nIteration: 209600 | Training Loss: 1483613.375 | Test loss: 3591863.250\nIteration: 209800 | Training Loss: 1482672.500 | Test loss: 3589552.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 210000 | Training Loss: 1481732.500 | Test loss: 3587176.250\nIteration: 210200 | Training Loss: 1480793.250 | Test loss: 3584961.500\nIteration: 210400 | Training Loss: 1479855.000 | Test loss: 3582667.500\nIteration: 210600 | Training Loss: 1478917.250 | Test loss: 3580356.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 210800 | Training Loss: 1477980.500 | Test loss: 3578055.500\nIteration: 211000 | Training Loss: 1477044.500 | Test loss: 3575765.000\nIteration: 211200 | Training Loss: 1476109.375 | Test loss: 3573451.500\nIteration: 211400 | Training Loss: 1475175.000 | Test loss: 3571151.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 211600 | Training Loss: 1474241.375 | Test loss: 3568902.750\nIteration: 211800 | Training Loss: 1473308.625 | Test loss: 3566607.500\nIteration: 212000 | Training Loss: 1472376.750 | Test loss: 3564318.500\nIteration: 212200 | Training Loss: 1471445.500 | Test loss: 3561989.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 212400 | Training Loss: 1470515.250 | Test loss: 3559739.000\nIteration: 212600 | Training Loss: 1469585.625 | Test loss: 3557488.250\nIteration: 212800 | Training Loss: 1468657.125 | Test loss: 3555217.750\nIteration: 213000 | Training Loss: 1467729.125 | Test loss: 3552909.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 213200 | Training Loss: 1466802.000 | Test loss: 3550582.250\nIteration: 213400 | Training Loss: 1465875.625 | Test loss: 3548352.500\nIteration: 213600 | Training Loss: 1464950.250 | Test loss: 3546085.250\nIteration: 213800 | Training Loss: 1464025.500 | Test loss: 3543790.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 214000 | Training Loss: 1463101.625 | Test loss: 3541549.250\nIteration: 214200 | Training Loss: 1462178.375 | Test loss: 3539263.500\nIteration: 214400 | Training Loss: 1461256.250 | Test loss: 3537033.500\nIteration: 214600 | Training Loss: 1460334.750 | Test loss: 3534762.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 214800 | Training Loss: 1459414.125 | Test loss: 3532466.250\nIteration: 215000 | Training Loss: 1458494.250 | Test loss: 3530230.750\nIteration: 215200 | Training Loss: 1457575.250 | Test loss: 3527976.000\nIteration: 215400 | Training Loss: 1456657.000 | Test loss: 3525704.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 215600 | Training Loss: 1455739.500 | Test loss: 3523460.750\nIteration: 215800 | Training Loss: 1454822.875 | Test loss: 3521197.000\nIteration: 216000 | Training Loss: 1453907.125 | Test loss: 3518943.500\nIteration: 216200 | Training Loss: 1452992.000 | Test loss: 3516708.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 216400 | Training Loss: 1452077.875 | Test loss: 3514424.250\nIteration: 216600 | Training Loss: 1451164.375 | Test loss: 3512234.250\nIteration: 216800 | Training Loss: 1450251.750 | Test loss: 3509967.000\nIteration: 217000 | Training Loss: 1449339.875 | Test loss: 3507763.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 217200 | Training Loss: 1448429.000 | Test loss: 3505477.500\nIteration: 217400 | Training Loss: 1447518.750 | Test loss: 3503268.000\nIteration: 217600 | Training Loss: 1446609.250 | Test loss: 3501035.000\nIteration: 217800 | Training Loss: 1445700.750 | Test loss: 3498769.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 218000 | Training Loss: 1444792.875 | Test loss: 3496524.750\nIteration: 218200 | Training Loss: 1443885.875 | Test loss: 3494299.500\nIteration: 218400 | Training Loss: 1442979.875 | Test loss: 3492038.000\nIteration: 218600 | Training Loss: 1442074.375 | Test loss: 3489847.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 218800 | Training Loss: 1441169.875 | Test loss: 3487619.000\nIteration: 219000 | Training Loss: 1440266.000 | Test loss: 3485336.000\nIteration: 219200 | Training Loss: 1439363.250 | Test loss: 3483207.250\nIteration: 219400 | Training Loss: 1438461.000 | Test loss: 3481055.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 219600 | Training Loss: 1437559.750 | Test loss: 3478764.750\nIteration: 219800 | Training Loss: 1436659.125 | Test loss: 3476483.250\nIteration: 220000 | Training Loss: 1435759.500 | Test loss: 3474317.500\nIteration: 220200 | Training Loss: 1434860.500 | Test loss: 3472115.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 220400 | Training Loss: 1433962.375 | Test loss: 3469903.000\nIteration: 220600 | Training Loss: 1433065.000 | Test loss: 3467755.750\nIteration: 220800 | Training Loss: 1432168.625 | Test loss: 3465487.250\nIteration: 221000 | Training Loss: 1431272.875 | Test loss: 3463332.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 221200 | Training Loss: 1430378.000 | Test loss: 3461041.750\nIteration: 221400 | Training Loss: 1429483.750 | Test loss: 3458868.250\nIteration: 221600 | Training Loss: 1428590.625 | Test loss: 3456675.500\nIteration: 221800 | Training Loss: 1427698.000 | Test loss: 3454472.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 222000 | Training Loss: 1426806.375 | Test loss: 3452296.250\nIteration: 222200 | Training Loss: 1425915.500 | Test loss: 3450096.500\nIteration: 222400 | Training Loss: 1425025.500 | Test loss: 3447898.250\nIteration: 222600 | Training Loss: 1424136.000 | Test loss: 3445685.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 222800 | Training Loss: 1423247.625 | Test loss: 3443521.500\nIteration: 223000 | Training Loss: 1422359.875 | Test loss: 3441328.500\nIteration: 223200 | Training Loss: 1421473.125 | Test loss: 3439146.750\nIteration: 223400 | Training Loss: 1420587.000 | Test loss: 3436974.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 223600 | Training Loss: 1419701.750 | Test loss: 3434800.750\nIteration: 223800 | Training Loss: 1418817.250 | Test loss: 3432673.250\nIteration: 224000 | Training Loss: 1417933.625 | Test loss: 3430443.500\nIteration: 224200 | Training Loss: 1417050.750 | Test loss: 3428253.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 224400 | Training Loss: 1416168.750 | Test loss: 3426056.500\nIteration: 224600 | Training Loss: 1415287.500 | Test loss: 3423913.750\nIteration: 224800 | Training Loss: 1414407.125 | Test loss: 3421749.750\nIteration: 225000 | Training Loss: 1413527.375 | Test loss: 3419590.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 225200 | Training Loss: 1412648.500 | Test loss: 3417432.750\nIteration: 225400 | Training Loss: 1411770.500 | Test loss: 3415250.750\nIteration: 225600 | Training Loss: 1410893.375 | Test loss: 3413105.500\nIteration: 225800 | Training Loss: 1410016.875 | Test loss: 3410925.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 226000 | Training Loss: 1409141.250 | Test loss: 3408787.500\nIteration: 226200 | Training Loss: 1408266.375 | Test loss: 3406625.500\nIteration: 226400 | Training Loss: 1407392.375 | Test loss: 3404485.250\nIteration: 226600 | Training Loss: 1406519.125 | Test loss: 3402334.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 226800 | Training Loss: 1405646.625 | Test loss: 3400191.500\nIteration: 227000 | Training Loss: 1404775.000 | Test loss: 3398001.000\nIteration: 227200 | Training Loss: 1403904.250 | Test loss: 3395890.250\nIteration: 227400 | Training Loss: 1403034.250 | Test loss: 3393728.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 227600 | Training Loss: 1402165.000 | Test loss: 3391604.750\nIteration: 227800 | Training Loss: 1401296.625 | Test loss: 3389480.250\nIteration: 228000 | Training Loss: 1400429.000 | Test loss: 3387368.250\nIteration: 228200 | Training Loss: 1399562.125 | Test loss: 3385237.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 228400 | Training Loss: 1398696.125 | Test loss: 3383152.750\nIteration: 228600 | Training Loss: 1397830.875 | Test loss: 3380964.500\nIteration: 228800 | Training Loss: 1396966.500 | Test loss: 3378762.000\nIteration: 229000 | Training Loss: 1396102.750 | Test loss: 3376726.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 229200 | Training Loss: 1395240.000 | Test loss: 3374634.500\nIteration: 229400 | Training Loss: 1394377.875 | Test loss: 3372505.000\nIteration: 229600 | Training Loss: 1393516.750 | Test loss: 3370396.250\nIteration: 229800 | Training Loss: 1392656.250 | Test loss: 3368285.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 230000 | Training Loss: 1391796.625 | Test loss: 3366193.000\nIteration: 230200 | Training Loss: 1390937.625 | Test loss: 3364135.500\nIteration: 230400 | Training Loss: 1390079.625 | Test loss: 3361980.500\nIteration: 230600 | Training Loss: 1389222.375 | Test loss: 3359913.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 230800 | Training Loss: 1388365.875 | Test loss: 3357872.250\nIteration: 231000 | Training Loss: 1387510.125 | Test loss: 3355755.500\nIteration: 231200 | Training Loss: 1386655.250 | Test loss: 3353689.500\nIteration: 231400 | Training Loss: 1385801.000 | Test loss: 3351613.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 231600 | Training Loss: 1384947.625 | Test loss: 3349562.750\nIteration: 231800 | Training Loss: 1384095.000 | Test loss: 3347531.250\nIteration: 232000 | Training Loss: 1383243.250 | Test loss: 3345472.250\nIteration: 232200 | Training Loss: 1382392.125 | Test loss: 3343433.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 232400 | Training Loss: 1381541.750 | Test loss: 3341408.750\nIteration: 232600 | Training Loss: 1380692.250 | Test loss: 3339422.250\nIteration: 232800 | Training Loss: 1379843.625 | Test loss: 3337410.250\nIteration: 233000 | Training Loss: 1378995.500 | Test loss: 3335424.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 233200 | Training Loss: 1378148.250 | Test loss: 3333430.250\nIteration: 233400 | Training Loss: 1377301.875 | Test loss: 3331477.250\nIteration: 233600 | Training Loss: 1376456.125 | Test loss: 3329461.500\nIteration: 233800 | Training Loss: 1375611.125 | Test loss: 3327466.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 234000 | Training Loss: 1374767.000 | Test loss: 3325461.250\nIteration: 234200 | Training Loss: 1373923.625 | Test loss: 3323475.750\nIteration: 234400 | Training Loss: 1373081.125 | Test loss: 3321543.500\nIteration: 234600 | Training Loss: 1372239.125 | Test loss: 3319533.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 234800 | Training Loss: 1371398.125 | Test loss: 3317588.500\nIteration: 235000 | Training Loss: 1370557.750 | Test loss: 3315636.000\nIteration: 235200 | Training Loss: 1369718.375 | Test loss: 3313679.250\nIteration: 235400 | Training Loss: 1368879.500 | Test loss: 3311715.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 235600 | Training Loss: 1368041.625 | Test loss: 3309783.750\nIteration: 235800 | Training Loss: 1367204.375 | Test loss: 3307774.750\nIteration: 236000 | Training Loss: 1366368.000 | Test loss: 3305830.000\nIteration: 236200 | Training Loss: 1365532.250 | Test loss: 3303883.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 236400 | Training Loss: 1364697.375 | Test loss: 3301973.500\nIteration: 236600 | Training Loss: 1363863.250 | Test loss: 3299976.750\nIteration: 236800 | Training Loss: 1363030.000 | Test loss: 3298025.750\nIteration: 237000 | Training Loss: 1362197.250 | Test loss: 3296077.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 237200 | Training Loss: 1361365.500 | Test loss: 3294135.750\nIteration: 237400 | Training Loss: 1360534.375 | Test loss: 3292207.500\nIteration: 237600 | Training Loss: 1359704.125 | Test loss: 3290259.750\nIteration: 237800 | Training Loss: 1358874.500 | Test loss: 3288308.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 238000 | Training Loss: 1358045.750 | Test loss: 3286361.750\nIteration: 238200 | Training Loss: 1357217.625 | Test loss: 3284445.250\nIteration: 238400 | Training Loss: 1356390.500 | Test loss: 3282515.000\nIteration: 238600 | Training Loss: 1355563.875 | Test loss: 3280562.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 238800 | Training Loss: 1354738.125 | Test loss: 3278666.000\nIteration: 239000 | Training Loss: 1353913.125 | Test loss: 3276733.750\nIteration: 239200 | Training Loss: 1353089.000 | Test loss: 3274785.000\nIteration: 239400 | Training Loss: 1352265.375 | Test loss: 3272899.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 239600 | Training Loss: 1351442.875 | Test loss: 3270977.500\nIteration: 239800 | Training Loss: 1350620.875 | Test loss: 3269063.500\nIteration: 240000 | Training Loss: 1349799.625 | Test loss: 3267164.000\nIteration: 240200 | Training Loss: 1348979.250 | Test loss: 3265237.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 240400 | Training Loss: 1348159.625 | Test loss: 3263349.500\nIteration: 240600 | Training Loss: 1347340.625 | Test loss: 3261478.750\nIteration: 240800 | Training Loss: 1346522.625 | Test loss: 3259607.000\nIteration: 241000 | Training Loss: 1345705.125 | Test loss: 3257688.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 241200 | Training Loss: 1344888.500 | Test loss: 3255772.500\nIteration: 241400 | Training Loss: 1344072.500 | Test loss: 3253921.500\nIteration: 241600 | Training Loss: 1343257.500 | Test loss: 3252046.000\nIteration: 241800 | Training Loss: 1342443.000 | Test loss: 3250198.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 242000 | Training Loss: 1341629.375 | Test loss: 3248334.750\nIteration: 242200 | Training Loss: 1340816.375 | Test loss: 3246452.250\nIteration: 242400 | Training Loss: 1340004.250 | Test loss: 3244602.000\nIteration: 242600 | Training Loss: 1339192.750 | Test loss: 3242733.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 242800 | Training Loss: 1338382.125 | Test loss: 3240881.250\nIteration: 243000 | Training Loss: 1337572.125 | Test loss: 3239026.250\nIteration: 243200 | Training Loss: 1336763.000 | Test loss: 3237168.750\nIteration: 243400 | Training Loss: 1335954.500 | Test loss: 3235344.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 243600 | Training Loss: 1335146.750 | Test loss: 3233503.000\nIteration: 243800 | Training Loss: 1334339.875 | Test loss: 3231665.250\nIteration: 244000 | Training Loss: 1333533.750 | Test loss: 3229850.250\nIteration: 244200 | Training Loss: 1332728.250 | Test loss: 3227978.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 244400 | Training Loss: 1331923.500 | Test loss: 3226180.500\nIteration: 244600 | Training Loss: 1331119.500 | Test loss: 3224339.750\nIteration: 244800 | Training Loss: 1330316.375 | Test loss: 3222490.000\nIteration: 245000 | Training Loss: 1329513.875 | Test loss: 3220681.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 245200 | Training Loss: 1328712.125 | Test loss: 3218830.500\nIteration: 245400 | Training Loss: 1327911.250 | Test loss: 3217025.500\nIteration: 245600 | Training Loss: 1327111.000 | Test loss: 3215167.500\nIteration: 245800 | Training Loss: 1326311.500 | Test loss: 3213347.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 246000 | Training Loss: 1325512.750 | Test loss: 3211546.750\nIteration: 246200 | Training Loss: 1324714.750 | Test loss: 3209712.000\nIteration: 246400 | Training Loss: 1323917.625 | Test loss: 3207880.250\nIteration: 246600 | Training Loss: 1323121.000 | Test loss: 3206121.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 246800 | Training Loss: 1322325.375 | Test loss: 3204261.250\nIteration: 247000 | Training Loss: 1321530.250 | Test loss: 3202405.250\nIteration: 247200 | Training Loss: 1320736.125 | Test loss: 3200606.500\nIteration: 247400 | Training Loss: 1319942.500 | Test loss: 3198782.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 247600 | Training Loss: 1319149.750 | Test loss: 3196975.000\nIteration: 247800 | Training Loss: 1318357.500 | Test loss: 3195197.000\nIteration: 248000 | Training Loss: 1317565.500 | Test loss: 3193393.000\nIteration: 248200 | Training Loss: 1316773.625 | Test loss: 3191524.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 248400 | Training Loss: 1315982.000 | Test loss: 3189721.750\nIteration: 248600 | Training Loss: 1315189.000 | Test loss: 3187911.000\nIteration: 248800 | Training Loss: 1314396.625 | Test loss: 3186112.500\nIteration: 249000 | Training Loss: 1313602.625 | Test loss: 3184299.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 249200 | Training Loss: 1312809.125 | Test loss: 3182480.750\nIteration: 249400 | Training Loss: 1312016.250 | Test loss: 3180623.750\nIteration: 249600 | Training Loss: 1311223.125 | Test loss: 3178817.500\nIteration: 249800 | Training Loss: 1310430.500 | Test loss: 3177039.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 250000 | Training Loss: 1309638.625 | Test loss: 3175207.500\nIteration: 250200 | Training Loss: 1308847.625 | Test loss: 3173399.750\nIteration: 250400 | Training Loss: 1308057.125 | Test loss: 3171587.250\nIteration: 250600 | Training Loss: 1307267.625 | Test loss: 3169787.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 250800 | Training Loss: 1306478.750 | Test loss: 3167992.000\nIteration: 251000 | Training Loss: 1305690.750 | Test loss: 3166195.250\nIteration: 251200 | Training Loss: 1304903.375 | Test loss: 3164396.750\nIteration: 251400 | Training Loss: 1304116.875 | Test loss: 3162548.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 251600 | Training Loss: 1303331.125 | Test loss: 3160777.000\nIteration: 251800 | Training Loss: 1302546.125 | Test loss: 3158933.500\nIteration: 252000 | Training Loss: 1301761.750 | Test loss: 3157209.250\nIteration: 252200 | Training Loss: 1300978.250 | Test loss: 3155437.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 252400 | Training Loss: 1300195.500 | Test loss: 3153575.250\nIteration: 252600 | Training Loss: 1299413.500 | Test loss: 3151779.000\nIteration: 252800 | Training Loss: 1298632.250 | Test loss: 3149981.750\nIteration: 253000 | Training Loss: 1297851.875 | Test loss: 3148215.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 253200 | Training Loss: 1297072.000 | Test loss: 3146470.250\nIteration: 253400 | Training Loss: 1296293.125 | Test loss: 3144700.250\nIteration: 253600 | Training Loss: 1295514.875 | Test loss: 3142851.250\nIteration: 253800 | Training Loss: 1294737.500 | Test loss: 3141058.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 254000 | Training Loss: 1293960.625 | Test loss: 3139281.000\nIteration: 254200 | Training Loss: 1293184.875 | Test loss: 3137520.500\nIteration: 254400 | Training Loss: 1292409.625 | Test loss: 3135736.250\nIteration: 254600 | Training Loss: 1291635.250 | Test loss: 3133966.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 254800 | Training Loss: 1290861.500 | Test loss: 3132189.000\nIteration: 255000 | Training Loss: 1290088.625 | Test loss: 3130355.000\nIteration: 255200 | Training Loss: 1289316.500 | Test loss: 3128610.750\nIteration: 255400 | Training Loss: 1288545.000 | Test loss: 3126871.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 255600 | Training Loss: 1287774.375 | Test loss: 3125113.750\nIteration: 255800 | Training Loss: 1287004.625 | Test loss: 3123297.750\nIteration: 256000 | Training Loss: 1286235.625 | Test loss: 3121550.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 256200 | Training Loss: 1285467.375 | Test loss: 3119798.750\nIteration: 256400 | Training Loss: 1284699.875 | Test loss: 3118005.750\nIteration: 256600 | Training Loss: 1283933.375 | Test loss: 3116249.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 256800 | Training Loss: 1283167.500 | Test loss: 3114472.000\nIteration: 257000 | Training Loss: 1282402.375 | Test loss: 3112747.250\nIteration: 257200 | Training Loss: 1281638.000 | Test loss: 3110963.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 257400 | Training Loss: 1280874.375 | Test loss: 3109259.000\nIteration: 257600 | Training Loss: 1280111.500 | Test loss: 3107469.000\nIteration: 257800 | Training Loss: 1279349.500 | Test loss: 3105653.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 258000 | Training Loss: 1278588.125 | Test loss: 3103954.750\nIteration: 258200 | Training Loss: 1277827.500 | Test loss: 3102203.500\nIteration: 258400 | Training Loss: 1277067.750 | Test loss: 3100435.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 258600 | Training Loss: 1276308.625 | Test loss: 3098697.500\nIteration: 258800 | Training Loss: 1275550.250 | Test loss: 3096970.750\nIteration: 259000 | Training Loss: 1274792.875 | Test loss: 3095259.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 259200 | Training Loss: 1274036.000 | Test loss: 3093464.000\nIteration: 259400 | Training Loss: 1273280.000 | Test loss: 3091703.750\nIteration: 259600 | Training Loss: 1272524.625 | Test loss: 3089981.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 259800 | Training Loss: 1271770.125 | Test loss: 3088241.500\nIteration: 260000 | Training Loss: 1271016.375 | Test loss: 3086514.750\nIteration: 260200 | Training Loss: 1270263.375 | Test loss: 3084779.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 260400 | Training Loss: 1269511.125 | Test loss: 3083007.000\nIteration: 260600 | Training Loss: 1268759.625 | Test loss: 3081364.750\nIteration: 260800 | Training Loss: 1268008.875 | Test loss: 3079566.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 261000 | Training Loss: 1267258.875 | Test loss: 3077857.000\nIteration: 261200 | Training Loss: 1266509.625 | Test loss: 3076053.000\nIteration: 261400 | Training Loss: 1265761.250 | Test loss: 3074383.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 261600 | Training Loss: 1265013.500 | Test loss: 3072602.500\nIteration: 261800 | Training Loss: 1264266.250 | Test loss: 3070941.000\nIteration: 262000 | Training Loss: 1263519.625 | Test loss: 3069200.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 262200 | Training Loss: 1262773.875 | Test loss: 3067449.250\nIteration: 262400 | Training Loss: 1262028.750 | Test loss: 3065742.250\nIteration: 262600 | Training Loss: 1261284.500 | Test loss: 3064045.250\nIteration: 262800 | Training Loss: 1260540.875 | Test loss: 3062337.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 263000 | Training Loss: 1259798.125 | Test loss: 3060611.500\nIteration: 263200 | Training Loss: 1259056.125 | Test loss: 3058887.250\nIteration: 263400 | Training Loss: 1258314.875 | Test loss: 3057168.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 263600 | Training Loss: 1257574.375 | Test loss: 3055496.750\nIteration: 263800 | Training Loss: 1256834.625 | Test loss: 3053754.250\nIteration: 264000 | Training Loss: 1256095.625 | Test loss: 3052053.500\nIteration: 264200 | Training Loss: 1255357.375 | Test loss: 3050330.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 264400 | Training Loss: 1254619.875 | Test loss: 3048635.500\nIteration: 264600 | Training Loss: 1253883.125 | Test loss: 3046919.250\nIteration: 264800 | Training Loss: 1253147.125 | Test loss: 3045222.000\nIteration: 265000 | Training Loss: 1252412.000 | Test loss: 3043518.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 265200 | Training Loss: 1251677.500 | Test loss: 3041819.500\nIteration: 265400 | Training Loss: 1250943.875 | Test loss: 3040153.250\nIteration: 265600 | Training Loss: 1250210.875 | Test loss: 3038409.000\nIteration: 265800 | Training Loss: 1249478.625 | Test loss: 3036751.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 266000 | Training Loss: 1248747.250 | Test loss: 3034997.500\nIteration: 266200 | Training Loss: 1248016.625 | Test loss: 3033311.250\nIteration: 266400 | Training Loss: 1247286.625 | Test loss: 3031591.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 266600 | Training Loss: 1246557.500 | Test loss: 3029968.250\nIteration: 266800 | Training Loss: 1245829.125 | Test loss: 3028278.000\nIteration: 267000 | Training Loss: 1245101.500 | Test loss: 3026615.000\nIteration: 267200 | Training Loss: 1244374.625 | Test loss: 3024891.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 267400 | Training Loss: 1243648.500 | Test loss: 3023222.250\nIteration: 267600 | Training Loss: 1242923.125 | Test loss: 3021565.750\nIteration: 267800 | Training Loss: 1242198.500 | Test loss: 3019807.000\nIteration: 268000 | Training Loss: 1241474.625 | Test loss: 3018203.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 268200 | Training Loss: 1240752.625 | Test loss: 3016512.000\nIteration: 268400 | Training Loss: 1240031.500 | Test loss: 3014836.000\nIteration: 268600 | Training Loss: 1239311.250 | Test loss: 3013192.250\nIteration: 268800 | Training Loss: 1238591.625 | Test loss: 3011478.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 269000 | Training Loss: 1237872.500 | Test loss: 3009819.500\nIteration: 269200 | Training Loss: 1237154.000 | Test loss: 3008160.750\nIteration: 269400 | Training Loss: 1236436.500 | Test loss: 3006486.250\nIteration: 269600 | Training Loss: 1235719.875 | Test loss: 3004825.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 269800 | Training Loss: 1235003.875 | Test loss: 3003176.250\nIteration: 270000 | Training Loss: 1234288.625 | Test loss: 3001519.000\nIteration: 270200 | Training Loss: 1233574.125 | Test loss: 2999862.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 270400 | Training Loss: 1232860.500 | Test loss: 2998222.500\nIteration: 270600 | Training Loss: 1232147.625 | Test loss: 2996556.000\nIteration: 270800 | Training Loss: 1231435.375 | Test loss: 2994897.500\nIteration: 271000 | Training Loss: 1230724.000 | Test loss: 2993250.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 271200 | Training Loss: 1230013.250 | Test loss: 2991608.500\nIteration: 271400 | Training Loss: 1229303.500 | Test loss: 2989986.750\nIteration: 271600 | Training Loss: 1228594.375 | Test loss: 2988362.500\nIteration: 271800 | Training Loss: 1227885.875 | Test loss: 2986619.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 272000 | Training Loss: 1227178.250 | Test loss: 2985027.750\nIteration: 272200 | Training Loss: 1226471.375 | Test loss: 2983384.500\nIteration: 272400 | Training Loss: 1225765.250 | Test loss: 2981780.000\nIteration: 272600 | Training Loss: 1225059.875 | Test loss: 2980115.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 272800 | Training Loss: 1224355.250 | Test loss: 2978476.000\nIteration: 273000 | Training Loss: 1223651.250 | Test loss: 2976850.000\nIteration: 273200 | Training Loss: 1222948.125 | Test loss: 2975203.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 273400 | Training Loss: 1222245.750 | Test loss: 2973567.000\nIteration: 273600 | Training Loss: 1221544.125 | Test loss: 2971953.500\nIteration: 273800 | Training Loss: 1220843.250 | Test loss: 2970312.000\nIteration: 274000 | Training Loss: 1220143.125 | Test loss: 2968690.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 274200 | Training Loss: 1219443.625 | Test loss: 2967085.000\nIteration: 274400 | Training Loss: 1218745.000 | Test loss: 2965457.250\nIteration: 274600 | Training Loss: 1218047.250 | Test loss: 2963804.250\nIteration: 274800 | Training Loss: 1217350.125 | Test loss: 2962234.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 275000 | Training Loss: 1216653.625 | Test loss: 2960639.500\nIteration: 275200 | Training Loss: 1215958.000 | Test loss: 2959008.000\nIteration: 275400 | Training Loss: 1215263.125 | Test loss: 2957360.000\nIteration: 275600 | Training Loss: 1214569.000 | Test loss: 2955777.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 275800 | Training Loss: 1213875.625 | Test loss: 2954177.750\nIteration: 276000 | Training Loss: 1213182.875 | Test loss: 2952565.250\nIteration: 276200 | Training Loss: 1212491.000 | Test loss: 2950960.500\nIteration: 276400 | Training Loss: 1211799.875 | Test loss: 2949369.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 276600 | Training Loss: 1211109.500 | Test loss: 2947802.500\nIteration: 276800 | Training Loss: 1210419.750 | Test loss: 2946185.000\nIteration: 277000 | Training Loss: 1209730.875 | Test loss: 2944578.750\nIteration: 277200 | Training Loss: 1209042.750 | Test loss: 2943071.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 277400 | Training Loss: 1208355.250 | Test loss: 2941456.750\nIteration: 277600 | Training Loss: 1207668.500 | Test loss: 2939857.750\nIteration: 277800 | Training Loss: 1206982.625 | Test loss: 2938293.000\nIteration: 278000 | Training Loss: 1206297.375 | Test loss: 2936696.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 278200 | Training Loss: 1205612.875 | Test loss: 2935156.500\nIteration: 278400 | Training Loss: 1204929.125 | Test loss: 2933596.750\nIteration: 278600 | Training Loss: 1204246.125 | Test loss: 2932025.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 278800 | Training Loss: 1203563.875 | Test loss: 2930471.250\nIteration: 279000 | Training Loss: 1202882.375 | Test loss: 2928929.000\nIteration: 279200 | Training Loss: 1202201.625 | Test loss: 2927379.000\nIteration: 279400 | Training Loss: 1201521.500 | Test loss: 2925847.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 279600 | Training Loss: 1200842.125 | Test loss: 2924324.500\nIteration: 279800 | Training Loss: 1200163.625 | Test loss: 2922774.000\nIteration: 280000 | Training Loss: 1199485.875 | Test loss: 2921234.000\nIteration: 280200 | Training Loss: 1198808.750 | Test loss: 2919715.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 280400 | Training Loss: 1198132.375 | Test loss: 2918191.500\nIteration: 280600 | Training Loss: 1197456.750 | Test loss: 2916670.250\nIteration: 280800 | Training Loss: 1196781.750 | Test loss: 2915144.750\nIteration: 281000 | Training Loss: 1196107.625 | Test loss: 2913607.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 281200 | Training Loss: 1195434.250 | Test loss: 2912076.750\nIteration: 281400 | Training Loss: 1194761.625 | Test loss: 2910590.250\nIteration: 281600 | Training Loss: 1194089.750 | Test loss: 2909097.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 281800 | Training Loss: 1193418.625 | Test loss: 2907517.750\nIteration: 282000 | Training Loss: 1192748.250 | Test loss: 2906026.250\nIteration: 282200 | Training Loss: 1192078.500 | Test loss: 2904509.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 282400 | Training Loss: 1191409.625 | Test loss: 2903005.500\nIteration: 282600 | Training Loss: 1190741.375 | Test loss: 2901471.000\nIteration: 282800 | Training Loss: 1190074.125 | Test loss: 2899965.500\nIteration: 283000 | Training Loss: 1189407.375 | Test loss: 2898491.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 283200 | Training Loss: 1188741.500 | Test loss: 2896923.000\nIteration: 283400 | Training Loss: 1188076.375 | Test loss: 2895432.500\nIteration: 283600 | Training Loss: 1187412.000 | Test loss: 2893898.250\nIteration: 283800 | Training Loss: 1186748.250 | Test loss: 2892454.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 284000 | Training Loss: 1186085.375 | Test loss: 2890889.250\nIteration: 284200 | Training Loss: 1185423.125 | Test loss: 2889414.500\nIteration: 284400 | Training Loss: 1184761.750 | Test loss: 2887914.750\nIteration: 284600 | Training Loss: 1184101.000 | Test loss: 2886392.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 284800 | Training Loss: 1183441.000 | Test loss: 2884904.000\nIteration: 285000 | Training Loss: 1182781.750 | Test loss: 2883400.250\nIteration: 285200 | Training Loss: 1182123.250 | Test loss: 2881906.250\nIteration: 285400 | Training Loss: 1181465.375 | Test loss: 2880439.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 285600 | Training Loss: 1180808.375 | Test loss: 2878899.250\nIteration: 285800 | Training Loss: 1180152.000 | Test loss: 2877423.750\nIteration: 286000 | Training Loss: 1179496.500 | Test loss: 2875901.500\nIteration: 286200 | Training Loss: 1178841.625 | Test loss: 2874437.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 286400 | Training Loss: 1178187.625 | Test loss: 2872951.500\nIteration: 286600 | Training Loss: 1177534.250 | Test loss: 2871468.500\nIteration: 286800 | Training Loss: 1176881.625 | Test loss: 2869966.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 287000 | Training Loss: 1176229.750 | Test loss: 2868505.750\nIteration: 287200 | Training Loss: 1175578.625 | Test loss: 2867010.000\nIteration: 287400 | Training Loss: 1174928.125 | Test loss: 2865516.000\nIteration: 287600 | Training Loss: 1174278.500 | Test loss: 2864032.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 287800 | Training Loss: 1173629.625 | Test loss: 2862555.000\nIteration: 288000 | Training Loss: 1172981.375 | Test loss: 2861100.750\nIteration: 288200 | Training Loss: 1172333.875 | Test loss: 2859627.500\nIteration: 288400 | Training Loss: 1171687.125 | Test loss: 2858094.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 288600 | Training Loss: 1171041.125 | Test loss: 2856608.000\nIteration: 288800 | Training Loss: 1170395.875 | Test loss: 2855167.250\nIteration: 289000 | Training Loss: 1169751.375 | Test loss: 2853739.500\nIteration: 289200 | Training Loss: 1169107.500 | Test loss: 2852231.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 289400 | Training Loss: 1168464.500 | Test loss: 2850762.750\nIteration: 289600 | Training Loss: 1167822.250 | Test loss: 2849304.000\nIteration: 289800 | Training Loss: 1167180.625 | Test loss: 2847813.500\nIteration: 290000 | Training Loss: 1166539.875 | Test loss: 2846359.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 290200 | Training Loss: 1165900.000 | Test loss: 2844897.750\nIteration: 290400 | Training Loss: 1165261.000 | Test loss: 2843439.500\nIteration: 290600 | Training Loss: 1164622.625 | Test loss: 2841953.750\nIteration: 290800 | Training Loss: 1163985.000 | Test loss: 2840520.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 291000 | Training Loss: 1163348.125 | Test loss: 2839043.250\nIteration: 291200 | Training Loss: 1162712.125 | Test loss: 2837587.250\nIteration: 291400 | Training Loss: 1162076.750 | Test loss: 2836146.000\nIteration: 291600 | Training Loss: 1161442.000 | Test loss: 2834682.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 291800 | Training Loss: 1160808.125 | Test loss: 2833226.000\nIteration: 292000 | Training Loss: 1160174.875 | Test loss: 2831743.500\nIteration: 292200 | Training Loss: 1159542.375 | Test loss: 2830361.000\nIteration: 292400 | Training Loss: 1158910.750 | Test loss: 2828871.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 292600 | Training Loss: 1158279.750 | Test loss: 2827460.000\nIteration: 292800 | Training Loss: 1157649.500 | Test loss: 2825983.250\nIteration: 293000 | Training Loss: 1157019.875 | Test loss: 2824532.000\nIteration: 293200 | Training Loss: 1156391.125 | Test loss: 2823092.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 293400 | Training Loss: 1155763.000 | Test loss: 2821615.000\nIteration: 293600 | Training Loss: 1155135.625 | Test loss: 2820214.250\nIteration: 293800 | Training Loss: 1154509.000 | Test loss: 2818777.500\nIteration: 294000 | Training Loss: 1153883.125 | Test loss: 2817317.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 294200 | Training Loss: 1153258.000 | Test loss: 2815879.000\nIteration: 294400 | Training Loss: 1152633.625 | Test loss: 2814452.000\nIteration: 294600 | Training Loss: 1152009.750 | Test loss: 2813031.750\nIteration: 294800 | Training Loss: 1151386.875 | Test loss: 2811593.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 295000 | Training Loss: 1150764.500 | Test loss: 2810121.750\nIteration: 295200 | Training Loss: 1150143.000 | Test loss: 2808730.500\nIteration: 295400 | Training Loss: 1149522.250 | Test loss: 2807329.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 295600 | Training Loss: 1148902.125 | Test loss: 2805881.750\nIteration: 295800 | Training Loss: 1148282.625 | Test loss: 2804462.500\nIteration: 296000 | Training Loss: 1147664.000 | Test loss: 2803037.750\nIteration: 296200 | Training Loss: 1147046.000 | Test loss: 2801599.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 296400 | Training Loss: 1146428.750 | Test loss: 2800237.750\nIteration: 296600 | Training Loss: 1145812.125 | Test loss: 2798786.250\nIteration: 296800 | Training Loss: 1145196.250 | Test loss: 2797393.000\nIteration: 297000 | Training Loss: 1144581.000 | Test loss: 2795958.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 297200 | Training Loss: 1143966.500 | Test loss: 2794584.750\nIteration: 297400 | Training Loss: 1143352.625 | Test loss: 2793168.500\nIteration: 297600 | Training Loss: 1142739.500 | Test loss: 2791760.250\nIteration: 297800 | Training Loss: 1142127.125 | Test loss: 2790368.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 298000 | Training Loss: 1141515.375 | Test loss: 2788950.250\nIteration: 298200 | Training Loss: 1140904.375 | Test loss: 2787568.250\nIteration: 298400 | Training Loss: 1140294.125 | Test loss: 2786170.750\nIteration: 298600 | Training Loss: 1139684.500 | Test loss: 2784782.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 298800 | Training Loss: 1139075.500 | Test loss: 2783385.250\nIteration: 299000 | Training Loss: 1138467.375 | Test loss: 2782036.000\nIteration: 299200 | Training Loss: 1137859.750 | Test loss: 2780603.500\nIteration: 299400 | Training Loss: 1137252.875 | Test loss: 2779212.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 299600 | Training Loss: 1136646.750 | Test loss: 2777838.500\nIteration: 299800 | Training Loss: 1136041.250 | Test loss: 2776433.000\nIteration: 300000 | Training Loss: 1135436.375 | Test loss: 2775074.000\nIteration: 300200 | Training Loss: 1134832.250 | Test loss: 2773681.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 300400 | Training Loss: 1134228.875 | Test loss: 2772304.500\nIteration: 300600 | Training Loss: 1133626.250 | Test loss: 2770922.250\nIteration: 300800 | Training Loss: 1133024.250 | Test loss: 2769574.250\nIteration: 301000 | Training Loss: 1132422.875 | Test loss: 2768168.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 301200 | Training Loss: 1131822.250 | Test loss: 2766806.750\nIteration: 301400 | Training Loss: 1131222.250 | Test loss: 2765381.000\nIteration: 301600 | Training Loss: 1130623.000 | Test loss: 2764013.750\nIteration: 301800 | Training Loss: 1130024.500 | Test loss: 2762658.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 302000 | Training Loss: 1129426.625 | Test loss: 2761289.250\nIteration: 302200 | Training Loss: 1128829.375 | Test loss: 2759898.750\nIteration: 302400 | Training Loss: 1128232.875 | Test loss: 2758530.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 302600 | Training Loss: 1127637.125 | Test loss: 2757161.000\nIteration: 302800 | Training Loss: 1127042.000 | Test loss: 2755895.750\nIteration: 303000 | Training Loss: 1126447.625 | Test loss: 2754436.000\nIteration: 303200 | Training Loss: 1125853.875 | Test loss: 2753088.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 303400 | Training Loss: 1125260.875 | Test loss: 2751698.750\nIteration: 303600 | Training Loss: 1124668.500 | Test loss: 2750376.500\nIteration: 303800 | Training Loss: 1124076.875 | Test loss: 2748972.000\nIteration: 304000 | Training Loss: 1123485.875 | Test loss: 2747584.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 304200 | Training Loss: 1122895.625 | Test loss: 2746253.500\nIteration: 304400 | Training Loss: 1122306.125 | Test loss: 2744881.250\nIteration: 304600 | Training Loss: 1121717.125 | Test loss: 2743532.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 304800 | Training Loss: 1121129.000 | Test loss: 2742172.000\nIteration: 305000 | Training Loss: 1120541.500 | Test loss: 2740831.000\nIteration: 305200 | Training Loss: 1119954.750 | Test loss: 2739452.000\nIteration: 305400 | Training Loss: 1119368.625 | Test loss: 2738138.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 305600 | Training Loss: 1118783.125 | Test loss: 2736739.250\nIteration: 305800 | Training Loss: 1118198.375 | Test loss: 2735412.750\nIteration: 306000 | Training Loss: 1117614.375 | Test loss: 2734067.000\nIteration: 306200 | Training Loss: 1117031.000 | Test loss: 2732701.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 306400 | Training Loss: 1116448.375 | Test loss: 2731366.750\nIteration: 306600 | Training Loss: 1115866.375 | Test loss: 2730026.250\nIteration: 306800 | Training Loss: 1115285.125 | Test loss: 2728683.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 307000 | Training Loss: 1114704.500 | Test loss: 2727322.500\nIteration: 307200 | Training Loss: 1114124.625 | Test loss: 2725991.750\nIteration: 307400 | Training Loss: 1113545.500 | Test loss: 2724649.750\nIteration: 307600 | Training Loss: 1112967.000 | Test loss: 2723307.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 307800 | Training Loss: 1112389.125 | Test loss: 2721965.500\nIteration: 308000 | Training Loss: 1111812.000 | Test loss: 2720625.250\nIteration: 308200 | Training Loss: 1111235.625 | Test loss: 2719302.750\nIteration: 308400 | Training Loss: 1110659.875 | Test loss: 2717954.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 308600 | Training Loss: 1110084.875 | Test loss: 2716629.500\nIteration: 308800 | Training Loss: 1109510.625 | Test loss: 2715262.250\nIteration: 309000 | Training Loss: 1108937.250 | Test loss: 2713955.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 309200 | Training Loss: 1108365.250 | Test loss: 2712618.500\nIteration: 309400 | Training Loss: 1107793.750 | Test loss: 2711292.750\nIteration: 309600 | Training Loss: 1107223.000 | Test loss: 2709946.250\nIteration: 309800 | Training Loss: 1106653.000 | Test loss: 2708611.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 310000 | Training Loss: 1106083.750 | Test loss: 2707321.000\nIteration: 310200 | Training Loss: 1105515.000 | Test loss: 2705952.000\nIteration: 310400 | Training Loss: 1104947.125 | Test loss: 2704663.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 310600 | Training Loss: 1104379.750 | Test loss: 2703343.250\nIteration: 310800 | Training Loss: 1103813.250 | Test loss: 2702014.250\nIteration: 311000 | Training Loss: 1103247.250 | Test loss: 2700694.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 311200 | Training Loss: 1102682.125 | Test loss: 2699376.000\nIteration: 311400 | Training Loss: 1102117.500 | Test loss: 2698064.250\nIteration: 311600 | Training Loss: 1101553.750 | Test loss: 2696746.000\nIteration: 311800 | Training Loss: 1100990.625 | Test loss: 2695436.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 312000 | Training Loss: 1100428.125 | Test loss: 2694119.750\nIteration: 312200 | Training Loss: 1099866.375 | Test loss: 2692798.250\nIteration: 312400 | Training Loss: 1099305.250 | Test loss: 2691475.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 312600 | Training Loss: 1098744.750 | Test loss: 2690182.000\nIteration: 312800 | Training Loss: 1098185.125 | Test loss: 2688866.750\nIteration: 313000 | Training Loss: 1097626.125 | Test loss: 2687583.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 313200 | Training Loss: 1097067.750 | Test loss: 2686255.250\nIteration: 313400 | Training Loss: 1096510.125 | Test loss: 2684931.250\nIteration: 313600 | Training Loss: 1095953.250 | Test loss: 2683643.250\nIteration: 313800 | Training Loss: 1095396.875 | Test loss: 2682333.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 314000 | Training Loss: 1094841.375 | Test loss: 2681037.750\nIteration: 314200 | Training Loss: 1094286.375 | Test loss: 2679746.750\nIteration: 314400 | Training Loss: 1093732.250 | Test loss: 2678433.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 314600 | Training Loss: 1093178.750 | Test loss: 2677132.500\nIteration: 314800 | Training Loss: 1092625.875 | Test loss: 2675841.250\nIteration: 315000 | Training Loss: 1092073.750 | Test loss: 2674547.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 315200 | Training Loss: 1091522.250 | Test loss: 2673236.000\nIteration: 315400 | Training Loss: 1090971.500 | Test loss: 2671947.250\nIteration: 315600 | Training Loss: 1090421.375 | Test loss: 2670654.500\nIteration: 315800 | Training Loss: 1089872.000 | Test loss: 2669365.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 316000 | Training Loss: 1089323.250 | Test loss: 2668071.250\nIteration: 316200 | Training Loss: 1088775.250 | Test loss: 2666783.750\nIteration: 316400 | Training Loss: 1088228.000 | Test loss: 2665490.000\nIteration: 316600 | Training Loss: 1087681.375 | Test loss: 2664204.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 316800 | Training Loss: 1087135.375 | Test loss: 2662886.750\nIteration: 317000 | Training Loss: 1086590.125 | Test loss: 2661626.250\nIteration: 317200 | Training Loss: 1086045.500 | Test loss: 2660374.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 317400 | Training Loss: 1085501.625 | Test loss: 2659070.750\nIteration: 317600 | Training Loss: 1084958.375 | Test loss: 2657779.750\nIteration: 317800 | Training Loss: 1084415.875 | Test loss: 2656517.750\nIteration: 318000 | Training Loss: 1083874.125 | Test loss: 2655198.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 318200 | Training Loss: 1083333.000 | Test loss: 2653923.250\nIteration: 318400 | Training Loss: 1082792.500 | Test loss: 2652649.250\nIteration: 318600 | Training Loss: 1082252.625 | Test loss: 2651415.500\nIteration: 318800 | Training Loss: 1081713.625 | Test loss: 2650106.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 319000 | Training Loss: 1081175.250 | Test loss: 2648827.250\nIteration: 319200 | Training Loss: 1080637.500 | Test loss: 2647548.750\nIteration: 319400 | Training Loss: 1080100.500 | Test loss: 2646318.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 319600 | Training Loss: 1079564.125 | Test loss: 2645009.250\nIteration: 319800 | Training Loss: 1079028.500 | Test loss: 2643749.250\nIteration: 320000 | Training Loss: 1078493.625 | Test loss: 2642507.750\nIteration: 320200 | Training Loss: 1077959.250 | Test loss: 2641224.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 320400 | Training Loss: 1077425.750 | Test loss: 2639968.750\nIteration: 320600 | Training Loss: 1076893.000 | Test loss: 2638679.250\nIteration: 320800 | Training Loss: 1076360.750 | Test loss: 2637402.000\nIteration: 321000 | Training Loss: 1075829.250 | Test loss: 2636163.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 321200 | Training Loss: 1075298.500 | Test loss: 2634894.750\nIteration: 321400 | Training Loss: 1074768.375 | Test loss: 2633642.250\nIteration: 321600 | Training Loss: 1074239.000 | Test loss: 2632378.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 321800 | Training Loss: 1073710.250 | Test loss: 2631128.500\nIteration: 322000 | Training Loss: 1073182.250 | Test loss: 2629870.500\nIteration: 322200 | Training Loss: 1072654.875 | Test loss: 2628596.250\nIteration: 322400 | Training Loss: 1072128.250 | Test loss: 2627361.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 322600 | Training Loss: 1071602.375 | Test loss: 2626082.250\nIteration: 322800 | Training Loss: 1071077.250 | Test loss: 2624859.750\nIteration: 323000 | Training Loss: 1070552.875 | Test loss: 2623625.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 323200 | Training Loss: 1070030.500 | Test loss: 2622354.250\nIteration: 323400 | Training Loss: 1069509.000 | Test loss: 2621118.500\nIteration: 323600 | Training Loss: 1068988.250 | Test loss: 2619895.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 323800 | Training Loss: 1068468.000 | Test loss: 2618639.750\nIteration: 324000 | Training Loss: 1067948.500 | Test loss: 2617391.500\nIteration: 324200 | Training Loss: 1067429.750 | Test loss: 2616160.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 324400 | Training Loss: 1066911.750 | Test loss: 2614921.500\nIteration: 324600 | Training Loss: 1066394.250 | Test loss: 2613675.750\nIteration: 324800 | Training Loss: 1065877.500 | Test loss: 2612443.000\nIteration: 325000 | Training Loss: 1065361.500 | Test loss: 2611240.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 325200 | Training Loss: 1064846.125 | Test loss: 2609973.500\nIteration: 325400 | Training Loss: 1064331.500 | Test loss: 2608777.750\nIteration: 325600 | Training Loss: 1063817.375 | Test loss: 2607530.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 325800 | Training Loss: 1063304.125 | Test loss: 2606286.500\nIteration: 326000 | Training Loss: 1062791.500 | Test loss: 2605074.500\nIteration: 326200 | Training Loss: 1062279.375 | Test loss: 2603801.500\nIteration: 326400 | Training Loss: 1061768.125 | Test loss: 2602626.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 326600 | Training Loss: 1061257.500 | Test loss: 2601380.250\nIteration: 326800 | Training Loss: 1060747.625 | Test loss: 2600189.500\nIteration: 327000 | Training Loss: 1060238.375 | Test loss: 2598955.750\nIteration: 327200 | Training Loss: 1059729.750 | Test loss: 2597733.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 327400 | Training Loss: 1059221.875 | Test loss: 2596501.500\nIteration: 327600 | Training Loss: 1058715.000 | Test loss: 2595310.250\nIteration: 327800 | Training Loss: 1058208.750 | Test loss: 2594093.000\nIteration: 328000 | Training Loss: 1057703.125 | Test loss: 2592890.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 328200 | Training Loss: 1057198.125 | Test loss: 2591669.000\nIteration: 328400 | Training Loss: 1056693.875 | Test loss: 2590465.500\nIteration: 328600 | Training Loss: 1056190.250 | Test loss: 2589249.250\nIteration: 328800 | Training Loss: 1055687.250 | Test loss: 2588067.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 329000 | Training Loss: 1055185.000 | Test loss: 2586842.750\nIteration: 329200 | Training Loss: 1054683.375 | Test loss: 2585663.250\nIteration: 329400 | Training Loss: 1054182.375 | Test loss: 2584417.000\nIteration: 329600 | Training Loss: 1053682.125 | Test loss: 2583240.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 329800 | Training Loss: 1053182.500 | Test loss: 2582037.250\nIteration: 330000 | Training Loss: 1052683.500 | Test loss: 2580838.750\nIteration: 330200 | Training Loss: 1052185.250 | Test loss: 2579640.750\nIteration: 330400 | Training Loss: 1051687.750 | Test loss: 2578424.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 330600 | Training Loss: 1051190.750 | Test loss: 2577239.500\nIteration: 330800 | Training Loss: 1050694.625 | Test loss: 2576049.750\nIteration: 331000 | Training Loss: 1050199.000 | Test loss: 2574864.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 331200 | Training Loss: 1049704.125 | Test loss: 2573666.000\nIteration: 331400 | Training Loss: 1049209.875 | Test loss: 2572500.000\nIteration: 331600 | Training Loss: 1048716.250 | Test loss: 2571297.500\nIteration: 331800 | Training Loss: 1048223.438 | Test loss: 2570104.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 332000 | Training Loss: 1047731.250 | Test loss: 2568925.250\nIteration: 332200 | Training Loss: 1047239.688 | Test loss: 2567754.500\nIteration: 332400 | Training Loss: 1046748.875 | Test loss: 2566562.000\nIteration: 332600 | Training Loss: 1046258.688 | Test loss: 2565362.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 332800 | Training Loss: 1045769.125 | Test loss: 2564204.250\nIteration: 333000 | Training Loss: 1045280.312 | Test loss: 2563014.000\nIteration: 333200 | Training Loss: 1044792.188 | Test loss: 2561863.000\nIteration: 333400 | Training Loss: 1044304.625 | Test loss: 2560676.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 333600 | Training Loss: 1043817.750 | Test loss: 2559526.500\nIteration: 333800 | Training Loss: 1043331.625 | Test loss: 2558352.750\nIteration: 334000 | Training Loss: 1042846.125 | Test loss: 2557178.750\nIteration: 334200 | Training Loss: 1042361.312 | Test loss: 2556029.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 334400 | Training Loss: 1041877.125 | Test loss: 2554855.500\nIteration: 334600 | Training Loss: 1041393.562 | Test loss: 2553704.500\nIteration: 334800 | Training Loss: 1040910.688 | Test loss: 2552545.250\nIteration: 335000 | Training Loss: 1040428.500 | Test loss: 2551403.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 335200 | Training Loss: 1039946.875 | Test loss: 2550260.500\nIteration: 335400 | Training Loss: 1039465.938 | Test loss: 2549114.500\nIteration: 335600 | Training Loss: 1038985.688 | Test loss: 2548003.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 335800 | Training Loss: 1038505.938 | Test loss: 2546865.500\nIteration: 336000 | Training Loss: 1038026.812 | Test loss: 2545725.500\nIteration: 336200 | Training Loss: 1037548.438 | Test loss: 2544623.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 336400 | Training Loss: 1037070.500 | Test loss: 2543510.250\nIteration: 336600 | Training Loss: 1036593.250 | Test loss: 2542392.250\nIteration: 336800 | Training Loss: 1036116.625 | Test loss: 2541300.250\nIteration: 337000 | Training Loss: 1035640.750 | Test loss: 2540188.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 337200 | Training Loss: 1035165.250 | Test loss: 2539095.000\nIteration: 337400 | Training Loss: 1034690.562 | Test loss: 2537977.500\nIteration: 337600 | Training Loss: 1034216.438 | Test loss: 2536892.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 337800 | Training Loss: 1033742.938 | Test loss: 2535794.500\nIteration: 338000 | Training Loss: 1033270.062 | Test loss: 2534687.750\nIteration: 338200 | Training Loss: 1032797.875 | Test loss: 2533599.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 338400 | Training Loss: 1032326.250 | Test loss: 2532499.000\nIteration: 338600 | Training Loss: 1031855.250 | Test loss: 2531416.500\nIteration: 338800 | Training Loss: 1031384.812 | Test loss: 2530298.500\nIteration: 339000 | Training Loss: 1030915.062 | Test loss: 2529257.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 339200 | Training Loss: 1030445.938 | Test loss: 2528147.500\nIteration: 339400 | Training Loss: 1029977.375 | Test loss: 2527063.000\nIteration: 339600 | Training Loss: 1029509.438 | Test loss: 2525977.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 339800 | Training Loss: 1029042.188 | Test loss: 2524895.000\nIteration: 340000 | Training Loss: 1028575.562 | Test loss: 2523833.000\nIteration: 340200 | Training Loss: 1028109.500 | Test loss: 2522723.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 340400 | Training Loss: 1027644.125 | Test loss: 2521639.250\nIteration: 340600 | Training Loss: 1027179.312 | Test loss: 2520553.750\nIteration: 340800 | Training Loss: 1026715.188 | Test loss: 2519476.750\nIteration: 341000 | Training Loss: 1026251.625 | Test loss: 2518388.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 341200 | Training Loss: 1025788.688 | Test loss: 2517328.250\nIteration: 341400 | Training Loss: 1025326.312 | Test loss: 2516247.000\nIteration: 341600 | Training Loss: 1024864.562 | Test loss: 2515132.250\nIteration: 341800 | Training Loss: 1024403.562 | Test loss: 2514054.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 342000 | Training Loss: 1023943.125 | Test loss: 2513001.750\nIteration: 342200 | Training Loss: 1023483.375 | Test loss: 2511926.500\nIteration: 342400 | Training Loss: 1023024.375 | Test loss: 2510872.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 342600 | Training Loss: 1022565.938 | Test loss: 2509789.250\nIteration: 342800 | Training Loss: 1022108.125 | Test loss: 2508722.500\nIteration: 343000 | Training Loss: 1021651.000 | Test loss: 2507653.250\nIteration: 343200 | Training Loss: 1021194.438 | Test loss: 2506594.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 343400 | Training Loss: 1020738.625 | Test loss: 2505519.750\nIteration: 343600 | Training Loss: 1020283.375 | Test loss: 2504467.500\nIteration: 343800 | Training Loss: 1019828.938 | Test loss: 2503381.750\nIteration: 344000 | Training Loss: 1019375.000 | Test loss: 2502306.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 344200 | Training Loss: 1018921.750 | Test loss: 2501267.750\nIteration: 344400 | Training Loss: 1018469.062 | Test loss: 2500183.500\nIteration: 344600 | Training Loss: 1018017.062 | Test loss: 2499144.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 344800 | Training Loss: 1017565.688 | Test loss: 2498079.750\nIteration: 345000 | Training Loss: 1017114.875 | Test loss: 2497027.000\nIteration: 345200 | Training Loss: 1016664.750 | Test loss: 2495971.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 345400 | Training Loss: 1016215.188 | Test loss: 2494932.000\nIteration: 345600 | Training Loss: 1015766.188 | Test loss: 2493878.000\nIteration: 345800 | Training Loss: 1015317.875 | Test loss: 2492787.000\nIteration: 346000 | Training Loss: 1014870.125 | Test loss: 2491739.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 346200 | Training Loss: 1014422.938 | Test loss: 2490691.000\nIteration: 346400 | Training Loss: 1013976.438 | Test loss: 2489636.500\nIteration: 346600 | Training Loss: 1013530.500 | Test loss: 2488580.750\nIteration: 346800 | Training Loss: 1013085.125 | Test loss: 2487527.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 347000 | Training Loss: 1012640.375 | Test loss: 2486480.000\nIteration: 347200 | Training Loss: 1012196.312 | Test loss: 2485436.250\nIteration: 347400 | Training Loss: 1011752.750 | Test loss: 2484366.000\nIteration: 347600 | Training Loss: 1011309.875 | Test loss: 2483338.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 347800 | Training Loss: 1010867.562 | Test loss: 2482295.500\nIteration: 348000 | Training Loss: 1010425.688 | Test loss: 2481247.000\nIteration: 348200 | Training Loss: 1009984.500 | Test loss: 2480203.500\nIteration: 348400 | Training Loss: 1009544.000 | Test loss: 2479164.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 348600 | Training Loss: 1009104.000 | Test loss: 2478118.000\nIteration: 348800 | Training Loss: 1008664.688 | Test loss: 2477080.500\nIteration: 349000 | Training Loss: 1008225.750 | Test loss: 2476024.000\nIteration: 349200 | Training Loss: 1007787.438 | Test loss: 2474985.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 349400 | Training Loss: 1007349.688 | Test loss: 2473955.250\nIteration: 349600 | Training Loss: 1006912.500 | Test loss: 2472926.750\nIteration: 349800 | Training Loss: 1006475.750 | Test loss: 2471854.000\nIteration: 350000 | Training Loss: 1006039.750 | Test loss: 2470856.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 350200 | Training Loss: 1005604.062 | Test loss: 2469792.000\nIteration: 350400 | Training Loss: 1005169.188 | Test loss: 2468774.250\nIteration: 350600 | Training Loss: 1004734.750 | Test loss: 2467728.000\nIteration: 350800 | Training Loss: 1004300.938 | Test loss: 2466699.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 351000 | Training Loss: 1003867.688 | Test loss: 2465654.250\nIteration: 351200 | Training Loss: 1003434.938 | Test loss: 2464630.250\nIteration: 351400 | Training Loss: 1003002.812 | Test loss: 2463601.250\nIteration: 351600 | Training Loss: 1002571.188 | Test loss: 2462573.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 351800 | Training Loss: 1002140.188 | Test loss: 2461540.750\nIteration: 352000 | Training Loss: 1001709.562 | Test loss: 2460516.000\nIteration: 352200 | Training Loss: 1001279.625 | Test loss: 2459472.500\nIteration: 352400 | Training Loss: 1000850.188 | Test loss: 2458465.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 352600 | Training Loss: 1000421.312 | Test loss: 2457463.750\nIteration: 352800 | Training Loss: 999993.375 | Test loss: 2456419.500\nIteration: 353000 | Training Loss: 999566.188 | Test loss: 2455397.750\nIteration: 353200 | Training Loss: 999139.688 | Test loss: 2454366.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 353400 | Training Loss: 998713.750 | Test loss: 2453367.250\nIteration: 353600 | Training Loss: 998288.500 | Test loss: 2452331.500\nIteration: 353800 | Training Loss: 997863.750 | Test loss: 2451325.000\nIteration: 354000 | Training Loss: 997439.500 | Test loss: 2450310.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 354200 | Training Loss: 997015.938 | Test loss: 2449284.500\nIteration: 354400 | Training Loss: 996592.875 | Test loss: 2448269.500\nIteration: 354600 | Training Loss: 996170.312 | Test loss: 2447263.500\nIteration: 354800 | Training Loss: 995748.312 | Test loss: 2446261.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 355000 | Training Loss: 995326.812 | Test loss: 2445256.000\nIteration: 355200 | Training Loss: 994905.938 | Test loss: 2444236.750\nIteration: 355400 | Training Loss: 994485.500 | Test loss: 2443238.250\nIteration: 355600 | Training Loss: 994065.438 | Test loss: 2442274.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 355800 | Training Loss: 993645.812 | Test loss: 2441237.500\nIteration: 356000 | Training Loss: 993226.562 | Test loss: 2440201.750\nIteration: 356200 | Training Loss: 992807.812 | Test loss: 2439235.750\nIteration: 356400 | Training Loss: 992389.312 | Test loss: 2438221.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 356600 | Training Loss: 991971.312 | Test loss: 2437207.500\nIteration: 356800 | Training Loss: 991553.750 | Test loss: 2436203.000\nIteration: 357000 | Training Loss: 991136.688 | Test loss: 2435216.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 357200 | Training Loss: 990719.938 | Test loss: 2434222.250\nIteration: 357400 | Training Loss: 990303.750 | Test loss: 2433216.000\nIteration: 357600 | Training Loss: 989887.938 | Test loss: 2432235.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 357800 | Training Loss: 989472.750 | Test loss: 2431238.000\nIteration: 358000 | Training Loss: 989057.938 | Test loss: 2430235.750\nIteration: 358200 | Training Loss: 988643.750 | Test loss: 2429275.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 358400 | Training Loss: 988229.875 | Test loss: 2428290.000\nIteration: 358600 | Training Loss: 987816.625 | Test loss: 2427330.250\nIteration: 358800 | Training Loss: 987403.750 | Test loss: 2426367.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 359000 | Training Loss: 986991.312 | Test loss: 2425388.250\nIteration: 359200 | Training Loss: 986579.688 | Test loss: 2424472.500\nIteration: 359400 | Training Loss: 986168.625 | Test loss: 2423542.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 359600 | Training Loss: 985758.000 | Test loss: 2422635.750\nIteration: 359800 | Training Loss: 985347.812 | Test loss: 2421730.000\nIteration: 360000 | Training Loss: 984937.938 | Test loss: 2420821.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 360200 | Training Loss: 984528.625 | Test loss: 2419949.250\nIteration: 360400 | Training Loss: 984119.312 | Test loss: 2419057.000\nIteration: 360600 | Training Loss: 983709.500 | Test loss: 2418175.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 360800 | Training Loss: 983300.188 | Test loss: 2417298.500\nIteration: 361000 | Training Loss: 982891.375 | Test loss: 2416435.500\nIteration: 361200 | Training Loss: 982482.875 | Test loss: 2415542.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 361400 | Training Loss: 982074.875 | Test loss: 2414661.750\nIteration: 361600 | Training Loss: 981667.250 | Test loss: 2413801.250\nIteration: 361800 | Training Loss: 981260.062 | Test loss: 2412911.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 362000 | Training Loss: 980853.250 | Test loss: 2412072.000\nIteration: 362200 | Training Loss: 980446.875 | Test loss: 2411210.250\nIteration: 362400 | Training Loss: 980041.000 | Test loss: 2410353.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 362600 | Training Loss: 979635.500 | Test loss: 2409448.500\nIteration: 362800 | Training Loss: 979230.438 | Test loss: 2408616.000\nIteration: 363000 | Training Loss: 978825.688 | Test loss: 2407749.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 363200 | Training Loss: 978421.438 | Test loss: 2406895.250\nIteration: 363400 | Training Loss: 978017.625 | Test loss: 2406022.250\nIteration: 363600 | Training Loss: 977614.125 | Test loss: 2405180.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 363800 | Training Loss: 977211.188 | Test loss: 2404308.250\nIteration: 364000 | Training Loss: 976808.562 | Test loss: 2403471.500\nIteration: 364200 | Training Loss: 976406.438 | Test loss: 2402615.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 364400 | Training Loss: 976004.625 | Test loss: 2401763.750\nIteration: 364600 | Training Loss: 975603.312 | Test loss: 2400927.000\nIteration: 364800 | Training Loss: 975202.375 | Test loss: 2400088.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 365000 | Training Loss: 974801.938 | Test loss: 2399228.500\nIteration: 365200 | Training Loss: 974401.812 | Test loss: 2398394.000\nIteration: 365400 | Training Loss: 974002.125 | Test loss: 2397551.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 365600 | Training Loss: 973602.875 | Test loss: 2396705.500\nIteration: 365800 | Training Loss: 973204.000 | Test loss: 2395880.000\nIteration: 366000 | Training Loss: 972805.625 | Test loss: 2395048.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 366200 | Training Loss: 972407.562 | Test loss: 2394222.250\nIteration: 366400 | Training Loss: 972009.938 | Test loss: 2393390.250\nIteration: 366600 | Training Loss: 971612.750 | Test loss: 2392558.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 366800 | Training Loss: 971215.938 | Test loss: 2391738.750\nIteration: 367000 | Training Loss: 970819.562 | Test loss: 2390901.000\nIteration: 367200 | Training Loss: 970423.688 | Test loss: 2390069.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 367400 | Training Loss: 970028.188 | Test loss: 2389257.500\nIteration: 367600 | Training Loss: 969633.062 | Test loss: 2388412.750\nIteration: 367800 | Training Loss: 969238.312 | Test loss: 2387573.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 368000 | Training Loss: 968844.062 | Test loss: 2386753.750\nIteration: 368200 | Training Loss: 968450.188 | Test loss: 2385932.500\nIteration: 368400 | Training Loss: 968056.750 | Test loss: 2385098.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 368600 | Training Loss: 967663.688 | Test loss: 2384280.500\nIteration: 368800 | Training Loss: 967271.062 | Test loss: 2383465.000\nIteration: 369000 | Training Loss: 966878.812 | Test loss: 2382645.500\nIteration: 369200 | Training Loss: 966486.938 | Test loss: 2381782.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 369400 | Training Loss: 966095.562 | Test loss: 2380987.500\nIteration: 369600 | Training Loss: 965704.625 | Test loss: 2380165.000\nIteration: 369800 | Training Loss: 965314.000 | Test loss: 2379329.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 370000 | Training Loss: 964923.875 | Test loss: 2378524.750\nIteration: 370200 | Training Loss: 964534.062 | Test loss: 2377710.250\nIteration: 370400 | Training Loss: 964144.688 | Test loss: 2376896.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 370600 | Training Loss: 963755.812 | Test loss: 2376070.000\nIteration: 370800 | Training Loss: 963367.250 | Test loss: 2375254.500\nIteration: 371000 | Training Loss: 962979.125 | Test loss: 2374443.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 371200 | Training Loss: 962591.500 | Test loss: 2373606.000\nIteration: 371400 | Training Loss: 962204.125 | Test loss: 2372825.500\nIteration: 371600 | Training Loss: 961817.250 | Test loss: 2372013.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 371800 | Training Loss: 961430.750 | Test loss: 2371197.250\nIteration: 372000 | Training Loss: 961044.688 | Test loss: 2370398.000\nIteration: 372200 | Training Loss: 960658.938 | Test loss: 2369601.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 372400 | Training Loss: 960273.688 | Test loss: 2368798.500\nIteration: 372600 | Training Loss: 959888.812 | Test loss: 2367994.500\nIteration: 372800 | Training Loss: 959504.250 | Test loss: 2367191.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 373000 | Training Loss: 959120.062 | Test loss: 2366418.750\nIteration: 373200 | Training Loss: 958736.250 | Test loss: 2365612.750\nIteration: 373400 | Training Loss: 958352.812 | Test loss: 2364826.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 373600 | Training Loss: 957969.750 | Test loss: 2364042.000\nIteration: 373800 | Training Loss: 957587.125 | Test loss: 2363263.500\nIteration: 374000 | Training Loss: 957204.750 | Test loss: 2362482.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 374200 | Training Loss: 956822.812 | Test loss: 2361693.750\nIteration: 374400 | Training Loss: 956441.250 | Test loss: 2360905.750\nIteration: 374600 | Training Loss: 956060.000 | Test loss: 2360133.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 374800 | Training Loss: 955679.125 | Test loss: 2359333.000\nIteration: 375000 | Training Loss: 955298.688 | Test loss: 2358556.750\nIteration: 375200 | Training Loss: 954918.562 | Test loss: 2357772.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 375400 | Training Loss: 954538.875 | Test loss: 2356989.500\nIteration: 375600 | Training Loss: 954159.438 | Test loss: 2356212.750\nIteration: 375800 | Training Loss: 953780.500 | Test loss: 2355426.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 376000 | Training Loss: 953401.875 | Test loss: 2354645.500\nIteration: 376200 | Training Loss: 953023.625 | Test loss: 2353845.000\nIteration: 376400 | Training Loss: 952645.688 | Test loss: 2353082.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 376600 | Training Loss: 952268.188 | Test loss: 2352288.500\nIteration: 376800 | Training Loss: 951891.125 | Test loss: 2351530.000\nIteration: 377000 | Training Loss: 951514.312 | Test loss: 2350742.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 377200 | Training Loss: 951137.938 | Test loss: 2349951.750\nIteration: 377400 | Training Loss: 950762.000 | Test loss: 2349189.750\nIteration: 377600 | Training Loss: 950386.312 | Test loss: 2348390.500\nIteration: 377800 | Training Loss: 950011.062 | Test loss: 2347635.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 378000 | Training Loss: 949636.188 | Test loss: 2346865.750\nIteration: 378200 | Training Loss: 949261.688 | Test loss: 2346079.750\nIteration: 378400 | Training Loss: 948887.562 | Test loss: 2345291.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 378600 | Training Loss: 948513.750 | Test loss: 2344532.250\nIteration: 378800 | Training Loss: 948140.312 | Test loss: 2343761.750\nIteration: 379000 | Training Loss: 947767.375 | Test loss: 2342973.250\nIteration: 379200 | Training Loss: 947394.750 | Test loss: 2342198.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 379400 | Training Loss: 947022.438 | Test loss: 2341442.250\nIteration: 379600 | Training Loss: 946650.500 | Test loss: 2340662.750\nIteration: 379800 | Training Loss: 946279.000 | Test loss: 2339893.000\nIteration: 380000 | Training Loss: 945907.812 | Test loss: 2339101.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 380200 | Training Loss: 945537.062 | Test loss: 2338338.250\nIteration: 380400 | Training Loss: 945166.625 | Test loss: 2337581.000\nIteration: 380600 | Training Loss: 944796.562 | Test loss: 2336810.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 380800 | Training Loss: 944426.875 | Test loss: 2336040.250\nIteration: 381000 | Training Loss: 944057.562 | Test loss: 2335279.250\nIteration: 381200 | Training Loss: 943688.625 | Test loss: 2334505.750\nIteration: 381400 | Training Loss: 943320.062 | Test loss: 2333745.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 381600 | Training Loss: 942951.875 | Test loss: 2332983.000\nIteration: 381800 | Training Loss: 942584.062 | Test loss: 2332193.250\nIteration: 382000 | Training Loss: 942216.625 | Test loss: 2331456.750\nIteration: 382200 | Training Loss: 941849.562 | Test loss: 2330687.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 382400 | Training Loss: 941482.812 | Test loss: 2329918.000\nIteration: 382600 | Training Loss: 941116.438 | Test loss: 2329150.250\nIteration: 382800 | Training Loss: 940750.500 | Test loss: 2328395.750\nIteration: 383000 | Training Loss: 940384.875 | Test loss: 2327635.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 383200 | Training Loss: 940019.625 | Test loss: 2326870.500\nIteration: 383400 | Training Loss: 939654.812 | Test loss: 2326120.500\nIteration: 383600 | Training Loss: 939290.250 | Test loss: 2325345.000\nIteration: 383800 | Training Loss: 938926.125 | Test loss: 2324581.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 384000 | Training Loss: 938562.312 | Test loss: 2323848.500\nIteration: 384200 | Training Loss: 938199.000 | Test loss: 2323097.500\nIteration: 384400 | Training Loss: 937835.875 | Test loss: 2322311.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 384600 | Training Loss: 937473.250 | Test loss: 2321577.500\nIteration: 384800 | Training Loss: 937110.938 | Test loss: 2320815.750\nIteration: 385000 | Training Loss: 936749.000 | Test loss: 2320064.250\nIteration: 385200 | Training Loss: 936387.438 | Test loss: 2319319.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 385400 | Training Loss: 936026.250 | Test loss: 2318559.500\nIteration: 385600 | Training Loss: 935665.375 | Test loss: 2317812.750\nIteration: 385800 | Training Loss: 935304.875 | Test loss: 2317067.750\nIteration: 386000 | Training Loss: 934944.750 | Test loss: 2316320.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 386200 | Training Loss: 934585.000 | Test loss: 2315577.750\nIteration: 386400 | Training Loss: 934225.625 | Test loss: 2314830.750\nIteration: 386600 | Training Loss: 933866.562 | Test loss: 2314089.000\nIteration: 386800 | Training Loss: 933507.938 | Test loss: 2313326.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 387000 | Training Loss: 933149.562 | Test loss: 2312628.750\nIteration: 387200 | Training Loss: 932791.500 | Test loss: 2311880.750\nIteration: 387400 | Training Loss: 932433.875 | Test loss: 2311153.500\nIteration: 387600 | Training Loss: 932076.562 | Test loss: 2310419.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 387800 | Training Loss: 931719.562 | Test loss: 2309701.500\nIteration: 388000 | Training Loss: 931363.000 | Test loss: 2308988.250\nIteration: 388200 | Training Loss: 931006.625 | Test loss: 2308268.500\nIteration: 388400 | Training Loss: 930650.688 | Test loss: 2307561.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 388600 | Training Loss: 930295.062 | Test loss: 2306861.500\nIteration: 388800 | Training Loss: 929939.688 | Test loss: 2306161.750\nIteration: 389000 | Training Loss: 929584.750 | Test loss: 2305472.250\nIteration: 389200 | Training Loss: 929230.125 | Test loss: 2304771.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 389400 | Training Loss: 928875.812 | Test loss: 2304085.000\nIteration: 389600 | Training Loss: 928521.875 | Test loss: 2303408.250\nIteration: 389800 | Training Loss: 928168.188 | Test loss: 2302724.000\nIteration: 390000 | Training Loss: 927814.938 | Test loss: 2302045.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 390200 | Training Loss: 927462.000 | Test loss: 2301401.500\nIteration: 390400 | Training Loss: 927109.375 | Test loss: 2300707.750\nIteration: 390600 | Training Loss: 926757.125 | Test loss: 2300046.750\nIteration: 390800 | Training Loss: 926405.188 | Test loss: 2299370.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 391000 | Training Loss: 926053.562 | Test loss: 2298706.250\nIteration: 391200 | Training Loss: 925702.312 | Test loss: 2298037.000\nIteration: 391400 | Training Loss: 925351.312 | Test loss: 2297379.500\nIteration: 391600 | Training Loss: 925000.688 | Test loss: 2296708.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 391800 | Training Loss: 924650.375 | Test loss: 2296041.500\nIteration: 392000 | Training Loss: 924300.438 | Test loss: 2295370.750\nIteration: 392200 | Training Loss: 923950.688 | Test loss: 2294709.000\nIteration: 392400 | Training Loss: 923601.250 | Test loss: 2294037.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 392600 | Training Loss: 923252.062 | Test loss: 2293373.500\nIteration: 392800 | Training Loss: 922903.188 | Test loss: 2292709.750\nIteration: 393000 | Training Loss: 922554.750 | Test loss: 2292041.250\nIteration: 393200 | Training Loss: 922206.625 | Test loss: 2291380.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 393400 | Training Loss: 921858.812 | Test loss: 2290702.000\nIteration: 393600 | Training Loss: 921511.375 | Test loss: 2290042.250\nIteration: 393800 | Training Loss: 921164.188 | Test loss: 2289402.750\nIteration: 394000 | Training Loss: 920817.312 | Test loss: 2288715.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 394200 | Training Loss: 920470.875 | Test loss: 2288050.500\nIteration: 394400 | Training Loss: 920124.750 | Test loss: 2287385.000\nIteration: 394600 | Training Loss: 919778.938 | Test loss: 2286725.500\nIteration: 394800 | Training Loss: 919433.438 | Test loss: 2286058.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 395000 | Training Loss: 919088.312 | Test loss: 2285394.500\nIteration: 395200 | Training Loss: 918743.500 | Test loss: 2284736.500\nIteration: 395400 | Training Loss: 918398.938 | Test loss: 2284075.000\nIteration: 395600 | Training Loss: 918054.875 | Test loss: 2283433.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 395800 | Training Loss: 917711.000 | Test loss: 2282751.250\nIteration: 396000 | Training Loss: 917367.562 | Test loss: 2282091.750\nIteration: 396200 | Training Loss: 917024.375 | Test loss: 2281421.250\nIteration: 396400 | Training Loss: 916681.625 | Test loss: 2280758.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 396600 | Training Loss: 916339.062 | Test loss: 2280093.000\nIteration: 396800 | Training Loss: 915996.875 | Test loss: 2279431.000\nIteration: 397000 | Training Loss: 915655.125 | Test loss: 2278776.750\nIteration: 397200 | Training Loss: 915313.562 | Test loss: 2278116.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 397400 | Training Loss: 914972.500 | Test loss: 2277451.000\nIteration: 397600 | Training Loss: 914631.625 | Test loss: 2276806.250\nIteration: 397800 | Training Loss: 914291.188 | Test loss: 2276158.250\nIteration: 398000 | Training Loss: 913951.000 | Test loss: 2275484.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 398200 | Training Loss: 913611.188 | Test loss: 2274811.250\nIteration: 398400 | Training Loss: 913271.688 | Test loss: 2274153.500\nIteration: 398600 | Training Loss: 912932.500 | Test loss: 2273494.750\nIteration: 398800 | Training Loss: 912593.688 | Test loss: 2272855.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 399000 | Training Loss: 912255.188 | Test loss: 2272174.500\nIteration: 399200 | Training Loss: 911917.000 | Test loss: 2271527.000\nIteration: 399400 | Training Loss: 911579.312 | Test loss: 2270863.000\nIteration: 399600 | Training Loss: 911242.375 | Test loss: 2270208.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 399800 | Training Loss: 910906.000 | Test loss: 2269550.750\nIteration: 400000 | Training Loss: 910570.062 | Test loss: 2268883.000\nIteration: 400200 | Training Loss: 910234.438 | Test loss: 2268244.750\nIteration: 400400 | Training Loss: 909899.188 | Test loss: 2267597.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 400600 | Training Loss: 909564.250 | Test loss: 2266927.500\nIteration: 400800 | Training Loss: 909229.625 | Test loss: 2266283.000\nIteration: 401000 | Training Loss: 908895.375 | Test loss: 2265610.000\nIteration: 401200 | Training Loss: 908561.375 | Test loss: 2264991.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 401400 | Training Loss: 908227.750 | Test loss: 2264325.500\nIteration: 401600 | Training Loss: 907894.438 | Test loss: 2263676.750\nIteration: 401800 | Training Loss: 907561.500 | Test loss: 2263029.000\nIteration: 402000 | Training Loss: 907228.812 | Test loss: 2262373.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 402200 | Training Loss: 906896.500 | Test loss: 2261731.500\nIteration: 402400 | Training Loss: 906564.562 | Test loss: 2261075.500\nIteration: 402600 | Training Loss: 906232.875 | Test loss: 2260413.250\nIteration: 402800 | Training Loss: 905901.562 | Test loss: 2259774.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 403000 | Training Loss: 905570.562 | Test loss: 2259133.250\nIteration: 403200 | Training Loss: 905239.875 | Test loss: 2258472.000\nIteration: 403400 | Training Loss: 904909.562 | Test loss: 2257839.000\nIteration: 403600 | Training Loss: 904579.562 | Test loss: 2257173.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 403800 | Training Loss: 904249.875 | Test loss: 2256528.750\nIteration: 404000 | Training Loss: 903920.500 | Test loss: 2255869.500\nIteration: 404200 | Training Loss: 903591.500 | Test loss: 2255229.750\nIteration: 404400 | Training Loss: 903262.812 | Test loss: 2254594.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 404600 | Training Loss: 902934.438 | Test loss: 2253952.500\nIteration: 404800 | Training Loss: 902606.438 | Test loss: 2253303.000\nIteration: 405000 | Training Loss: 902278.688 | Test loss: 2252661.000\nIteration: 405200 | Training Loss: 901951.312 | Test loss: 2252025.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 405400 | Training Loss: 901624.312 | Test loss: 2251376.500\nIteration: 405600 | Training Loss: 901297.562 | Test loss: 2250728.750\nIteration: 405800 | Training Loss: 900971.188 | Test loss: 2250080.500\nIteration: 406000 | Training Loss: 900645.125 | Test loss: 2249444.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 406200 | Training Loss: 900319.375 | Test loss: 2248811.500\nIteration: 406400 | Training Loss: 899994.000 | Test loss: 2248171.500\nIteration: 406600 | Training Loss: 899669.000 | Test loss: 2247525.250\nIteration: 406800 | Training Loss: 899344.375 | Test loss: 2246868.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 407000 | Training Loss: 899020.000 | Test loss: 2246243.000\nIteration: 407200 | Training Loss: 898696.062 | Test loss: 2245602.500\nIteration: 407400 | Training Loss: 898372.438 | Test loss: 2244964.250\nIteration: 407600 | Training Loss: 898049.125 | Test loss: 2244328.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 407800 | Training Loss: 897726.188 | Test loss: 2243699.250\nIteration: 408000 | Training Loss: 897403.562 | Test loss: 2243053.500\nIteration: 408200 | Training Loss: 897081.312 | Test loss: 2242416.500\nIteration: 408400 | Training Loss: 896759.375 | Test loss: 2241784.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 408600 | Training Loss: 896437.750 | Test loss: 2241148.500\nIteration: 408800 | Training Loss: 896116.500 | Test loss: 2240510.000\nIteration: 409000 | Training Loss: 895795.562 | Test loss: 2239903.000\nIteration: 409200 | Training Loss: 895474.875 | Test loss: 2239242.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 409400 | Training Loss: 895154.625 | Test loss: 2238614.500\nIteration: 409600 | Training Loss: 894834.688 | Test loss: 2237960.000\nIteration: 409800 | Training Loss: 894515.062 | Test loss: 2237346.500\nIteration: 410000 | Training Loss: 894195.750 | Test loss: 2236712.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 410200 | Training Loss: 893876.812 | Test loss: 2236096.750\nIteration: 410400 | Training Loss: 893558.188 | Test loss: 2235447.000\nIteration: 410600 | Training Loss: 893239.875 | Test loss: 2234819.000\nIteration: 410800 | Training Loss: 892921.938 | Test loss: 2234191.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 411000 | Training Loss: 892604.312 | Test loss: 2233553.000\nIteration: 411200 | Training Loss: 892287.062 | Test loss: 2232932.250\nIteration: 411400 | Training Loss: 891970.188 | Test loss: 2232300.750\nIteration: 411600 | Training Loss: 891653.625 | Test loss: 2231670.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 411800 | Training Loss: 891337.438 | Test loss: 2231044.500\nIteration: 412000 | Training Loss: 891021.500 | Test loss: 2230420.000\nIteration: 412200 | Training Loss: 890706.000 | Test loss: 2229791.500\nIteration: 412400 | Training Loss: 890390.688 | Test loss: 2229138.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 412600 | Training Loss: 890075.812 | Test loss: 2228539.250\nIteration: 412800 | Training Loss: 889761.188 | Test loss: 2227918.250\nIteration: 413000 | Training Loss: 889446.938 | Test loss: 2227295.750\nIteration: 413200 | Training Loss: 889132.938 | Test loss: 2226676.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 413400 | Training Loss: 888819.562 | Test loss: 2226047.250\nIteration: 413600 | Training Loss: 888506.812 | Test loss: 2225424.750\nIteration: 413800 | Training Loss: 888194.375 | Test loss: 2224799.500\nIteration: 414000 | Training Loss: 887882.250 | Test loss: 2224180.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 414200 | Training Loss: 887570.500 | Test loss: 2223558.000\nIteration: 414400 | Training Loss: 887259.125 | Test loss: 2222925.750\nIteration: 414600 | Training Loss: 886947.938 | Test loss: 2222311.000\nIteration: 414800 | Training Loss: 886637.188 | Test loss: 2221697.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 415000 | Training Loss: 886326.750 | Test loss: 2221079.500\nIteration: 415200 | Training Loss: 886016.562 | Test loss: 2220449.250\nIteration: 415400 | Training Loss: 885706.812 | Test loss: 2219843.500\nIteration: 415600 | Training Loss: 885397.375 | Test loss: 2219235.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 415800 | Training Loss: 885088.188 | Test loss: 2218618.750\nIteration: 416000 | Training Loss: 884779.438 | Test loss: 2217993.250\nIteration: 416200 | Training Loss: 884471.000 | Test loss: 2217379.000\nIteration: 416400 | Training Loss: 884162.875 | Test loss: 2216761.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 416600 | Training Loss: 883855.125 | Test loss: 2216147.250\nIteration: 416800 | Training Loss: 883547.625 | Test loss: 2215532.500\nIteration: 417000 | Training Loss: 883240.500 | Test loss: 2214927.500\nIteration: 417200 | Training Loss: 882933.688 | Test loss: 2214300.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 417400 | Training Loss: 882627.188 | Test loss: 2213692.000\nIteration: 417600 | Training Loss: 882321.062 | Test loss: 2213062.500\nIteration: 417800 | Training Loss: 882015.188 | Test loss: 2212470.250\nIteration: 418000 | Training Loss: 881709.688 | Test loss: 2211855.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 418200 | Training Loss: 881404.500 | Test loss: 2211250.500\nIteration: 418400 | Training Loss: 881099.562 | Test loss: 2210634.250\nIteration: 418600 | Training Loss: 880795.062 | Test loss: 2210030.250\nIteration: 418800 | Training Loss: 880490.875 | Test loss: 2209416.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 419000 | Training Loss: 880186.938 | Test loss: 2208815.000\nIteration: 419200 | Training Loss: 879883.438 | Test loss: 2208200.500\nIteration: 419400 | Training Loss: 879580.188 | Test loss: 2207604.500\nIteration: 419600 | Training Loss: 879277.250 | Test loss: 2206984.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 419800 | Training Loss: 878974.625 | Test loss: 2206377.000\nIteration: 420000 | Training Loss: 878672.375 | Test loss: 2205778.500\nIteration: 420200 | Training Loss: 878370.438 | Test loss: 2205173.750\nIteration: 420400 | Training Loss: 878068.875 | Test loss: 2204563.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 420600 | Training Loss: 877767.500 | Test loss: 2203960.000\nIteration: 420800 | Training Loss: 877466.562 | Test loss: 2203347.750\nIteration: 421000 | Training Loss: 877165.938 | Test loss: 2202746.500\nIteration: 421200 | Training Loss: 876865.625 | Test loss: 2202143.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 421400 | Training Loss: 876565.688 | Test loss: 2201544.750\nIteration: 421600 | Training Loss: 876265.938 | Test loss: 2200953.500\nIteration: 421800 | Training Loss: 875966.625 | Test loss: 2200339.000\nIteration: 422000 | Training Loss: 875667.562 | Test loss: 2199739.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 422200 | Training Loss: 875368.938 | Test loss: 2199137.250\nIteration: 422400 | Training Loss: 875070.562 | Test loss: 2198538.000\nIteration: 422600 | Training Loss: 874772.562 | Test loss: 2197937.500\nIteration: 422800 | Training Loss: 874474.938 | Test loss: 2197336.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 423000 | Training Loss: 874177.625 | Test loss: 2196753.500\nIteration: 423200 | Training Loss: 873880.625 | Test loss: 2196143.000\nIteration: 423400 | Training Loss: 873584.000 | Test loss: 2195567.000\nIteration: 423600 | Training Loss: 873287.688 | Test loss: 2194958.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 423800 | Training Loss: 872991.688 | Test loss: 2194354.500\nIteration: 424000 | Training Loss: 872696.000 | Test loss: 2193766.750\nIteration: 424200 | Training Loss: 872400.625 | Test loss: 2193171.250\nIteration: 424400 | Training Loss: 872105.562 | Test loss: 2192578.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 424600 | Training Loss: 871810.875 | Test loss: 2191998.000\nIteration: 424800 | Training Loss: 871516.500 | Test loss: 2191396.000\nIteration: 425000 | Training Loss: 871222.375 | Test loss: 2190812.750\nIteration: 425200 | Training Loss: 870928.625 | Test loss: 2190213.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 425400 | Training Loss: 870635.188 | Test loss: 2189630.500\nIteration: 425600 | Training Loss: 870342.062 | Test loss: 2189042.000\nIteration: 425800 | Training Loss: 870049.250 | Test loss: 2188456.500\nIteration: 426000 | Training Loss: 869756.750 | Test loss: 2187870.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 426200 | Training Loss: 869464.562 | Test loss: 2187281.000\nIteration: 426400 | Training Loss: 869172.688 | Test loss: 2186706.250\nIteration: 426600 | Training Loss: 868881.125 | Test loss: 2186126.750\nIteration: 426800 | Training Loss: 868589.875 | Test loss: 2185545.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 427000 | Training Loss: 868298.938 | Test loss: 2184981.500\nIteration: 427200 | Training Loss: 868008.312 | Test loss: 2184395.500\nIteration: 427400 | Training Loss: 867718.062 | Test loss: 2183820.500\nIteration: 427600 | Training Loss: 867428.062 | Test loss: 2183265.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 427800 | Training Loss: 867138.438 | Test loss: 2182697.500\nIteration: 428000 | Training Loss: 866849.062 | Test loss: 2182105.250\nIteration: 428200 | Training Loss: 866560.000 | Test loss: 2181541.750\nIteration: 428400 | Training Loss: 866271.250 | Test loss: 2180975.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 428600 | Training Loss: 865982.875 | Test loss: 2180398.000\nIteration: 428800 | Training Loss: 865694.688 | Test loss: 2179846.250\nIteration: 429000 | Training Loss: 865406.875 | Test loss: 2179268.750\nIteration: 429200 | Training Loss: 865119.375 | Test loss: 2178699.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 429400 | Training Loss: 864832.250 | Test loss: 2178127.250\nIteration: 429600 | Training Loss: 864545.312 | Test loss: 2177576.250\nIteration: 429800 | Training Loss: 864258.812 | Test loss: 2177000.000\nIteration: 430000 | Training Loss: 863972.562 | Test loss: 2176437.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 430200 | Training Loss: 863686.625 | Test loss: 2175874.250\nIteration: 430400 | Training Loss: 863401.000 | Test loss: 2175313.750\nIteration: 430600 | Training Loss: 863115.750 | Test loss: 2174754.000\nIteration: 430800 | Training Loss: 862830.812 | Test loss: 2174172.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 431000 | Training Loss: 862546.250 | Test loss: 2173620.250\nIteration: 431200 | Training Loss: 862262.000 | Test loss: 2173065.500\nIteration: 431400 | Training Loss: 861978.000 | Test loss: 2172501.000\nIteration: 431600 | Training Loss: 861694.375 | Test loss: 2171942.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 431800 | Training Loss: 861411.000 | Test loss: 2171384.000\nIteration: 432000 | Training Loss: 861127.938 | Test loss: 2170823.500\nIteration: 432200 | Training Loss: 860845.188 | Test loss: 2170266.250\nIteration: 432400 | Training Loss: 860562.812 | Test loss: 2169710.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 432600 | Training Loss: 860280.688 | Test loss: 2169163.000\nIteration: 432800 | Training Loss: 859998.875 | Test loss: 2168595.500\nIteration: 433000 | Training Loss: 859717.375 | Test loss: 2168037.250\nIteration: 433200 | Training Loss: 859436.188 | Test loss: 2167481.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 433400 | Training Loss: 859155.250 | Test loss: 2166932.250\nIteration: 433600 | Training Loss: 858874.688 | Test loss: 2166372.500\nIteration: 433800 | Training Loss: 858594.438 | Test loss: 2165817.000\nIteration: 434000 | Training Loss: 858314.438 | Test loss: 2165272.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 434200 | Training Loss: 858034.750 | Test loss: 2164714.000\nIteration: 434400 | Training Loss: 857755.438 | Test loss: 2164161.000\nIteration: 434600 | Training Loss: 857476.312 | Test loss: 2163607.750\nIteration: 434800 | Training Loss: 857197.625 | Test loss: 2163040.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 435000 | Training Loss: 856919.125 | Test loss: 2162508.750\nIteration: 435200 | Training Loss: 856641.000 | Test loss: 2161961.250\nIteration: 435400 | Training Loss: 856363.188 | Test loss: 2161408.500\nIteration: 435600 | Training Loss: 856085.562 | Test loss: 2160864.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 435800 | Training Loss: 855808.375 | Test loss: 2160316.250\nIteration: 436000 | Training Loss: 855531.438 | Test loss: 2159766.500\nIteration: 436200 | Training Loss: 855254.750 | Test loss: 2159215.250\nIteration: 436400 | Training Loss: 854978.562 | Test loss: 2158675.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 436600 | Training Loss: 854702.875 | Test loss: 2158127.000\nIteration: 436800 | Training Loss: 854427.438 | Test loss: 2157565.500\nIteration: 437000 | Training Loss: 854152.312 | Test loss: 2157058.000\nIteration: 437200 | Training Loss: 853877.375 | Test loss: 2156500.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 437400 | Training Loss: 853602.750 | Test loss: 2155942.250\nIteration: 437600 | Training Loss: 853328.312 | Test loss: 2155425.500\nIteration: 437800 | Training Loss: 853054.188 | Test loss: 2154873.500\nIteration: 438000 | Training Loss: 852780.312 | Test loss: 2154328.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 438200 | Training Loss: 852506.562 | Test loss: 2153807.500\nIteration: 438400 | Training Loss: 852233.125 | Test loss: 2153267.000\nIteration: 438600 | Training Loss: 851959.812 | Test loss: 2152723.500\nIteration: 438800 | Training Loss: 851686.750 | Test loss: 2152189.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 439000 | Training Loss: 851413.625 | Test loss: 2151652.250\nIteration: 439200 | Training Loss: 851140.438 | Test loss: 2151109.500\nIteration: 439400 | Training Loss: 850867.375 | Test loss: 2150567.750\nIteration: 439600 | Training Loss: 850594.625 | Test loss: 2150035.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 439800 | Training Loss: 850322.000 | Test loss: 2149505.000\nIteration: 440000 | Training Loss: 850049.625 | Test loss: 2148955.000\nIteration: 440200 | Training Loss: 849777.438 | Test loss: 2148416.250\nIteration: 440400 | Training Loss: 849505.562 | Test loss: 2147875.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 440600 | Training Loss: 849233.812 | Test loss: 2147348.750\nIteration: 440800 | Training Loss: 848962.375 | Test loss: 2146797.500\nIteration: 441000 | Training Loss: 848691.062 | Test loss: 2146269.750\nIteration: 441200 | Training Loss: 848420.125 | Test loss: 2145720.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 441400 | Training Loss: 848149.250 | Test loss: 2145179.000\nIteration: 441600 | Training Loss: 847878.625 | Test loss: 2144638.250\nIteration: 441800 | Training Loss: 847608.312 | Test loss: 2144102.000\nIteration: 442000 | Training Loss: 847338.125 | Test loss: 2143566.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 442200 | Training Loss: 847068.188 | Test loss: 2143028.500\nIteration: 442400 | Training Loss: 846798.500 | Test loss: 2142500.750\nIteration: 442600 | Training Loss: 846529.000 | Test loss: 2141950.750\nIteration: 442800 | Training Loss: 846259.688 | Test loss: 2141403.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 443000 | Training Loss: 845990.625 | Test loss: 2140870.000\nIteration: 443200 | Training Loss: 845721.875 | Test loss: 2140340.500\nIteration: 443400 | Training Loss: 845453.188 | Test loss: 2139801.500\nIteration: 443600 | Training Loss: 845184.875 | Test loss: 2139263.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 443800 | Training Loss: 844916.625 | Test loss: 2138725.750\nIteration: 444000 | Training Loss: 844648.750 | Test loss: 2138176.750\nIteration: 444200 | Training Loss: 844381.000 | Test loss: 2137653.750\nIteration: 444400 | Training Loss: 844113.500 | Test loss: 2137119.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 444600 | Training Loss: 843846.188 | Test loss: 2136594.000\nIteration: 444800 | Training Loss: 843579.312 | Test loss: 2136054.000\nIteration: 445000 | Training Loss: 843313.000 | Test loss: 2135520.250\nIteration: 445200 | Training Loss: 843046.938 | Test loss: 2134984.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 445400 | Training Loss: 842781.125 | Test loss: 2134446.250\nIteration: 445600 | Training Loss: 842515.562 | Test loss: 2133913.750\nIteration: 445800 | Training Loss: 842250.125 | Test loss: 2133383.250\nIteration: 446000 | Training Loss: 841984.938 | Test loss: 2132846.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 446200 | Training Loss: 841720.000 | Test loss: 2132318.250\nIteration: 446400 | Training Loss: 841455.250 | Test loss: 2131785.250\nIteration: 446600 | Training Loss: 841190.750 | Test loss: 2131264.500\nIteration: 446800 | Training Loss: 840926.438 | Test loss: 2130723.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 447000 | Training Loss: 840662.312 | Test loss: 2130214.000\nIteration: 447200 | Training Loss: 840398.500 | Test loss: 2129661.250\nIteration: 447400 | Training Loss: 840134.875 | Test loss: 2129131.250\nIteration: 447600 | Training Loss: 839871.438 | Test loss: 2128603.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 447800 | Training Loss: 839608.250 | Test loss: 2128079.000\nIteration: 448000 | Training Loss: 839345.188 | Test loss: 2127549.750\nIteration: 448200 | Training Loss: 839082.438 | Test loss: 2127008.250\nIteration: 448400 | Training Loss: 838819.875 | Test loss: 2126490.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 448600 | Training Loss: 838557.500 | Test loss: 2125981.500\nIteration: 448800 | Training Loss: 838295.438 | Test loss: 2125445.000\nIteration: 449000 | Training Loss: 838033.500 | Test loss: 2124917.500\nIteration: 449200 | Training Loss: 837771.875 | Test loss: 2124399.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 449400 | Training Loss: 837510.438 | Test loss: 2123872.000\nIteration: 449600 | Training Loss: 837249.188 | Test loss: 2123337.000\nIteration: 449800 | Training Loss: 836988.125 | Test loss: 2122828.500\nIteration: 450000 | Training Loss: 836727.375 | Test loss: 2122313.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 450200 | Training Loss: 836466.750 | Test loss: 2121788.000\nIteration: 450400 | Training Loss: 836206.375 | Test loss: 2121279.750\nIteration: 450600 | Training Loss: 835946.250 | Test loss: 2120764.250\nIteration: 450800 | Training Loss: 835686.250 | Test loss: 2120256.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 451000 | Training Loss: 835426.500 | Test loss: 2119740.750\nIteration: 451200 | Training Loss: 835166.938 | Test loss: 2119225.750\nIteration: 451400 | Training Loss: 834907.562 | Test loss: 2118730.750\nIteration: 451600 | Training Loss: 834648.375 | Test loss: 2118228.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 451800 | Training Loss: 834389.438 | Test loss: 2117724.250\nIteration: 452000 | Training Loss: 834130.562 | Test loss: 2117232.750\nIteration: 452200 | Training Loss: 833871.625 | Test loss: 2116729.000\nIteration: 452400 | Training Loss: 833612.812 | Test loss: 2116228.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 452600 | Training Loss: 833354.250 | Test loss: 2115730.000\nIteration: 452800 | Training Loss: 833095.875 | Test loss: 2115239.250\nIteration: 453000 | Training Loss: 832837.688 | Test loss: 2114750.750\nIteration: 453200 | Training Loss: 832579.688 | Test loss: 2114255.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 453400 | Training Loss: 832321.875 | Test loss: 2113761.000\nIteration: 453600 | Training Loss: 832064.312 | Test loss: 2113271.500\nIteration: 453800 | Training Loss: 831806.938 | Test loss: 2112780.000\nIteration: 454000 | Training Loss: 831549.750 | Test loss: 2112292.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 454200 | Training Loss: 831292.750 | Test loss: 2111797.750\nIteration: 454400 | Training Loss: 831036.000 | Test loss: 2111315.500\nIteration: 454600 | Training Loss: 830779.438 | Test loss: 2110828.750\nIteration: 454800 | Training Loss: 830523.062 | Test loss: 2110325.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 455000 | Training Loss: 830266.812 | Test loss: 2109853.500\nIteration: 455200 | Training Loss: 830010.875 | Test loss: 2109358.500\nIteration: 455400 | Training Loss: 829755.062 | Test loss: 2108866.250\nIteration: 455600 | Training Loss: 829499.500 | Test loss: 2108384.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 455800 | Training Loss: 829244.125 | Test loss: 2107891.750\nIteration: 456000 | Training Loss: 828988.938 | Test loss: 2107413.500\nIteration: 456200 | Training Loss: 828734.000 | Test loss: 2106925.500\nIteration: 456400 | Training Loss: 828479.188 | Test loss: 2106439.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 456600 | Training Loss: 828224.688 | Test loss: 2105952.500\nIteration: 456800 | Training Loss: 827970.312 | Test loss: 2105472.000\nIteration: 457000 | Training Loss: 827716.125 | Test loss: 2104986.000\nIteration: 457200 | Training Loss: 827462.188 | Test loss: 2104514.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 457400 | Training Loss: 827208.438 | Test loss: 2104015.000\nIteration: 457600 | Training Loss: 826954.875 | Test loss: 2103535.750\nIteration: 457800 | Training Loss: 826701.500 | Test loss: 2103049.000\nIteration: 458000 | Training Loss: 826448.312 | Test loss: 2102559.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 458200 | Training Loss: 826195.375 | Test loss: 2102084.000\nIteration: 458400 | Training Loss: 825942.750 | Test loss: 2101602.500\nIteration: 458600 | Training Loss: 825690.375 | Test loss: 2101120.750\nIteration: 458800 | Training Loss: 825438.250 | Test loss: 2100635.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 459000 | Training Loss: 825186.312 | Test loss: 2100156.500\nIteration: 459200 | Training Loss: 824934.562 | Test loss: 2099679.250\nIteration: 459400 | Training Loss: 824683.062 | Test loss: 2099211.000\nIteration: 459600 | Training Loss: 824431.688 | Test loss: 2098721.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 459800 | Training Loss: 824180.500 | Test loss: 2098239.000\nIteration: 460000 | Training Loss: 823929.562 | Test loss: 2097767.250\nIteration: 460200 | Training Loss: 823678.812 | Test loss: 2097284.250\nIteration: 460400 | Training Loss: 823428.250 | Test loss: 2096805.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 460600 | Training Loss: 823177.875 | Test loss: 2096342.625\nIteration: 460800 | Training Loss: 822927.688 | Test loss: 2095861.250\nIteration: 461000 | Training Loss: 822677.750 | Test loss: 2095382.875\nIteration: 461200 | Training Loss: 822427.938 | Test loss: 2094907.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 461400 | Training Loss: 822178.312 | Test loss: 2094430.000\nIteration: 461600 | Training Loss: 821928.938 | Test loss: 2093963.500\nIteration: 461800 | Training Loss: 821679.750 | Test loss: 2093489.375\nIteration: 462000 | Training Loss: 821430.688 | Test loss: 2093021.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 462200 | Training Loss: 821181.875 | Test loss: 2092545.125\nIteration: 462400 | Training Loss: 820933.188 | Test loss: 2092086.625\nIteration: 462600 | Training Loss: 820684.688 | Test loss: 2091619.750\nIteration: 462800 | Training Loss: 820436.500 | Test loss: 2091148.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 463000 | Training Loss: 820188.375 | Test loss: 2090690.000\nIteration: 463200 | Training Loss: 819940.438 | Test loss: 2090225.875\nIteration: 463400 | Training Loss: 819692.688 | Test loss: 2089754.375\nIteration: 463600 | Training Loss: 819445.188 | Test loss: 2089288.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 463800 | Training Loss: 819197.812 | Test loss: 2088836.250\nIteration: 464000 | Training Loss: 818950.562 | Test loss: 2088384.750\nIteration: 464200 | Training Loss: 818703.562 | Test loss: 2087919.250\nIteration: 464400 | Training Loss: 818456.312 | Test loss: 2087481.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 464600 | Training Loss: 818208.875 | Test loss: 2087035.250\nIteration: 464800 | Training Loss: 817961.625 | Test loss: 2086602.875\nIteration: 465000 | Training Loss: 817714.500 | Test loss: 2086165.500\nIteration: 465200 | Training Loss: 817467.500 | Test loss: 2085717.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 465400 | Training Loss: 817220.688 | Test loss: 2085294.875\nIteration: 465600 | Training Loss: 816974.000 | Test loss: 2084857.125\nIteration: 465800 | Training Loss: 816727.500 | Test loss: 2084427.750\nIteration: 466000 | Training Loss: 816481.125 | Test loss: 2084002.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 466200 | Training Loss: 816234.938 | Test loss: 2083573.500\nIteration: 466400 | Training Loss: 815988.938 | Test loss: 2083150.500\nIteration: 466600 | Training Loss: 815743.125 | Test loss: 2082719.250\nIteration: 466800 | Training Loss: 815497.438 | Test loss: 2082310.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 467000 | Training Loss: 815251.875 | Test loss: 2081872.000\nIteration: 467200 | Training Loss: 815006.562 | Test loss: 2081442.875\nIteration: 467400 | Training Loss: 814761.312 | Test loss: 2081025.250\nIteration: 467600 | Training Loss: 814516.250 | Test loss: 2080609.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 467800 | Training Loss: 814271.312 | Test loss: 2080179.875\nIteration: 468000 | Training Loss: 814026.562 | Test loss: 2079745.375\nIteration: 468200 | Training Loss: 813781.938 | Test loss: 2079329.250\nIteration: 468400 | Training Loss: 813537.438 | Test loss: 2078906.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 468600 | Training Loss: 813293.188 | Test loss: 2078481.750\nIteration: 468800 | Training Loss: 813049.062 | Test loss: 2078056.625\nIteration: 469000 | Training Loss: 812805.062 | Test loss: 2077626.625\nIteration: 469200 | Training Loss: 812561.250 | Test loss: 2077204.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 469400 | Training Loss: 812317.562 | Test loss: 2076784.000\nIteration: 469600 | Training Loss: 812074.062 | Test loss: 2076382.500\nIteration: 469800 | Training Loss: 811830.688 | Test loss: 2075947.500\nIteration: 470000 | Training Loss: 811587.500 | Test loss: 2075526.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 470200 | Training Loss: 811344.375 | Test loss: 2075108.125\nIteration: 470400 | Training Loss: 811101.500 | Test loss: 2074682.875\nIteration: 470600 | Training Loss: 810858.750 | Test loss: 2074261.250\nIteration: 470800 | Training Loss: 810616.188 | Test loss: 2073838.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 471000 | Training Loss: 810373.750 | Test loss: 2073423.875\nIteration: 471200 | Training Loss: 810131.500 | Test loss: 2072994.500\nIteration: 471400 | Training Loss: 809889.375 | Test loss: 2072577.750\nIteration: 471600 | Training Loss: 809647.438 | Test loss: 2072154.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 471800 | Training Loss: 809405.562 | Test loss: 2071732.875\nIteration: 472000 | Training Loss: 809163.938 | Test loss: 2071320.125\nIteration: 472200 | Training Loss: 808922.375 | Test loss: 2070879.625\nIteration: 472400 | Training Loss: 808681.250 | Test loss: 2070479.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 472600 | Training Loss: 808440.188 | Test loss: 2070056.500\nIteration: 472800 | Training Loss: 808199.375 | Test loss: 2069632.750\nIteration: 473000 | Training Loss: 807958.688 | Test loss: 2069217.375\nIteration: 473200 | Training Loss: 807718.250 | Test loss: 2068790.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 473400 | Training Loss: 807477.875 | Test loss: 2068383.000\nIteration: 473600 | Training Loss: 807237.688 | Test loss: 2067956.250\nIteration: 473800 | Training Loss: 806997.625 | Test loss: 2067540.875\nIteration: 474000 | Training Loss: 806757.750 | Test loss: 2067113.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 474200 | Training Loss: 806518.000 | Test loss: 2066702.875\nIteration: 474400 | Training Loss: 806278.438 | Test loss: 2066282.500\nIteration: 474600 | Training Loss: 806039.000 | Test loss: 2065863.750\nIteration: 474800 | Training Loss: 805799.750 | Test loss: 2065445.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 475000 | Training Loss: 805560.625 | Test loss: 2065028.125\nIteration: 475200 | Training Loss: 805321.625 | Test loss: 2064609.625\nIteration: 475400 | Training Loss: 805082.812 | Test loss: 2064199.875\nIteration: 475600 | Training Loss: 804844.188 | Test loss: 2063776.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 475800 | Training Loss: 804605.625 | Test loss: 2063355.375\nIteration: 476000 | Training Loss: 804367.375 | Test loss: 2062941.625\nIteration: 476200 | Training Loss: 804129.125 | Test loss: 2062511.250\nIteration: 476400 | Training Loss: 803891.125 | Test loss: 2062102.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 476600 | Training Loss: 803653.188 | Test loss: 2061684.500\nIteration: 476800 | Training Loss: 803415.500 | Test loss: 2061271.125\nIteration: 477000 | Training Loss: 803177.938 | Test loss: 2060856.250\nIteration: 477200 | Training Loss: 802940.562 | Test loss: 2060446.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 477400 | Training Loss: 802703.250 | Test loss: 2060028.250\nIteration: 477600 | Training Loss: 802466.188 | Test loss: 2059608.250\nIteration: 477800 | Training Loss: 802229.125 | Test loss: 2059197.500\nIteration: 478000 | Training Loss: 801992.438 | Test loss: 2058781.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 478200 | Training Loss: 801755.688 | Test loss: 2058368.500\nIteration: 478400 | Training Loss: 801519.250 | Test loss: 2057954.375\nIteration: 478600 | Training Loss: 801282.875 | Test loss: 2057536.750\nIteration: 478800 | Training Loss: 801046.750 | Test loss: 2057127.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 479000 | Training Loss: 800810.688 | Test loss: 2056709.250\nIteration: 479200 | Training Loss: 800574.812 | Test loss: 2056298.875\nIteration: 479400 | Training Loss: 800339.062 | Test loss: 2055892.250\nIteration: 479600 | Training Loss: 800103.562 | Test loss: 2055471.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 479800 | Training Loss: 799868.125 | Test loss: 2055041.250\nIteration: 480000 | Training Loss: 799632.875 | Test loss: 2054643.375\nIteration: 480200 | Training Loss: 799397.812 | Test loss: 2054230.250\nIteration: 480400 | Training Loss: 799162.812 | Test loss: 2053815.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 480600 | Training Loss: 798928.000 | Test loss: 2053405.125\nIteration: 480800 | Training Loss: 798693.438 | Test loss: 2052995.750\nIteration: 481000 | Training Loss: 798458.875 | Test loss: 2052583.625\nIteration: 481200 | Training Loss: 798224.625 | Test loss: 2052165.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 481400 | Training Loss: 797990.438 | Test loss: 2051759.750\nIteration: 481600 | Training Loss: 797756.438 | Test loss: 2051348.750\nIteration: 481800 | Training Loss: 797522.500 | Test loss: 2050935.875\nIteration: 482000 | Training Loss: 797288.875 | Test loss: 2050524.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 482200 | Training Loss: 797055.250 | Test loss: 2050114.125\nIteration: 482400 | Training Loss: 796821.875 | Test loss: 2049695.875\nIteration: 482600 | Training Loss: 796588.688 | Test loss: 2049292.500\nIteration: 482800 | Training Loss: 796355.625 | Test loss: 2048883.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 483000 | Training Loss: 796122.625 | Test loss: 2048471.625\nIteration: 483200 | Training Loss: 795889.875 | Test loss: 2048057.750\nIteration: 483400 | Training Loss: 795657.250 | Test loss: 2047648.875\nIteration: 483600 | Training Loss: 795424.812 | Test loss: 2047239.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 483800 | Training Loss: 795192.438 | Test loss: 2046835.750\nIteration: 484000 | Training Loss: 794960.312 | Test loss: 2046419.750\nIteration: 484200 | Training Loss: 794728.312 | Test loss: 2046009.000\nIteration: 484400 | Training Loss: 794496.500 | Test loss: 2045598.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 484600 | Training Loss: 794264.750 | Test loss: 2045196.875\nIteration: 484800 | Training Loss: 794033.250 | Test loss: 2044787.625\nIteration: 485000 | Training Loss: 793801.875 | Test loss: 2044372.500\nIteration: 485200 | Training Loss: 793570.625 | Test loss: 2043966.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 485400 | Training Loss: 793339.562 | Test loss: 2043556.000\nIteration: 485600 | Training Loss: 793108.625 | Test loss: 2043143.750\nIteration: 485800 | Training Loss: 792877.875 | Test loss: 2042741.000\nIteration: 486000 | Training Loss: 792647.250 | Test loss: 2042334.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 486200 | Training Loss: 792416.812 | Test loss: 2041928.125\nIteration: 486400 | Training Loss: 792186.562 | Test loss: 2041517.500\nIteration: 486600 | Training Loss: 791956.438 | Test loss: 2041110.125\nIteration: 486800 | Training Loss: 791726.438 | Test loss: 2040706.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 487000 | Training Loss: 791496.562 | Test loss: 2040298.500\nIteration: 487200 | Training Loss: 791266.938 | Test loss: 2039891.000\nIteration: 487400 | Training Loss: 791037.375 | Test loss: 2039494.125\nIteration: 487600 | Training Loss: 790808.000 | Test loss: 2039079.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 487800 | Training Loss: 790578.812 | Test loss: 2038673.125\nIteration: 488000 | Training Loss: 790349.750 | Test loss: 2038266.000\nIteration: 488200 | Training Loss: 790120.812 | Test loss: 2037861.750\nIteration: 488400 | Training Loss: 789892.125 | Test loss: 2037460.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 488600 | Training Loss: 789663.438 | Test loss: 2037050.875\nIteration: 488800 | Training Loss: 789435.062 | Test loss: 2036642.125\nIteration: 489000 | Training Loss: 789206.750 | Test loss: 2036237.625\nIteration: 489200 | Training Loss: 788978.625 | Test loss: 2035848.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 489400 | Training Loss: 788750.625 | Test loss: 2035429.500\nIteration: 489600 | Training Loss: 788522.875 | Test loss: 2035043.500\nIteration: 489800 | Training Loss: 788295.188 | Test loss: 2034620.250\nIteration: 490000 | Training Loss: 788067.625 | Test loss: 2034221.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 490200 | Training Loss: 787840.250 | Test loss: 2033816.000\nIteration: 490400 | Training Loss: 787613.062 | Test loss: 2033410.000\nIteration: 490600 | Training Loss: 787386.000 | Test loss: 2033010.375\nIteration: 490800 | Training Loss: 787159.125 | Test loss: 2032613.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 491000 | Training Loss: 786932.375 | Test loss: 2032203.000\nIteration: 491200 | Training Loss: 786705.812 | Test loss: 2031813.875\nIteration: 491400 | Training Loss: 786479.375 | Test loss: 2031403.625\nIteration: 491600 | Training Loss: 786253.062 | Test loss: 2030992.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 491800 | Training Loss: 786026.938 | Test loss: 2030593.000\nIteration: 492000 | Training Loss: 785801.000 | Test loss: 2030192.875\nIteration: 492200 | Training Loss: 785575.125 | Test loss: 2029794.000\nIteration: 492400 | Training Loss: 785349.562 | Test loss: 2029392.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 492600 | Training Loss: 785124.062 | Test loss: 2028986.750\nIteration: 492800 | Training Loss: 784898.688 | Test loss: 2028587.250\nIteration: 493000 | Training Loss: 784673.438 | Test loss: 2028198.000\nIteration: 493200 | Training Loss: 784448.438 | Test loss: 2027782.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 493400 | Training Loss: 784223.562 | Test loss: 2027387.000\nIteration: 493600 | Training Loss: 783998.812 | Test loss: 2026982.625\nIteration: 493800 | Training Loss: 783774.250 | Test loss: 2026585.250\nIteration: 494000 | Training Loss: 783549.875 | Test loss: 2026185.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 494200 | Training Loss: 783325.562 | Test loss: 2025795.875\nIteration: 494400 | Training Loss: 783101.438 | Test loss: 2025385.875\nIteration: 494600 | Training Loss: 782877.438 | Test loss: 2024988.625\nIteration: 494800 | Training Loss: 782653.688 | Test loss: 2024587.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 495000 | Training Loss: 782430.000 | Test loss: 2024191.500\nIteration: 495200 | Training Loss: 782206.562 | Test loss: 2023792.125\nIteration: 495400 | Training Loss: 781983.250 | Test loss: 2023394.125\nIteration: 495600 | Training Loss: 781760.250 | Test loss: 2022998.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 495800 | Training Loss: 781537.312 | Test loss: 2022596.500\nIteration: 496000 | Training Loss: 781314.625 | Test loss: 2022205.250\nIteration: 496200 | Training Loss: 781092.062 | Test loss: 2021805.125\nIteration: 496400 | Training Loss: 780869.750 | Test loss: 2021405.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 496600 | Training Loss: 780647.562 | Test loss: 2021011.375\nIteration: 496800 | Training Loss: 780425.562 | Test loss: 2020611.750\nIteration: 497000 | Training Loss: 780203.688 | Test loss: 2020218.375\nIteration: 497200 | Training Loss: 779982.000 | Test loss: 2019816.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 497400 | Training Loss: 779760.500 | Test loss: 2019419.375\nIteration: 497600 | Training Loss: 779539.125 | Test loss: 2019031.500\nIteration: 497800 | Training Loss: 779317.938 | Test loss: 2018630.500\nIteration: 498000 | Training Loss: 779096.875 | Test loss: 2018239.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 498200 | Training Loss: 778876.000 | Test loss: 2017841.375\nIteration: 498400 | Training Loss: 778655.250 | Test loss: 2017445.000\nIteration: 498600 | Training Loss: 778434.625 | Test loss: 2017047.250\nIteration: 498800 | Training Loss: 778214.250 | Test loss: 2016647.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 499000 | Training Loss: 777993.875 | Test loss: 2016261.875\nIteration: 499200 | Training Loss: 777773.812 | Test loss: 2015857.625\nIteration: 499400 | Training Loss: 777553.750 | Test loss: 2015479.125\nIteration: 499600 | Training Loss: 777333.938 | Test loss: 2015083.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 499800 | Training Loss: 777114.250 | Test loss: 2014685.625\nIteration: 500000 | Training Loss: 776894.812 | Test loss: 2014292.000\nIteration: 500200 | Training Loss: 776675.375 | Test loss: 2013900.625\nIteration: 500400 | Training Loss: 776456.188 | Test loss: 2013502.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 500600 | Training Loss: 776237.125 | Test loss: 2013111.000\nIteration: 500800 | Training Loss: 776018.250 | Test loss: 2012720.500\nIteration: 501000 | Training Loss: 775799.438 | Test loss: 2012326.625\nIteration: 501200 | Training Loss: 775580.875 | Test loss: 2011933.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 501400 | Training Loss: 775362.438 | Test loss: 2011546.750\nIteration: 501600 | Training Loss: 775144.188 | Test loss: 2011143.500\nIteration: 501800 | Training Loss: 774926.000 | Test loss: 2010754.500\nIteration: 502000 | Training Loss: 774708.250 | Test loss: 2010365.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 502200 | Training Loss: 774491.000 | Test loss: 2009977.250\nIteration: 502400 | Training Loss: 774274.312 | Test loss: 2009588.625\nIteration: 502600 | Training Loss: 774058.062 | Test loss: 2009198.125\nIteration: 502800 | Training Loss: 773842.812 | Test loss: 2008810.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 503000 | Training Loss: 773627.812 | Test loss: 2008423.500\nIteration: 503200 | Training Loss: 773414.188 | Test loss: 2008036.750\nIteration: 503400 | Training Loss: 773200.812 | Test loss: 2007652.000\nIteration: 503600 | Training Loss: 772987.688 | Test loss: 2007265.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 503800 | Training Loss: 772774.625 | Test loss: 2006892.625\nIteration: 504000 | Training Loss: 772561.750 | Test loss: 2006502.125\nIteration: 504200 | Training Loss: 772348.938 | Test loss: 2006120.000\nIteration: 504400 | Training Loss: 772136.375 | Test loss: 2005738.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 504600 | Training Loss: 771923.875 | Test loss: 2005351.250\nIteration: 504800 | Training Loss: 771711.562 | Test loss: 2004970.250\nIteration: 505000 | Training Loss: 771499.375 | Test loss: 2004593.875\nIteration: 505200 | Training Loss: 771287.438 | Test loss: 2004209.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 505400 | Training Loss: 771075.500 | Test loss: 2003825.375\nIteration: 505600 | Training Loss: 770863.875 | Test loss: 2003454.125\nIteration: 505800 | Training Loss: 770652.250 | Test loss: 2003063.250\nIteration: 506000 | Training Loss: 770440.938 | Test loss: 2002668.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 506200 | Training Loss: 770229.625 | Test loss: 2002303.125\nIteration: 506400 | Training Loss: 770018.562 | Test loss: 2001914.875\nIteration: 506600 | Training Loss: 769807.812 | Test loss: 2001532.875\nIteration: 506800 | Training Loss: 769597.375 | Test loss: 2001145.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 507000 | Training Loss: 769387.062 | Test loss: 2000770.500\nIteration: 507200 | Training Loss: 769176.938 | Test loss: 2000394.250\nIteration: 507400 | Training Loss: 768966.938 | Test loss: 2000013.000\nIteration: 507600 | Training Loss: 768757.125 | Test loss: 1999627.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 507800 | Training Loss: 768547.375 | Test loss: 1999250.125\nIteration: 508000 | Training Loss: 768337.812 | Test loss: 1998875.750\nIteration: 508200 | Training Loss: 768128.438 | Test loss: 1998493.875\nIteration: 508400 | Training Loss: 767919.125 | Test loss: 1998113.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 508600 | Training Loss: 767710.062 | Test loss: 1997734.000\nIteration: 508800 | Training Loss: 767501.125 | Test loss: 1997350.500\nIteration: 509000 | Training Loss: 767292.312 | Test loss: 1996990.250\nIteration: 509200 | Training Loss: 767083.625 | Test loss: 1996600.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 509400 | Training Loss: 766875.125 | Test loss: 1996222.125\nIteration: 509600 | Training Loss: 766666.688 | Test loss: 1995844.500\nIteration: 509800 | Training Loss: 766458.500 | Test loss: 1995466.750\nIteration: 510000 | Training Loss: 766250.750 | Test loss: 1995093.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 510200 | Training Loss: 766043.562 | Test loss: 1994713.125\nIteration: 510400 | Training Loss: 765836.500 | Test loss: 1994329.875\nIteration: 510600 | Training Loss: 765629.625 | Test loss: 1993955.875\nIteration: 510800 | Training Loss: 765422.875 | Test loss: 1993580.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 511000 | Training Loss: 765216.188 | Test loss: 1993198.375\nIteration: 511200 | Training Loss: 765009.750 | Test loss: 1992830.750\nIteration: 511400 | Training Loss: 764803.375 | Test loss: 1992449.750\nIteration: 511600 | Training Loss: 764597.250 | Test loss: 1992072.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 511800 | Training Loss: 764391.188 | Test loss: 1991694.125\nIteration: 512000 | Training Loss: 764185.375 | Test loss: 1991320.750\nIteration: 512200 | Training Loss: 763979.625 | Test loss: 1990939.375\nIteration: 512400 | Training Loss: 763774.000 | Test loss: 1990567.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 512600 | Training Loss: 763568.562 | Test loss: 1990193.250\nIteration: 512800 | Training Loss: 763363.312 | Test loss: 1989818.750\nIteration: 513000 | Training Loss: 763158.125 | Test loss: 1989444.250\nIteration: 513200 | Training Loss: 762953.125 | Test loss: 1989071.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 513400 | Training Loss: 762748.250 | Test loss: 1988694.250\nIteration: 513600 | Training Loss: 762543.562 | Test loss: 1988319.875\nIteration: 513800 | Training Loss: 762339.000 | Test loss: 1987955.875\nIteration: 514000 | Training Loss: 762134.625 | Test loss: 1987571.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 514200 | Training Loss: 761930.312 | Test loss: 1987199.125\nIteration: 514400 | Training Loss: 761726.188 | Test loss: 1986824.125\nIteration: 514600 | Training Loss: 761522.188 | Test loss: 1986449.875\nIteration: 514800 | Training Loss: 761318.438 | Test loss: 1986079.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 515000 | Training Loss: 761114.750 | Test loss: 1985705.500\nIteration: 515200 | Training Loss: 760911.312 | Test loss: 1985330.125\nIteration: 515400 | Training Loss: 760707.938 | Test loss: 1984960.875\nIteration: 515600 | Training Loss: 760504.750 | Test loss: 1984589.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 515800 | Training Loss: 760301.750 | Test loss: 1984218.500\nIteration: 516000 | Training Loss: 760099.188 | Test loss: 1983850.250\nIteration: 516200 | Training Loss: 759896.875 | Test loss: 1983481.500\nIteration: 516400 | Training Loss: 759694.750 | Test loss: 1983113.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 516600 | Training Loss: 759492.750 | Test loss: 1982746.000\nIteration: 516800 | Training Loss: 759290.938 | Test loss: 1982370.875\nIteration: 517000 | Training Loss: 759089.250 | Test loss: 1982012.625\nIteration: 517200 | Training Loss: 758887.688 | Test loss: 1981641.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 517400 | Training Loss: 758686.312 | Test loss: 1981278.125\nIteration: 517600 | Training Loss: 758485.062 | Test loss: 1980905.250\nIteration: 517800 | Training Loss: 758283.938 | Test loss: 1980539.500\nIteration: 518000 | Training Loss: 758083.000 | Test loss: 1980171.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 518200 | Training Loss: 757882.188 | Test loss: 1979805.875\nIteration: 518400 | Training Loss: 757681.562 | Test loss: 1979440.125\nIteration: 518600 | Training Loss: 757481.062 | Test loss: 1979076.125\nIteration: 518800 | Training Loss: 757280.625 | Test loss: 1978707.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 519000 | Training Loss: 757080.375 | Test loss: 1978342.750\nIteration: 519200 | Training Loss: 756880.312 | Test loss: 1977974.750\nIteration: 519400 | Training Loss: 756680.375 | Test loss: 1977609.250\nIteration: 519600 | Training Loss: 756480.625 | Test loss: 1977246.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 519800 | Training Loss: 756280.938 | Test loss: 1976879.750\nIteration: 520000 | Training Loss: 756081.438 | Test loss: 1976514.000\nIteration: 520200 | Training Loss: 755882.062 | Test loss: 1976151.250\nIteration: 520400 | Training Loss: 755682.812 | Test loss: 1975782.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 520600 | Training Loss: 755483.438 | Test loss: 1975411.000\nIteration: 520800 | Training Loss: 755284.250 | Test loss: 1975054.125\nIteration: 521000 | Training Loss: 755085.188 | Test loss: 1974687.375\nIteration: 521200 | Training Loss: 754886.250 | Test loss: 1974324.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 521400 | Training Loss: 754687.438 | Test loss: 1973956.250\nIteration: 521600 | Training Loss: 754488.812 | Test loss: 1973585.250\nIteration: 521800 | Training Loss: 754290.312 | Test loss: 1973228.000\nIteration: 522000 | Training Loss: 754092.000 | Test loss: 1972866.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 522200 | Training Loss: 753893.812 | Test loss: 1972492.250\nIteration: 522400 | Training Loss: 753695.750 | Test loss: 1972128.875\nIteration: 522600 | Training Loss: 753497.875 | Test loss: 1971763.625\nIteration: 522800 | Training Loss: 753300.125 | Test loss: 1971406.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 523000 | Training Loss: 753102.562 | Test loss: 1971031.875\nIteration: 523200 | Training Loss: 752905.062 | Test loss: 1970670.875\nIteration: 523400 | Training Loss: 752707.750 | Test loss: 1970300.375\nIteration: 523600 | Training Loss: 752510.562 | Test loss: 1969942.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 523800 | Training Loss: 752313.562 | Test loss: 1969577.000\nIteration: 524000 | Training Loss: 752116.625 | Test loss: 1969216.625\nIteration: 524200 | Training Loss: 751919.938 | Test loss: 1968848.625\nIteration: 524400 | Training Loss: 751723.375 | Test loss: 1968488.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 524600 | Training Loss: 751526.875 | Test loss: 1968124.000\nIteration: 524800 | Training Loss: 751330.625 | Test loss: 1967761.500\nIteration: 525000 | Training Loss: 751134.500 | Test loss: 1967398.500\nIteration: 525200 | Training Loss: 750938.438 | Test loss: 1967035.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 525400 | Training Loss: 750742.625 | Test loss: 1966675.250\nIteration: 525600 | Training Loss: 750546.875 | Test loss: 1966317.250\nIteration: 525800 | Training Loss: 750351.312 | Test loss: 1965951.375\nIteration: 526000 | Training Loss: 750155.938 | Test loss: 1965589.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 526200 | Training Loss: 749960.688 | Test loss: 1965228.250\nIteration: 526400 | Training Loss: 749765.562 | Test loss: 1964872.625\nIteration: 526600 | Training Loss: 749570.625 | Test loss: 1964504.375\nIteration: 526800 | Training Loss: 749375.812 | Test loss: 1964143.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 527000 | Training Loss: 749181.125 | Test loss: 1963782.500\nIteration: 527200 | Training Loss: 748986.625 | Test loss: 1963423.000\nIteration: 527400 | Training Loss: 748792.188 | Test loss: 1963062.875\nIteration: 527600 | Training Loss: 748597.938 | Test loss: 1962697.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 527800 | Training Loss: 748403.812 | Test loss: 1962341.000\nIteration: 528000 | Training Loss: 748209.875 | Test loss: 1961980.625\nIteration: 528200 | Training Loss: 748016.062 | Test loss: 1961621.250\nIteration: 528400 | Training Loss: 747822.438 | Test loss: 1961261.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 528600 | Training Loss: 747628.875 | Test loss: 1960903.375\nIteration: 528800 | Training Loss: 747435.438 | Test loss: 1960539.625\nIteration: 529000 | Training Loss: 747242.312 | Test loss: 1960183.000\nIteration: 529200 | Training Loss: 747049.188 | Test loss: 1959820.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 529400 | Training Loss: 746856.250 | Test loss: 1959464.625\nIteration: 529600 | Training Loss: 746663.438 | Test loss: 1959104.375\nIteration: 529800 | Training Loss: 746470.812 | Test loss: 1958745.750\nIteration: 530000 | Training Loss: 746278.312 | Test loss: 1958385.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 530200 | Training Loss: 746085.938 | Test loss: 1958026.875\nIteration: 530400 | Training Loss: 745893.688 | Test loss: 1957670.625\nIteration: 530600 | Training Loss: 745701.625 | Test loss: 1957305.625\nIteration: 530800 | Training Loss: 745509.750 | Test loss: 1956947.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 531000 | Training Loss: 745317.938 | Test loss: 1956590.375\nIteration: 531200 | Training Loss: 745126.312 | Test loss: 1956234.250\nIteration: 531400 | Training Loss: 744934.875 | Test loss: 1955872.875\nIteration: 531600 | Training Loss: 744743.500 | Test loss: 1955514.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 531800 | Training Loss: 744552.250 | Test loss: 1955156.875\nIteration: 532000 | Training Loss: 744361.125 | Test loss: 1954797.125\nIteration: 532200 | Training Loss: 744170.188 | Test loss: 1954442.625\nIteration: 532400 | Training Loss: 743979.438 | Test loss: 1954085.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 532600 | Training Loss: 743788.812 | Test loss: 1953727.250\nIteration: 532800 | Training Loss: 743598.250 | Test loss: 1953368.625\nIteration: 533000 | Training Loss: 743407.875 | Test loss: 1953014.000\nIteration: 533200 | Training Loss: 743217.688 | Test loss: 1952652.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 533400 | Training Loss: 743027.562 | Test loss: 1952293.750\nIteration: 533600 | Training Loss: 742837.625 | Test loss: 1951917.125\nIteration: 533800 | Training Loss: 742647.875 | Test loss: 1951581.625\nIteration: 534000 | Training Loss: 742458.125 | Test loss: 1951218.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 534200 | Training Loss: 742268.625 | Test loss: 1950862.875\nIteration: 534400 | Training Loss: 742079.250 | Test loss: 1950498.000\nIteration: 534600 | Training Loss: 741889.938 | Test loss: 1950138.625\nIteration: 534800 | Training Loss: 741700.812 | Test loss: 1949789.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 535000 | Training Loss: 741511.812 | Test loss: 1949424.000\nIteration: 535200 | Training Loss: 741322.875 | Test loss: 1949063.625\nIteration: 535400 | Training Loss: 741134.125 | Test loss: 1948698.250\nIteration: 535600 | Training Loss: 740945.562 | Test loss: 1948336.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 535800 | Training Loss: 740757.062 | Test loss: 1947967.250\nIteration: 536000 | Training Loss: 740568.688 | Test loss: 1947606.625\nIteration: 536200 | Training Loss: 740380.438 | Test loss: 1947238.875\nIteration: 536400 | Training Loss: 740192.312 | Test loss: 1946853.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 536600 | Training Loss: 740004.250 | Test loss: 1946483.125\nIteration: 536800 | Training Loss: 739816.438 | Test loss: 1946094.500\nIteration: 537000 | Training Loss: 739628.625 | Test loss: 1945712.750\nIteration: 537200 | Training Loss: 739441.000 | Test loss: 1945318.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 537400 | Training Loss: 739253.375 | Test loss: 1944929.375\nIteration: 537600 | Training Loss: 739066.000 | Test loss: 1944530.250\nIteration: 537800 | Training Loss: 738878.688 | Test loss: 1944120.625\nIteration: 538000 | Training Loss: 738691.438 | Test loss: 1943719.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 538200 | Training Loss: 738504.312 | Test loss: 1943315.375\nIteration: 538400 | Training Loss: 738317.312 | Test loss: 1942908.625\nIteration: 538600 | Training Loss: 738130.375 | Test loss: 1942493.875\nIteration: 538800 | Training Loss: 737943.625 | Test loss: 1942083.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 539000 | Training Loss: 737756.938 | Test loss: 1941676.875\nIteration: 539200 | Training Loss: 737570.375 | Test loss: 1941272.125\nIteration: 539400 | Training Loss: 737383.938 | Test loss: 1940861.500\nIteration: 539600 | Training Loss: 737197.562 | Test loss: 1940450.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 539800 | Training Loss: 737011.375 | Test loss: 1940042.000\nIteration: 540000 | Training Loss: 736825.250 | Test loss: 1939625.750\nIteration: 540200 | Training Loss: 736639.250 | Test loss: 1939219.625\nIteration: 540400 | Training Loss: 736453.312 | Test loss: 1938812.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 540600 | Training Loss: 736267.500 | Test loss: 1938407.875\nIteration: 540800 | Training Loss: 736081.875 | Test loss: 1937995.500\nIteration: 541000 | Training Loss: 735896.312 | Test loss: 1937588.125\nIteration: 541200 | Training Loss: 735710.812 | Test loss: 1937180.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 541400 | Training Loss: 735525.500 | Test loss: 1936774.000\nIteration: 541600 | Training Loss: 735340.250 | Test loss: 1936361.750\nIteration: 541800 | Training Loss: 735155.125 | Test loss: 1935950.875\nIteration: 542000 | Training Loss: 734970.188 | Test loss: 1935547.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 542200 | Training Loss: 734785.250 | Test loss: 1935141.000\nIteration: 542400 | Training Loss: 734600.438 | Test loss: 1934732.125\nIteration: 542600 | Training Loss: 734415.750 | Test loss: 1934328.500\nIteration: 542800 | Training Loss: 734231.250 | Test loss: 1933916.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 543000 | Training Loss: 734046.750 | Test loss: 1933508.250\nIteration: 543200 | Training Loss: 733862.375 | Test loss: 1933100.750\nIteration: 543400 | Training Loss: 733678.188 | Test loss: 1932702.625\nIteration: 543600 | Training Loss: 733494.062 | Test loss: 1932287.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 543800 | Training Loss: 733310.062 | Test loss: 1931882.125\nIteration: 544000 | Training Loss: 733126.188 | Test loss: 1931475.000\nIteration: 544200 | Training Loss: 732942.375 | Test loss: 1931070.750\nIteration: 544400 | Training Loss: 732758.688 | Test loss: 1930664.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 544600 | Training Loss: 732575.125 | Test loss: 1930257.625\nIteration: 544800 | Training Loss: 732391.688 | Test loss: 1929853.500\nIteration: 545000 | Training Loss: 732208.312 | Test loss: 1929446.000\nIteration: 545200 | Training Loss: 732025.062 | Test loss: 1929039.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 545400 | Training Loss: 731842.000 | Test loss: 1928635.250\nIteration: 545600 | Training Loss: 731658.938 | Test loss: 1928235.125\nIteration: 545800 | Training Loss: 731476.062 | Test loss: 1927826.250\nIteration: 546000 | Training Loss: 731293.312 | Test loss: 1927415.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 546200 | Training Loss: 731110.625 | Test loss: 1927014.000\nIteration: 546400 | Training Loss: 730928.062 | Test loss: 1926604.125\nIteration: 546600 | Training Loss: 730745.562 | Test loss: 1926198.000\nIteration: 546800 | Training Loss: 730563.250 | Test loss: 1925805.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 547000 | Training Loss: 730381.062 | Test loss: 1925394.750\nIteration: 547200 | Training Loss: 730198.875 | Test loss: 1924988.375\nIteration: 547400 | Training Loss: 730016.875 | Test loss: 1924583.375\nIteration: 547600 | Training Loss: 729835.000 | Test loss: 1924181.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 547800 | Training Loss: 729653.250 | Test loss: 1923773.000\nIteration: 548000 | Training Loss: 729471.562 | Test loss: 1923371.875\nIteration: 548200 | Training Loss: 729290.000 | Test loss: 1922969.375\nIteration: 548400 | Training Loss: 729108.562 | Test loss: 1922560.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 548600 | Training Loss: 728927.188 | Test loss: 1922157.750\nIteration: 548800 | Training Loss: 728745.938 | Test loss: 1921748.125\nIteration: 549000 | Training Loss: 728564.875 | Test loss: 1921350.875\nIteration: 549200 | Training Loss: 728383.812 | Test loss: 1920944.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 549400 | Training Loss: 728202.875 | Test loss: 1920538.625\nIteration: 549600 | Training Loss: 728022.125 | Test loss: 1920131.750\nIteration: 549800 | Training Loss: 727841.438 | Test loss: 1919728.250\nIteration: 550000 | Training Loss: 727660.875 | Test loss: 1919325.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 550200 | Training Loss: 727480.438 | Test loss: 1918918.000\nIteration: 550400 | Training Loss: 727300.062 | Test loss: 1918502.000\nIteration: 550600 | Training Loss: 727119.812 | Test loss: 1918109.000\nIteration: 550800 | Training Loss: 726939.688 | Test loss: 1917705.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 551000 | Training Loss: 726759.688 | Test loss: 1917295.625\nIteration: 551200 | Training Loss: 726579.750 | Test loss: 1916893.375\nIteration: 551400 | Training Loss: 726400.000 | Test loss: 1916491.750\nIteration: 551600 | Training Loss: 726220.250 | Test loss: 1916083.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 551800 | Training Loss: 726040.750 | Test loss: 1915680.250\nIteration: 552000 | Training Loss: 725861.250 | Test loss: 1915271.625\nIteration: 552200 | Training Loss: 725681.938 | Test loss: 1914873.625\nIteration: 552400 | Training Loss: 725502.625 | Test loss: 1914466.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 552600 | Training Loss: 725323.500 | Test loss: 1914063.250\nIteration: 552800 | Training Loss: 725144.438 | Test loss: 1913662.625\nIteration: 553000 | Training Loss: 724965.625 | Test loss: 1913255.625\nIteration: 553200 | Training Loss: 724786.750 | Test loss: 1912850.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 553400 | Training Loss: 724608.062 | Test loss: 1912446.000\nIteration: 553600 | Training Loss: 724429.500 | Test loss: 1912043.125\nIteration: 553800 | Training Loss: 724251.000 | Test loss: 1911636.750\nIteration: 554000 | Training Loss: 724072.625 | Test loss: 1911233.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 554200 | Training Loss: 723894.438 | Test loss: 1910831.000\nIteration: 554400 | Training Loss: 723716.250 | Test loss: 1910433.000\nIteration: 554600 | Training Loss: 723538.188 | Test loss: 1910032.125\nIteration: 554800 | Training Loss: 723360.312 | Test loss: 1909620.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 555000 | Training Loss: 723182.500 | Test loss: 1909215.750\nIteration: 555200 | Training Loss: 723004.812 | Test loss: 1908818.750\nIteration: 555400 | Training Loss: 722827.188 | Test loss: 1908415.500\nIteration: 555600 | Training Loss: 722649.688 | Test loss: 1908013.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 555800 | Training Loss: 722472.312 | Test loss: 1907610.375\nIteration: 556000 | Training Loss: 722295.062 | Test loss: 1907215.000\nIteration: 556200 | Training Loss: 722117.875 | Test loss: 1906808.000\nIteration: 556400 | Training Loss: 721940.875 | Test loss: 1906406.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 556600 | Training Loss: 721763.938 | Test loss: 1906001.750\nIteration: 556800 | Training Loss: 721587.125 | Test loss: 1905605.250\nIteration: 557000 | Training Loss: 721410.438 | Test loss: 1905208.750\nIteration: 557200 | Training Loss: 721233.812 | Test loss: 1904801.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 557400 | Training Loss: 721057.375 | Test loss: 1904396.500\nIteration: 557600 | Training Loss: 720880.938 | Test loss: 1904007.750\nIteration: 557800 | Training Loss: 720704.688 | Test loss: 1903598.500\nIteration: 558000 | Training Loss: 720528.562 | Test loss: 1903198.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 558200 | Training Loss: 720352.500 | Test loss: 1902798.000\nIteration: 558400 | Training Loss: 720176.562 | Test loss: 1902400.625\nIteration: 558600 | Training Loss: 720000.750 | Test loss: 1902002.500\nIteration: 558800 | Training Loss: 719825.062 | Test loss: 1901606.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 559000 | Training Loss: 719649.438 | Test loss: 1901207.000\nIteration: 559200 | Training Loss: 719474.000 | Test loss: 1900802.375\nIteration: 559400 | Training Loss: 719298.562 | Test loss: 1900418.500\nIteration: 559600 | Training Loss: 719123.375 | Test loss: 1900014.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 559800 | Training Loss: 718948.188 | Test loss: 1899619.375\nIteration: 560000 | Training Loss: 718773.188 | Test loss: 1899218.500\nIteration: 560200 | Training Loss: 718598.250 | Test loss: 1898822.500\nIteration: 560400 | Training Loss: 718423.438 | Test loss: 1898425.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 560600 | Training Loss: 718248.688 | Test loss: 1898030.000\nIteration: 560800 | Training Loss: 718074.125 | Test loss: 1897631.750\nIteration: 561000 | Training Loss: 717899.625 | Test loss: 1897238.875\nIteration: 561200 | Training Loss: 717725.250 | Test loss: 1896840.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 561400 | Training Loss: 717551.000 | Test loss: 1896444.000\nIteration: 561600 | Training Loss: 717376.812 | Test loss: 1896050.500\nIteration: 561800 | Training Loss: 717202.812 | Test loss: 1895651.750\nIteration: 562000 | Training Loss: 717028.875 | Test loss: 1895264.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 562200 | Training Loss: 716855.062 | Test loss: 1894862.750\nIteration: 562400 | Training Loss: 716681.312 | Test loss: 1894464.125\nIteration: 562600 | Training Loss: 716507.688 | Test loss: 1894072.500\nIteration: 562800 | Training Loss: 716334.250 | Test loss: 1893683.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 563000 | Training Loss: 716160.875 | Test loss: 1893283.250\nIteration: 563200 | Training Loss: 715987.562 | Test loss: 1892887.750\nIteration: 563400 | Training Loss: 715814.438 | Test loss: 1892481.500\nIteration: 563600 | Training Loss: 715641.375 | Test loss: 1892099.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 563800 | Training Loss: 715468.438 | Test loss: 1891706.750\nIteration: 564000 | Training Loss: 715295.625 | Test loss: 1891313.875\nIteration: 564200 | Training Loss: 715122.875 | Test loss: 1890917.625\nIteration: 564400 | Training Loss: 714950.250 | Test loss: 1890518.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 564600 | Training Loss: 714777.750 | Test loss: 1890132.375\nIteration: 564800 | Training Loss: 714605.375 | Test loss: 1889737.000\nIteration: 565000 | Training Loss: 714433.125 | Test loss: 1889352.125\nIteration: 565200 | Training Loss: 714260.938 | Test loss: 1888957.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 565400 | Training Loss: 714088.875 | Test loss: 1888569.000\nIteration: 565600 | Training Loss: 713916.938 | Test loss: 1888174.250\nIteration: 565800 | Training Loss: 713745.125 | Test loss: 1887768.500\nIteration: 566000 | Training Loss: 713573.375 | Test loss: 1887386.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 566200 | Training Loss: 713401.750 | Test loss: 1886994.500\nIteration: 566400 | Training Loss: 713230.250 | Test loss: 1886604.000\nIteration: 566600 | Training Loss: 713058.875 | Test loss: 1886214.250\nIteration: 566800 | Training Loss: 712887.562 | Test loss: 1885815.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 567000 | Training Loss: 712716.375 | Test loss: 1885425.750\nIteration: 567200 | Training Loss: 712545.312 | Test loss: 1885045.125\nIteration: 567400 | Training Loss: 712374.375 | Test loss: 1884645.750\nIteration: 567600 | Training Loss: 712203.500 | Test loss: 1884258.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 567800 | Training Loss: 712032.750 | Test loss: 1883867.250\nIteration: 568000 | Training Loss: 711862.188 | Test loss: 1883476.000\nIteration: 568200 | Training Loss: 711691.625 | Test loss: 1883087.500\nIteration: 568400 | Training Loss: 711521.250 | Test loss: 1882700.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 568600 | Training Loss: 711351.000 | Test loss: 1882308.000\nIteration: 568800 | Training Loss: 711180.812 | Test loss: 1881919.375\nIteration: 569000 | Training Loss: 711010.750 | Test loss: 1881534.250\nIteration: 569200 | Training Loss: 710840.750 | Test loss: 1881140.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 569400 | Training Loss: 710670.875 | Test loss: 1880753.375\nIteration: 569600 | Training Loss: 710501.188 | Test loss: 1880366.875\nIteration: 569800 | Training Loss: 710331.562 | Test loss: 1879974.250\nIteration: 570000 | Training Loss: 710162.000 | Test loss: 1879589.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 570200 | Training Loss: 709992.625 | Test loss: 1879199.750\nIteration: 570400 | Training Loss: 709823.312 | Test loss: 1878807.625\nIteration: 570600 | Training Loss: 709654.125 | Test loss: 1878414.750\nIteration: 570800 | Training Loss: 709485.062 | Test loss: 1878034.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 571000 | Training Loss: 709316.062 | Test loss: 1877647.375\nIteration: 571200 | Training Loss: 709147.250 | Test loss: 1877259.250\nIteration: 571400 | Training Loss: 708978.500 | Test loss: 1876869.750\nIteration: 571600 | Training Loss: 708809.812 | Test loss: 1876486.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 571800 | Training Loss: 708641.312 | Test loss: 1876097.125\nIteration: 572000 | Training Loss: 708472.875 | Test loss: 1875715.875\nIteration: 572200 | Training Loss: 708304.625 | Test loss: 1875327.875\nIteration: 572400 | Training Loss: 708136.438 | Test loss: 1874939.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 572600 | Training Loss: 707968.312 | Test loss: 1874554.375\nIteration: 572800 | Training Loss: 707800.375 | Test loss: 1874167.375\nIteration: 573000 | Training Loss: 707632.500 | Test loss: 1873783.125\nIteration: 573200 | Training Loss: 707464.750 | Test loss: 1873398.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 573400 | Training Loss: 707297.125 | Test loss: 1873015.000\nIteration: 573600 | Training Loss: 707129.562 | Test loss: 1872627.750\nIteration: 573800 | Training Loss: 706962.125 | Test loss: 1872241.125\nIteration: 574000 | Training Loss: 706794.875 | Test loss: 1871856.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 574200 | Training Loss: 706627.625 | Test loss: 1871471.625\nIteration: 574400 | Training Loss: 706460.625 | Test loss: 1871086.875\nIteration: 574600 | Training Loss: 706293.625 | Test loss: 1870703.000\nIteration: 574800 | Training Loss: 706126.750 | Test loss: 1870320.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 575000 | Training Loss: 705960.000 | Test loss: 1869940.000\nIteration: 575200 | Training Loss: 705793.312 | Test loss: 1869552.625\nIteration: 575400 | Training Loss: 705626.875 | Test loss: 1869164.625\nIteration: 575600 | Training Loss: 705460.375 | Test loss: 1868781.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 575800 | Training Loss: 705294.062 | Test loss: 1868402.750\nIteration: 576000 | Training Loss: 705127.875 | Test loss: 1868022.500\nIteration: 576200 | Training Loss: 704961.812 | Test loss: 1867639.125\nIteration: 576400 | Training Loss: 704795.812 | Test loss: 1867254.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 576600 | Training Loss: 704629.938 | Test loss: 1866869.250\nIteration: 576800 | Training Loss: 704464.188 | Test loss: 1866494.875\nIteration: 577000 | Training Loss: 704298.562 | Test loss: 1866114.750\nIteration: 577200 | Training Loss: 704133.000 | Test loss: 1865732.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 577400 | Training Loss: 703967.562 | Test loss: 1865346.875\nIteration: 577600 | Training Loss: 703802.250 | Test loss: 1864962.625\nIteration: 577800 | Training Loss: 703637.062 | Test loss: 1864583.000\nIteration: 578000 | Training Loss: 703471.938 | Test loss: 1864205.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 578200 | Training Loss: 703307.000 | Test loss: 1863819.000\nIteration: 578400 | Training Loss: 703142.062 | Test loss: 1863440.000\nIteration: 578600 | Training Loss: 702977.375 | Test loss: 1863059.625\nIteration: 578800 | Training Loss: 702812.625 | Test loss: 1862678.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 579000 | Training Loss: 702648.125 | Test loss: 1862296.125\nIteration: 579200 | Training Loss: 702483.750 | Test loss: 1861922.000\nIteration: 579400 | Training Loss: 702319.375 | Test loss: 1861539.875\nIteration: 579600 | Training Loss: 702155.188 | Test loss: 1861159.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 579800 | Training Loss: 701991.062 | Test loss: 1860779.250\nIteration: 580000 | Training Loss: 701827.062 | Test loss: 1860396.750\nIteration: 580200 | Training Loss: 701663.188 | Test loss: 1860021.875\nIteration: 580400 | Training Loss: 701499.438 | Test loss: 1859653.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 580600 | Training Loss: 701335.750 | Test loss: 1859264.250\nIteration: 580800 | Training Loss: 701172.188 | Test loss: 1858885.750\nIteration: 581000 | Training Loss: 701008.750 | Test loss: 1858506.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 581200 | Training Loss: 700845.438 | Test loss: 1858130.875\nIteration: 581400 | Training Loss: 700682.188 | Test loss: 1857751.625\nIteration: 581600 | Training Loss: 700519.125 | Test loss: 1857362.500\nIteration: 581800 | Training Loss: 700356.125 | Test loss: 1856995.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 582000 | Training Loss: 700193.250 | Test loss: 1856619.250\nIteration: 582200 | Training Loss: 700030.438 | Test loss: 1856240.750\nIteration: 582400 | Training Loss: 699867.750 | Test loss: 1855863.875\nIteration: 582600 | Training Loss: 699705.250 | Test loss: 1855485.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 582800 | Training Loss: 699542.812 | Test loss: 1855109.125\nIteration: 583000 | Training Loss: 699380.438 | Test loss: 1854733.375\nIteration: 583200 | Training Loss: 699218.250 | Test loss: 1854356.250\nIteration: 583400 | Training Loss: 699056.125 | Test loss: 1853985.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 583600 | Training Loss: 698894.125 | Test loss: 1853604.875\nIteration: 583800 | Training Loss: 698732.188 | Test loss: 1853230.250\nIteration: 584000 | Training Loss: 698570.438 | Test loss: 1852850.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 584200 | Training Loss: 698408.750 | Test loss: 1852479.250\nIteration: 584400 | Training Loss: 698247.188 | Test loss: 1852101.875\nIteration: 584600 | Training Loss: 698085.750 | Test loss: 1851726.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 584800 | Training Loss: 697924.438 | Test loss: 1851353.875\nIteration: 585000 | Training Loss: 697763.188 | Test loss: 1850976.125\nIteration: 585200 | Training Loss: 697602.062 | Test loss: 1850603.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 585400 | Training Loss: 697441.062 | Test loss: 1850225.750\nIteration: 585600 | Training Loss: 697280.188 | Test loss: 1849854.250\nIteration: 585800 | Training Loss: 697119.438 | Test loss: 1849482.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 586000 | Training Loss: 696958.688 | Test loss: 1849109.000\nIteration: 586200 | Training Loss: 696798.250 | Test loss: 1848737.500\nIteration: 586400 | Training Loss: 696637.750 | Test loss: 1848363.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 586600 | Training Loss: 696477.438 | Test loss: 1847989.000\nIteration: 586800 | Training Loss: 696317.188 | Test loss: 1847619.500\nIteration: 587000 | Training Loss: 696157.062 | Test loss: 1847234.500\nIteration: 587200 | Training Loss: 695997.125 | Test loss: 1846875.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 587400 | Training Loss: 695837.188 | Test loss: 1846505.375\nIteration: 587600 | Training Loss: 695677.438 | Test loss: 1846135.625\nIteration: 587800 | Training Loss: 695517.750 | Test loss: 1845762.000\nIteration: 588000 | Training Loss: 695358.250 | Test loss: 1845387.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 588200 | Training Loss: 695198.750 | Test loss: 1845019.750\nIteration: 588400 | Training Loss: 695039.438 | Test loss: 1844653.000\nIteration: 588600 | Training Loss: 694880.188 | Test loss: 1844286.250\nIteration: 588800 | Training Loss: 694721.062 | Test loss: 1843910.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 589000 | Training Loss: 694562.062 | Test loss: 1843540.625\nIteration: 589200 | Training Loss: 694403.250 | Test loss: 1843174.750\nIteration: 589400 | Training Loss: 694244.375 | Test loss: 1842803.750\nIteration: 589600 | Training Loss: 694085.750 | Test loss: 1842430.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 589800 | Training Loss: 693927.188 | Test loss: 1842063.875\nIteration: 590000 | Training Loss: 693768.750 | Test loss: 1841689.375\nIteration: 590200 | Training Loss: 693610.438 | Test loss: 1841324.125\nIteration: 590400 | Training Loss: 693452.188 | Test loss: 1840955.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 590600 | Training Loss: 693294.062 | Test loss: 1840589.625\nIteration: 590800 | Training Loss: 693136.062 | Test loss: 1840218.875\nIteration: 591000 | Training Loss: 692978.188 | Test loss: 1839851.000\nIteration: 591200 | Training Loss: 692820.375 | Test loss: 1839483.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 591400 | Training Loss: 692662.750 | Test loss: 1839117.375\nIteration: 591600 | Training Loss: 692505.250 | Test loss: 1838747.000\nIteration: 591800 | Training Loss: 692347.812 | Test loss: 1838379.250\nIteration: 592000 | Training Loss: 692190.562 | Test loss: 1838019.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 592200 | Training Loss: 692033.375 | Test loss: 1837636.750\nIteration: 592400 | Training Loss: 691876.312 | Test loss: 1837277.000\nIteration: 592600 | Training Loss: 691719.312 | Test loss: 1836911.500\nIteration: 592800 | Training Loss: 691562.500 | Test loss: 1836546.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 593000 | Training Loss: 691405.750 | Test loss: 1836189.875\nIteration: 593200 | Training Loss: 691249.125 | Test loss: 1835811.875\nIteration: 593400 | Training Loss: 691092.625 | Test loss: 1835444.875\nIteration: 593600 | Training Loss: 690936.188 | Test loss: 1835080.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 593800 | Training Loss: 690779.938 | Test loss: 1834722.500\nIteration: 594000 | Training Loss: 690623.750 | Test loss: 1834348.375\nIteration: 594200 | Training Loss: 690467.688 | Test loss: 1833981.750\nIteration: 594400 | Training Loss: 690311.688 | Test loss: 1833622.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 594600 | Training Loss: 690155.812 | Test loss: 1833250.750\nIteration: 594800 | Training Loss: 690000.125 | Test loss: 1832887.500\nIteration: 595000 | Training Loss: 689844.375 | Test loss: 1832528.125\nIteration: 595200 | Training Loss: 689688.875 | Test loss: 1832158.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 595400 | Training Loss: 689533.500 | Test loss: 1831785.125\nIteration: 595600 | Training Loss: 689378.188 | Test loss: 1831428.625\nIteration: 595800 | Training Loss: 689222.938 | Test loss: 1831065.125\nIteration: 596000 | Training Loss: 689067.812 | Test loss: 1830700.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 596200 | Training Loss: 688912.875 | Test loss: 1830338.000\nIteration: 596400 | Training Loss: 688758.000 | Test loss: 1829974.875\nIteration: 596600 | Training Loss: 688603.250 | Test loss: 1829611.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 596800 | Training Loss: 688448.562 | Test loss: 1829247.250\nIteration: 597000 | Training Loss: 688294.000 | Test loss: 1828884.875\nIteration: 597200 | Training Loss: 688139.625 | Test loss: 1828522.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 597400 | Training Loss: 687985.250 | Test loss: 1828158.500\nIteration: 597600 | Training Loss: 687831.062 | Test loss: 1827794.625\nIteration: 597800 | Training Loss: 687676.938 | Test loss: 1827434.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 598000 | Training Loss: 687522.938 | Test loss: 1827073.375\nIteration: 598200 | Training Loss: 687369.062 | Test loss: 1826717.125\nIteration: 598400 | Training Loss: 687215.250 | Test loss: 1826342.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 598600 | Training Loss: 687061.625 | Test loss: 1825982.250\nIteration: 598800 | Training Loss: 686908.000 | Test loss: 1825632.875\nIteration: 599000 | Training Loss: 686754.625 | Test loss: 1825264.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 599200 | Training Loss: 686601.250 | Test loss: 1824901.625\nIteration: 599400 | Training Loss: 686448.000 | Test loss: 1824539.500\nIteration: 599600 | Training Loss: 686294.938 | Test loss: 1824181.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 599800 | Training Loss: 686141.875 | Test loss: 1823820.875\nIteration: 600000 | Training Loss: 685989.000 | Test loss: 1823460.000\nIteration: 600200 | Training Loss: 685836.188 | Test loss: 1823100.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 600400 | Training Loss: 685683.500 | Test loss: 1822738.250\nIteration: 600600 | Training Loss: 685530.938 | Test loss: 1822380.625\nIteration: 600800 | Training Loss: 685378.438 | Test loss: 1822021.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 601000 | Training Loss: 685226.125 | Test loss: 1821660.875\nIteration: 601200 | Training Loss: 685073.875 | Test loss: 1821302.250\nIteration: 601400 | Training Loss: 684921.750 | Test loss: 1820941.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 601600 | Training Loss: 684769.688 | Test loss: 1820583.125\nIteration: 601800 | Training Loss: 684617.750 | Test loss: 1820225.000\nIteration: 602000 | Training Loss: 684466.000 | Test loss: 1819872.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 602200 | Training Loss: 684314.375 | Test loss: 1819506.875\nIteration: 602400 | Training Loss: 684162.750 | Test loss: 1819147.625\nIteration: 602600 | Training Loss: 684011.250 | Test loss: 1818790.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 602800 | Training Loss: 683859.938 | Test loss: 1818432.625\nIteration: 603000 | Training Loss: 683708.688 | Test loss: 1818075.875\nIteration: 603200 | Training Loss: 683557.562 | Test loss: 1817718.125\nIteration: 603400 | Training Loss: 683406.562 | Test loss: 1817359.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 603600 | Training Loss: 683255.625 | Test loss: 1817004.375\nIteration: 603800 | Training Loss: 683104.812 | Test loss: 1816645.000\nIteration: 604000 | Training Loss: 682954.125 | Test loss: 1816288.750\nIteration: 604200 | Training Loss: 682803.500 | Test loss: 1815925.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 604400 | Training Loss: 682653.062 | Test loss: 1815574.250\nIteration: 604600 | Training Loss: 682502.688 | Test loss: 1815217.250\nIteration: 604800 | Training Loss: 682352.438 | Test loss: 1814862.125\nIteration: 605000 | Training Loss: 682202.250 | Test loss: 1814507.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 605200 | Training Loss: 682052.188 | Test loss: 1814140.500\nIteration: 605400 | Training Loss: 681902.250 | Test loss: 1813795.000\nIteration: 605600 | Training Loss: 681752.438 | Test loss: 1813440.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 605800 | Training Loss: 681602.750 | Test loss: 1813086.125\nIteration: 606000 | Training Loss: 681453.125 | Test loss: 1812725.250\nIteration: 606200 | Training Loss: 681303.625 | Test loss: 1812377.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 606400 | Training Loss: 681154.250 | Test loss: 1812018.250\nIteration: 606600 | Training Loss: 681005.000 | Test loss: 1811659.625\nIteration: 606800 | Training Loss: 680855.812 | Test loss: 1811309.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 607000 | Training Loss: 680706.750 | Test loss: 1810955.500\nIteration: 607200 | Training Loss: 680557.750 | Test loss: 1810600.875\nIteration: 607400 | Training Loss: 680408.938 | Test loss: 1810255.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 607600 | Training Loss: 680260.188 | Test loss: 1809893.875\nIteration: 607800 | Training Loss: 680111.562 | Test loss: 1809540.125\nIteration: 608000 | Training Loss: 679963.000 | Test loss: 1809181.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 608200 | Training Loss: 679814.625 | Test loss: 1808833.375\nIteration: 608400 | Training Loss: 679666.312 | Test loss: 1808487.750\nIteration: 608600 | Training Loss: 679518.125 | Test loss: 1808125.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 608800 | Training Loss: 679369.938 | Test loss: 1807776.125\nIteration: 609000 | Training Loss: 679222.000 | Test loss: 1807424.750\nIteration: 609200 | Training Loss: 679074.125 | Test loss: 1807067.500\nIteration: 609400 | Training Loss: 678926.312 | Test loss: 1806715.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 609600 | Training Loss: 678778.688 | Test loss: 1806358.750\nIteration: 609800 | Training Loss: 678631.062 | Test loss: 1806009.750\nIteration: 610000 | Training Loss: 678483.562 | Test loss: 1805654.500\nIteration: 610200 | Training Loss: 678336.188 | Test loss: 1805306.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 610400 | Training Loss: 678188.938 | Test loss: 1804957.125\nIteration: 610600 | Training Loss: 678041.750 | Test loss: 1804602.125\nIteration: 610800 | Training Loss: 677894.688 | Test loss: 1804249.375\nIteration: 611000 | Training Loss: 677747.688 | Test loss: 1803898.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 611200 | Training Loss: 677600.812 | Test loss: 1803550.875\nIteration: 611400 | Training Loss: 677454.062 | Test loss: 1803194.875\nIteration: 611600 | Training Loss: 677307.312 | Test loss: 1802841.750\nIteration: 611800 | Training Loss: 677160.750 | Test loss: 1802490.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 612000 | Training Loss: 677014.250 | Test loss: 1802140.875\nIteration: 612200 | Training Loss: 676867.875 | Test loss: 1801778.875\nIteration: 612400 | Training Loss: 676721.562 | Test loss: 1801432.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 612600 | Training Loss: 676575.375 | Test loss: 1801084.750\nIteration: 612800 | Training Loss: 676429.188 | Test loss: 1800737.000\nIteration: 613000 | Training Loss: 676283.188 | Test loss: 1800382.250\nIteration: 613200 | Training Loss: 676137.250 | Test loss: 1800029.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 613400 | Training Loss: 675991.375 | Test loss: 1799681.625\nIteration: 613600 | Training Loss: 675845.625 | Test loss: 1799335.500\nIteration: 613800 | Training Loss: 675699.938 | Test loss: 1798979.000\nIteration: 614000 | Training Loss: 675554.375 | Test loss: 1798627.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 614200 | Training Loss: 675408.875 | Test loss: 1798280.375\nIteration: 614400 | Training Loss: 675263.438 | Test loss: 1797931.125\nIteration: 614600 | Training Loss: 675118.125 | Test loss: 1797580.750\nIteration: 614800 | Training Loss: 674972.938 | Test loss: 1797231.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 615000 | Training Loss: 674827.812 | Test loss: 1796885.625\nIteration: 615200 | Training Loss: 674682.750 | Test loss: 1796535.625\nIteration: 615400 | Training Loss: 674537.750 | Test loss: 1796190.625\nIteration: 615600 | Training Loss: 674392.875 | Test loss: 1795836.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 615800 | Training Loss: 674248.188 | Test loss: 1795488.875\nIteration: 616000 | Training Loss: 674103.438 | Test loss: 1795138.125\nIteration: 616200 | Training Loss: 673958.875 | Test loss: 1794791.000\nIteration: 616400 | Training Loss: 673814.375 | Test loss: 1794448.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 616600 | Training Loss: 673669.938 | Test loss: 1794095.500\nIteration: 616800 | Training Loss: 673525.625 | Test loss: 1793747.875\nIteration: 617000 | Training Loss: 673381.438 | Test loss: 1793397.250\nIteration: 617200 | Training Loss: 673237.312 | Test loss: 1793053.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 617400 | Training Loss: 673093.188 | Test loss: 1792705.375\nIteration: 617600 | Training Loss: 672949.312 | Test loss: 1792358.125\nIteration: 617800 | Training Loss: 672805.375 | Test loss: 1792014.625\nIteration: 618000 | Training Loss: 672661.625 | Test loss: 1791675.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 618200 | Training Loss: 672517.938 | Test loss: 1791322.125\nIteration: 618400 | Training Loss: 672374.312 | Test loss: 1790966.375\nIteration: 618600 | Training Loss: 672230.812 | Test loss: 1790632.500\nIteration: 618800 | Training Loss: 672087.438 | Test loss: 1790284.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 619000 | Training Loss: 671944.062 | Test loss: 1789937.375\nIteration: 619200 | Training Loss: 671800.812 | Test loss: 1789600.375\nIteration: 619400 | Training Loss: 671657.688 | Test loss: 1789252.500\nIteration: 619600 | Training Loss: 671514.625 | Test loss: 1788907.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 619800 | Training Loss: 671371.688 | Test loss: 1788559.625\nIteration: 620000 | Training Loss: 671228.750 | Test loss: 1788224.875\nIteration: 620200 | Training Loss: 671085.938 | Test loss: 1787874.250\nIteration: 620400 | Training Loss: 670943.250 | Test loss: 1787533.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 620600 | Training Loss: 670800.625 | Test loss: 1787189.875\nIteration: 620800 | Training Loss: 670658.125 | Test loss: 1786849.250\nIteration: 621000 | Training Loss: 670515.688 | Test loss: 1786498.375\nIteration: 621200 | Training Loss: 670373.312 | Test loss: 1786162.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 621400 | Training Loss: 670231.062 | Test loss: 1785822.875\nIteration: 621600 | Training Loss: 670088.938 | Test loss: 1785476.500\nIteration: 621800 | Training Loss: 669946.875 | Test loss: 1785136.625\nIteration: 622000 | Training Loss: 669804.875 | Test loss: 1784794.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 622200 | Training Loss: 669662.938 | Test loss: 1784453.000\nIteration: 622400 | Training Loss: 669521.188 | Test loss: 1784112.250\nIteration: 622600 | Training Loss: 669379.438 | Test loss: 1783779.500\nIteration: 622800 | Training Loss: 669237.812 | Test loss: 1783432.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 623000 | Training Loss: 669096.250 | Test loss: 1783092.750\nIteration: 623200 | Training Loss: 668954.812 | Test loss: 1782742.500\nIteration: 623400 | Training Loss: 668813.438 | Test loss: 1782413.000\nIteration: 623600 | Training Loss: 668672.188 | Test loss: 1782075.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 623800 | Training Loss: 668531.000 | Test loss: 1781731.750\nIteration: 624000 | Training Loss: 668389.875 | Test loss: 1781396.375\nIteration: 624200 | Training Loss: 668248.875 | Test loss: 1781057.125\nIteration: 624400 | Training Loss: 668107.938 | Test loss: 1780718.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 624600 | Training Loss: 667967.125 | Test loss: 1780383.500\nIteration: 624800 | Training Loss: 667826.438 | Test loss: 1780042.875\nIteration: 625000 | Training Loss: 667685.812 | Test loss: 1779701.250\nIteration: 625200 | Training Loss: 667545.250 | Test loss: 1779368.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 625400 | Training Loss: 667404.750 | Test loss: 1779029.750\nIteration: 625600 | Training Loss: 667264.375 | Test loss: 1778692.125\nIteration: 625800 | Training Loss: 667124.125 | Test loss: 1778359.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 626000 | Training Loss: 666983.875 | Test loss: 1778018.500\nIteration: 626200 | Training Loss: 666843.812 | Test loss: 1777683.000\nIteration: 626400 | Training Loss: 666703.750 | Test loss: 1777344.375\nIteration: 626600 | Training Loss: 666563.875 | Test loss: 1777011.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 626800 | Training Loss: 666424.000 | Test loss: 1776673.000\nIteration: 627000 | Training Loss: 666284.312 | Test loss: 1776335.500\nIteration: 627200 | Training Loss: 666144.688 | Test loss: 1776006.500\nIteration: 627400 | Training Loss: 666005.062 | Test loss: 1775659.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 627600 | Training Loss: 665865.625 | Test loss: 1775327.000\nIteration: 627800 | Training Loss: 665726.250 | Test loss: 1774996.875\nIteration: 628000 | Training Loss: 665586.938 | Test loss: 1774656.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 628200 | Training Loss: 665447.688 | Test loss: 1774323.625\nIteration: 628400 | Training Loss: 665308.562 | Test loss: 1773987.875\nIteration: 628600 | Training Loss: 665169.562 | Test loss: 1773651.250\nIteration: 628800 | Training Loss: 665030.625 | Test loss: 1773315.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 629000 | Training Loss: 664891.750 | Test loss: 1772982.500\nIteration: 629200 | Training Loss: 664753.000 | Test loss: 1772645.000\nIteration: 629400 | Training Loss: 664614.312 | Test loss: 1772314.125\nIteration: 629600 | Training Loss: 664475.750 | Test loss: 1771978.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 629800 | Training Loss: 664337.250 | Test loss: 1771646.250\nIteration: 630000 | Training Loss: 664198.812 | Test loss: 1771313.125\nIteration: 630200 | Training Loss: 664060.500 | Test loss: 1770977.125\nIteration: 630400 | Training Loss: 663922.250 | Test loss: 1770645.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 630600 | Training Loss: 663784.125 | Test loss: 1770310.250\nIteration: 630800 | Training Loss: 663646.062 | Test loss: 1769980.000\nIteration: 631000 | Training Loss: 663508.062 | Test loss: 1769643.750\nIteration: 631200 | Training Loss: 663370.188 | Test loss: 1769301.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 631400 | Training Loss: 663232.438 | Test loss: 1768979.875\nIteration: 631600 | Training Loss: 663094.750 | Test loss: 1768646.125\nIteration: 631800 | Training Loss: 662957.125 | Test loss: 1768312.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 632000 | Training Loss: 662819.625 | Test loss: 1767983.125\nIteration: 632200 | Training Loss: 662682.188 | Test loss: 1767649.875\nIteration: 632400 | Training Loss: 662544.812 | Test loss: 1767316.875\nIteration: 632600 | Training Loss: 662407.562 | Test loss: 1766984.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 632800 | Training Loss: 662270.438 | Test loss: 1766653.375\nIteration: 633000 | Training Loss: 662133.312 | Test loss: 1766321.500\nIteration: 633200 | Training Loss: 661996.375 | Test loss: 1765992.125\nIteration: 633400 | Training Loss: 661859.438 | Test loss: 1765661.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 633600 | Training Loss: 661722.688 | Test loss: 1765329.375\nIteration: 633800 | Training Loss: 661585.938 | Test loss: 1764996.125\nIteration: 634000 | Training Loss: 661449.250 | Test loss: 1764667.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 634200 | Training Loss: 661312.750 | Test loss: 1764337.250\nIteration: 634400 | Training Loss: 661176.312 | Test loss: 1764006.250\nIteration: 634600 | Training Loss: 661039.938 | Test loss: 1763676.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 634800 | Training Loss: 660903.625 | Test loss: 1763345.625\nIteration: 635000 | Training Loss: 660767.438 | Test loss: 1763016.500\nIteration: 635200 | Training Loss: 660631.375 | Test loss: 1762685.250\nIteration: 635400 | Training Loss: 660495.375 | Test loss: 1762352.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 635600 | Training Loss: 660359.500 | Test loss: 1762027.625\nIteration: 635800 | Training Loss: 660223.625 | Test loss: 1761697.250\nIteration: 636000 | Training Loss: 660087.875 | Test loss: 1761365.750\nIteration: 636200 | Training Loss: 659952.250 | Test loss: 1761036.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 636400 | Training Loss: 659816.688 | Test loss: 1760712.250\nIteration: 636600 | Training Loss: 659681.188 | Test loss: 1760380.375\nIteration: 636800 | Training Loss: 659545.812 | Test loss: 1760053.875\nIteration: 637000 | Training Loss: 659410.562 | Test loss: 1759719.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 637200 | Training Loss: 659275.312 | Test loss: 1759394.875\nIteration: 637400 | Training Loss: 659140.188 | Test loss: 1759066.125\nIteration: 637600 | Training Loss: 659005.125 | Test loss: 1758739.375\nIteration: 637800 | Training Loss: 658870.250 | Test loss: 1758406.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 638000 | Training Loss: 658735.375 | Test loss: 1758082.125\nIteration: 638200 | Training Loss: 658600.625 | Test loss: 1757754.750\nIteration: 638400 | Training Loss: 658465.938 | Test loss: 1757427.750\nIteration: 638600 | Training Loss: 658331.375 | Test loss: 1757104.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 638800 | Training Loss: 658196.875 | Test loss: 1756775.375\nIteration: 639000 | Training Loss: 658062.438 | Test loss: 1756443.750\nIteration: 639200 | Training Loss: 657928.188 | Test loss: 1756117.750\nIteration: 639400 | Training Loss: 657793.938 | Test loss: 1755791.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 639600 | Training Loss: 657659.812 | Test loss: 1755463.750\nIteration: 639800 | Training Loss: 657525.750 | Test loss: 1755128.250\nIteration: 640000 | Training Loss: 657391.812 | Test loss: 1754811.250\nIteration: 640200 | Training Loss: 657257.938 | Test loss: 1754483.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 640400 | Training Loss: 657124.188 | Test loss: 1754155.125\nIteration: 640600 | Training Loss: 656990.500 | Test loss: 1753830.750\nIteration: 640800 | Training Loss: 656856.875 | Test loss: 1753501.875\nIteration: 641000 | Training Loss: 656723.375 | Test loss: 1753177.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 641200 | Training Loss: 656589.938 | Test loss: 1752850.500\nIteration: 641400 | Training Loss: 656456.625 | Test loss: 1752524.500\nIteration: 641600 | Training Loss: 656323.375 | Test loss: 1752202.125\nIteration: 641800 | Training Loss: 656190.188 | Test loss: 1751879.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 642000 | Training Loss: 656057.125 | Test loss: 1751549.625\nIteration: 642200 | Training Loss: 655924.188 | Test loss: 1751226.125\nIteration: 642400 | Training Loss: 655791.312 | Test loss: 1750901.250\nIteration: 642600 | Training Loss: 655658.438 | Test loss: 1750576.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 642800 | Training Loss: 655525.750 | Test loss: 1750251.250\nIteration: 643000 | Training Loss: 655393.125 | Test loss: 1749925.875\nIteration: 643200 | Training Loss: 655260.625 | Test loss: 1749600.875\nIteration: 643400 | Training Loss: 655128.125 | Test loss: 1749278.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 643600 | Training Loss: 654995.750 | Test loss: 1748949.125\nIteration: 643800 | Training Loss: 654863.500 | Test loss: 1748629.250\nIteration: 644000 | Training Loss: 654731.375 | Test loss: 1748303.625\nIteration: 644200 | Training Loss: 654599.250 | Test loss: 1747981.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 644400 | Training Loss: 654467.250 | Test loss: 1747657.750\nIteration: 644600 | Training Loss: 654335.312 | Test loss: 1747334.000\nIteration: 644800 | Training Loss: 654203.562 | Test loss: 1747012.875\nIteration: 645000 | Training Loss: 654071.812 | Test loss: 1746685.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 645200 | Training Loss: 653940.188 | Test loss: 1746363.625\nIteration: 645400 | Training Loss: 653808.562 | Test loss: 1746041.750\nIteration: 645600 | Training Loss: 653677.125 | Test loss: 1745717.500\nIteration: 645800 | Training Loss: 653545.750 | Test loss: 1745393.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 646000 | Training Loss: 653414.438 | Test loss: 1745067.375\nIteration: 646200 | Training Loss: 653283.250 | Test loss: 1744750.125\nIteration: 646400 | Training Loss: 653152.188 | Test loss: 1744426.625\nIteration: 646600 | Training Loss: 653021.062 | Test loss: 1744104.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 646800 | Training Loss: 652890.188 | Test loss: 1743782.250\nIteration: 647000 | Training Loss: 652759.375 | Test loss: 1743462.000\nIteration: 647200 | Training Loss: 652628.562 | Test loss: 1743137.000\nIteration: 647400 | Training Loss: 652497.938 | Test loss: 1742816.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 647600 | Training Loss: 652367.438 | Test loss: 1742487.750\nIteration: 647800 | Training Loss: 652237.000 | Test loss: 1742173.000\nIteration: 648000 | Training Loss: 652106.688 | Test loss: 1741853.250\nIteration: 648200 | Training Loss: 651976.438 | Test loss: 1741531.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 648400 | Training Loss: 651846.312 | Test loss: 1741210.250\nIteration: 648600 | Training Loss: 651716.312 | Test loss: 1740893.250\nIteration: 648800 | Training Loss: 651586.375 | Test loss: 1740573.125\nIteration: 649000 | Training Loss: 651456.562 | Test loss: 1740253.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 649200 | Training Loss: 651326.875 | Test loss: 1739928.250\nIteration: 649400 | Training Loss: 651197.188 | Test loss: 1739611.125\nIteration: 649600 | Training Loss: 651067.688 | Test loss: 1739288.750\nIteration: 649800 | Training Loss: 650938.250 | Test loss: 1738971.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 650000 | Training Loss: 650808.875 | Test loss: 1738651.625\nIteration: 650200 | Training Loss: 650679.688 | Test loss: 1738331.875\nIteration: 650400 | Training Loss: 650550.500 | Test loss: 1738013.875\nIteration: 650600 | Training Loss: 650421.438 | Test loss: 1737691.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 650800 | Training Loss: 650292.500 | Test loss: 1737376.000\nIteration: 651000 | Training Loss: 650163.688 | Test loss: 1737059.875\nIteration: 651200 | Training Loss: 650034.938 | Test loss: 1736738.500\nIteration: 651400 | Training Loss: 649906.250 | Test loss: 1736419.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 651600 | Training Loss: 649777.688 | Test loss: 1736105.875\nIteration: 651800 | Training Loss: 649649.188 | Test loss: 1735784.875\nIteration: 652000 | Training Loss: 649520.812 | Test loss: 1735465.000\nIteration: 652200 | Training Loss: 649392.562 | Test loss: 1735148.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 652400 | Training Loss: 649264.375 | Test loss: 1734830.500\nIteration: 652600 | Training Loss: 649136.250 | Test loss: 1734518.000\nIteration: 652800 | Training Loss: 649008.250 | Test loss: 1734197.875\nIteration: 653000 | Training Loss: 648880.312 | Test loss: 1733880.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 653200 | Training Loss: 648752.438 | Test loss: 1733569.750\nIteration: 653400 | Training Loss: 648624.688 | Test loss: 1733244.625\nIteration: 653600 | Training Loss: 648497.062 | Test loss: 1732933.750\nIteration: 653800 | Training Loss: 648369.500 | Test loss: 1732612.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 654000 | Training Loss: 648242.000 | Test loss: 1732290.500\nIteration: 654200 | Training Loss: 648114.688 | Test loss: 1731979.000\nIteration: 654400 | Training Loss: 647987.312 | Test loss: 1731663.250\nIteration: 654600 | Training Loss: 647860.125 | Test loss: 1731345.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 654800 | Training Loss: 647733.000 | Test loss: 1731028.000\nIteration: 655000 | Training Loss: 647605.938 | Test loss: 1730712.875\nIteration: 655200 | Training Loss: 647478.938 | Test loss: 1730397.625\nIteration: 655400 | Training Loss: 647352.125 | Test loss: 1730082.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 655600 | Training Loss: 647225.312 | Test loss: 1729760.125\nIteration: 655800 | Training Loss: 647098.625 | Test loss: 1729447.875\nIteration: 656000 | Training Loss: 646972.000 | Test loss: 1729134.250\nIteration: 656200 | Training Loss: 646845.500 | Test loss: 1728816.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 656400 | Training Loss: 646719.062 | Test loss: 1728501.625\nIteration: 656600 | Training Loss: 646592.688 | Test loss: 1728185.875\nIteration: 656800 | Training Loss: 646466.500 | Test loss: 1727869.000\nIteration: 657000 | Training Loss: 646340.250 | Test loss: 1727555.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 657200 | Training Loss: 646214.188 | Test loss: 1727243.750\nIteration: 657400 | Training Loss: 646088.188 | Test loss: 1726923.500\nIteration: 657600 | Training Loss: 645962.312 | Test loss: 1726605.500\nIteration: 657800 | Training Loss: 645836.438 | Test loss: 1726293.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 658000 | Training Loss: 645710.750 | Test loss: 1725978.625\nIteration: 658200 | Training Loss: 645585.062 | Test loss: 1725662.750\nIteration: 658400 | Training Loss: 645459.500 | Test loss: 1725351.125\nIteration: 658600 | Training Loss: 645334.062 | Test loss: 1725033.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 658800 | Training Loss: 645208.625 | Test loss: 1724720.250\nIteration: 659000 | Training Loss: 645083.312 | Test loss: 1724406.500\nIteration: 659200 | Training Loss: 644958.125 | Test loss: 1724091.000\nIteration: 659400 | Training Loss: 644833.000 | Test loss: 1723777.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 659600 | Training Loss: 644707.938 | Test loss: 1723464.625\nIteration: 659800 | Training Loss: 644583.000 | Test loss: 1723152.500\nIteration: 660000 | Training Loss: 644458.125 | Test loss: 1722835.375\nIteration: 660200 | Training Loss: 644333.375 | Test loss: 1722521.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 660400 | Training Loss: 644208.625 | Test loss: 1722207.250\nIteration: 660600 | Training Loss: 644084.062 | Test loss: 1721895.750\nIteration: 660800 | Training Loss: 643959.562 | Test loss: 1721576.125\nIteration: 661000 | Training Loss: 643835.062 | Test loss: 1721270.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 661200 | Training Loss: 643710.750 | Test loss: 1720954.750\nIteration: 661400 | Training Loss: 643586.500 | Test loss: 1720641.500\nIteration: 661600 | Training Loss: 643462.312 | Test loss: 1720328.875\nIteration: 661800 | Training Loss: 643338.250 | Test loss: 1720014.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 662000 | Training Loss: 643214.250 | Test loss: 1719704.500\nIteration: 662200 | Training Loss: 643090.312 | Test loss: 1719390.500\nIteration: 662400 | Training Loss: 642966.500 | Test loss: 1719078.625\nIteration: 662600 | Training Loss: 642842.750 | Test loss: 1718775.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 662800 | Training Loss: 642719.062 | Test loss: 1718456.125\nIteration: 663000 | Training Loss: 642595.562 | Test loss: 1718143.750\nIteration: 663200 | Training Loss: 642472.062 | Test loss: 1717831.125\nIteration: 663400 | Training Loss: 642348.688 | Test loss: 1717515.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 663600 | Training Loss: 642225.375 | Test loss: 1717206.125\nIteration: 663800 | Training Loss: 642102.188 | Test loss: 1716896.250\nIteration: 664000 | Training Loss: 641979.000 | Test loss: 1716591.125\nIteration: 664200 | Training Loss: 641856.000 | Test loss: 1716271.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 664400 | Training Loss: 641733.062 | Test loss: 1715968.250\nIteration: 664600 | Training Loss: 641610.188 | Test loss: 1715655.375\nIteration: 664800 | Training Loss: 641487.375 | Test loss: 1715341.125\nIteration: 665000 | Training Loss: 641364.688 | Test loss: 1715032.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 665200 | Training Loss: 641242.062 | Test loss: 1714721.625\nIteration: 665400 | Training Loss: 641119.562 | Test loss: 1714418.875\nIteration: 665600 | Training Loss: 640997.125 | Test loss: 1714110.500\nIteration: 665800 | Training Loss: 640874.750 | Test loss: 1713792.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 666000 | Training Loss: 640752.562 | Test loss: 1713481.375\nIteration: 666200 | Training Loss: 640630.375 | Test loss: 1713167.125\nIteration: 666400 | Training Loss: 640508.250 | Test loss: 1712862.125\nIteration: 666600 | Training Loss: 640386.250 | Test loss: 1712552.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 666800 | Training Loss: 640264.375 | Test loss: 1712238.750\nIteration: 667000 | Training Loss: 640142.562 | Test loss: 1711929.375\nIteration: 667200 | Training Loss: 640020.750 | Test loss: 1711626.500\nIteration: 667400 | Training Loss: 639899.125 | Test loss: 1711316.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 667600 | Training Loss: 639777.562 | Test loss: 1711008.250\nIteration: 667800 | Training Loss: 639656.125 | Test loss: 1710698.875\nIteration: 668000 | Training Loss: 639534.750 | Test loss: 1710387.750\nIteration: 668200 | Training Loss: 639413.375 | Test loss: 1710079.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 668400 | Training Loss: 639292.188 | Test loss: 1709775.625\nIteration: 668600 | Training Loss: 639171.062 | Test loss: 1709465.000\nIteration: 668800 | Training Loss: 639050.000 | Test loss: 1709161.625\nIteration: 669000 | Training Loss: 638929.062 | Test loss: 1708853.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 669200 | Training Loss: 638808.250 | Test loss: 1708544.250\nIteration: 669400 | Training Loss: 638687.438 | Test loss: 1708237.000\nIteration: 669600 | Training Loss: 638566.750 | Test loss: 1707930.875\nIteration: 669800 | Training Loss: 638446.125 | Test loss: 1707623.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 670000 | Training Loss: 638325.625 | Test loss: 1707314.125\nIteration: 670200 | Training Loss: 638205.188 | Test loss: 1707014.875\nIteration: 670400 | Training Loss: 638084.812 | Test loss: 1706702.000\nIteration: 670600 | Training Loss: 637964.562 | Test loss: 1706395.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 670800 | Training Loss: 637844.438 | Test loss: 1706092.125\nIteration: 671000 | Training Loss: 637724.312 | Test loss: 1705784.125\nIteration: 671200 | Training Loss: 637604.312 | Test loss: 1705475.500\nIteration: 671400 | Training Loss: 637484.375 | Test loss: 1705178.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 671600 | Training Loss: 637364.625 | Test loss: 1704867.875\nIteration: 671800 | Training Loss: 637244.812 | Test loss: 1704559.625\nIteration: 672000 | Training Loss: 637125.188 | Test loss: 1704254.625\nIteration: 672200 | Training Loss: 637005.688 | Test loss: 1703946.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 672400 | Training Loss: 636886.188 | Test loss: 1703645.125\nIteration: 672600 | Training Loss: 636766.812 | Test loss: 1703340.000\nIteration: 672800 | Training Loss: 636647.500 | Test loss: 1703034.875\nIteration: 673000 | Training Loss: 636528.250 | Test loss: 1702729.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 673200 | Training Loss: 636409.125 | Test loss: 1702427.000\nIteration: 673400 | Training Loss: 636290.062 | Test loss: 1702118.750\nIteration: 673600 | Training Loss: 636171.188 | Test loss: 1701816.375\nIteration: 673800 | Training Loss: 636052.312 | Test loss: 1701512.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 674000 | Training Loss: 635933.500 | Test loss: 1701209.500\nIteration: 674200 | Training Loss: 635814.812 | Test loss: 1700906.125\nIteration: 674400 | Training Loss: 635696.188 | Test loss: 1700594.875\nIteration: 674600 | Training Loss: 635577.625 | Test loss: 1700298.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 674800 | Training Loss: 635459.250 | Test loss: 1699991.750\nIteration: 675000 | Training Loss: 635340.938 | Test loss: 1699695.375\nIteration: 675200 | Training Loss: 635222.625 | Test loss: 1699387.625\nIteration: 675400 | Training Loss: 635104.438 | Test loss: 1699086.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 675600 | Training Loss: 634986.375 | Test loss: 1698781.500\nIteration: 675800 | Training Loss: 634868.438 | Test loss: 1698480.375\nIteration: 676000 | Training Loss: 634750.500 | Test loss: 1698177.375\nIteration: 676200 | Training Loss: 634632.688 | Test loss: 1697877.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 676400 | Training Loss: 634514.938 | Test loss: 1697573.000\nIteration: 676600 | Training Loss: 634397.312 | Test loss: 1697271.250\nIteration: 676800 | Training Loss: 634279.688 | Test loss: 1696968.875\nIteration: 677000 | Training Loss: 634162.250 | Test loss: 1696667.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 677200 | Training Loss: 634044.875 | Test loss: 1696367.250\nIteration: 677400 | Training Loss: 633927.562 | Test loss: 1696064.875\nIteration: 677600 | Training Loss: 633810.375 | Test loss: 1695766.875\nIteration: 677800 | Training Loss: 633693.188 | Test loss: 1695461.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 678000 | Training Loss: 633576.188 | Test loss: 1695160.000\nIteration: 678200 | Training Loss: 633459.250 | Test loss: 1694857.000\nIteration: 678400 | Training Loss: 633342.375 | Test loss: 1694550.375\nIteration: 678600 | Training Loss: 633225.562 | Test loss: 1694261.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 678800 | Training Loss: 633108.875 | Test loss: 1693957.250\nIteration: 679000 | Training Loss: 632992.312 | Test loss: 1693659.125\nIteration: 679200 | Training Loss: 632875.750 | Test loss: 1693357.750\nIteration: 679400 | Training Loss: 632759.312 | Test loss: 1693056.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 679600 | Training Loss: 632643.000 | Test loss: 1692756.875\nIteration: 679800 | Training Loss: 632526.750 | Test loss: 1692453.375\nIteration: 680000 | Training Loss: 632410.562 | Test loss: 1692155.750\nIteration: 680200 | Training Loss: 632294.500 | Test loss: 1691859.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 680400 | Training Loss: 632178.438 | Test loss: 1691559.625\nIteration: 680600 | Training Loss: 632062.562 | Test loss: 1691259.375\nIteration: 680800 | Training Loss: 631946.750 | Test loss: 1690966.750\nIteration: 681000 | Training Loss: 631831.000 | Test loss: 1690663.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 681200 | Training Loss: 631715.375 | Test loss: 1690364.875\nIteration: 681400 | Training Loss: 631599.812 | Test loss: 1690071.750\nIteration: 681600 | Training Loss: 631484.312 | Test loss: 1689768.000\nIteration: 681800 | Training Loss: 631368.938 | Test loss: 1689472.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 682000 | Training Loss: 631253.625 | Test loss: 1689176.625\nIteration: 682200 | Training Loss: 631138.438 | Test loss: 1688873.125\nIteration: 682400 | Training Loss: 631023.312 | Test loss: 1688575.625\nIteration: 682600 | Training Loss: 630908.250 | Test loss: 1688277.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 682800 | Training Loss: 630793.312 | Test loss: 1687980.125\nIteration: 683000 | Training Loss: 630678.438 | Test loss: 1687682.750\nIteration: 683200 | Training Loss: 630563.625 | Test loss: 1687386.125\nIteration: 683400 | Training Loss: 630448.938 | Test loss: 1687088.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 683600 | Training Loss: 630334.375 | Test loss: 1686789.750\nIteration: 683800 | Training Loss: 630219.812 | Test loss: 1686495.750\nIteration: 684000 | Training Loss: 630105.438 | Test loss: 1686200.875\nIteration: 684200 | Training Loss: 629991.062 | Test loss: 1685904.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 684400 | Training Loss: 629876.750 | Test loss: 1685609.750\nIteration: 684600 | Training Loss: 629762.625 | Test loss: 1685309.375\nIteration: 684800 | Training Loss: 629648.562 | Test loss: 1685013.000\nIteration: 685000 | Training Loss: 629534.562 | Test loss: 1684724.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 685200 | Training Loss: 629420.625 | Test loss: 1684423.375\nIteration: 685400 | Training Loss: 629306.812 | Test loss: 1684126.250\nIteration: 685600 | Training Loss: 629193.062 | Test loss: 1683830.250\nIteration: 685800 | Training Loss: 629079.438 | Test loss: 1683534.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 686000 | Training Loss: 628965.875 | Test loss: 1683239.875\nIteration: 686200 | Training Loss: 628852.438 | Test loss: 1682943.375\nIteration: 686400 | Training Loss: 628739.062 | Test loss: 1682647.000\nIteration: 686600 | Training Loss: 628625.750 | Test loss: 1682355.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 686800 | Training Loss: 628512.562 | Test loss: 1682059.125\nIteration: 687000 | Training Loss: 628399.438 | Test loss: 1681766.250\nIteration: 687200 | Training Loss: 628286.500 | Test loss: 1681464.375\nIteration: 687400 | Training Loss: 628173.500 | Test loss: 1681173.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 687600 | Training Loss: 628060.688 | Test loss: 1680875.000\nIteration: 687800 | Training Loss: 627947.938 | Test loss: 1680582.375\nIteration: 688000 | Training Loss: 627835.250 | Test loss: 1680289.625\nIteration: 688200 | Training Loss: 627722.625 | Test loss: 1680000.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 688400 | Training Loss: 627610.188 | Test loss: 1679699.875\nIteration: 688600 | Training Loss: 627497.750 | Test loss: 1679406.750\nIteration: 688800 | Training Loss: 627385.438 | Test loss: 1679114.750\nIteration: 689000 | Training Loss: 627273.188 | Test loss: 1678818.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 689200 | Training Loss: 627161.062 | Test loss: 1678526.250\nIteration: 689400 | Training Loss: 627048.938 | Test loss: 1678232.750\nIteration: 689600 | Training Loss: 626937.000 | Test loss: 1677937.625\nIteration: 689800 | Training Loss: 626825.062 | Test loss: 1677642.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 690000 | Training Loss: 626713.250 | Test loss: 1677350.000\nIteration: 690200 | Training Loss: 626601.562 | Test loss: 1677060.125\nIteration: 690400 | Training Loss: 626489.875 | Test loss: 1676759.750\nIteration: 690600 | Training Loss: 626378.375 | Test loss: 1676465.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 690800 | Training Loss: 626266.938 | Test loss: 1676182.500\nIteration: 691000 | Training Loss: 626155.500 | Test loss: 1675888.000\nIteration: 691200 | Training Loss: 626044.250 | Test loss: 1675596.625\nIteration: 691400 | Training Loss: 625933.062 | Test loss: 1675303.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 691600 | Training Loss: 625822.000 | Test loss: 1675012.250\nIteration: 691800 | Training Loss: 625710.938 | Test loss: 1674719.500\nIteration: 692000 | Training Loss: 625599.938 | Test loss: 1674427.625\nIteration: 692200 | Training Loss: 625489.125 | Test loss: 1674139.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 692400 | Training Loss: 625378.375 | Test loss: 1673837.375\nIteration: 692600 | Training Loss: 625267.625 | Test loss: 1673550.500\nIteration: 692800 | Training Loss: 625157.000 | Test loss: 1673261.875\nIteration: 693000 | Training Loss: 625046.562 | Test loss: 1672970.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 693200 | Training Loss: 624936.125 | Test loss: 1672681.000\nIteration: 693400 | Training Loss: 624825.750 | Test loss: 1672390.625\nIteration: 693600 | Training Loss: 624715.500 | Test loss: 1672100.125\nIteration: 693800 | Training Loss: 624605.375 | Test loss: 1671808.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 694000 | Training Loss: 624495.312 | Test loss: 1671519.125\nIteration: 694200 | Training Loss: 624385.312 | Test loss: 1671227.625\nIteration: 694400 | Training Loss: 624275.375 | Test loss: 1670936.125\nIteration: 694600 | Training Loss: 624165.562 | Test loss: 1670654.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 694800 | Training Loss: 624055.875 | Test loss: 1670353.750\nIteration: 695000 | Training Loss: 623946.188 | Test loss: 1670069.750\nIteration: 695200 | Training Loss: 623836.625 | Test loss: 1669782.000\nIteration: 695400 | Training Loss: 623727.188 | Test loss: 1669491.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 695600 | Training Loss: 623617.750 | Test loss: 1669202.375\nIteration: 695800 | Training Loss: 623508.438 | Test loss: 1668911.625\nIteration: 696000 | Training Loss: 623399.250 | Test loss: 1668624.125\nIteration: 696200 | Training Loss: 623290.125 | Test loss: 1668334.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 696400 | Training Loss: 623181.062 | Test loss: 1668052.500\nIteration: 696600 | Training Loss: 623072.125 | Test loss: 1667752.875\nIteration: 696800 | Training Loss: 622963.250 | Test loss: 1667473.500\nIteration: 697000 | Training Loss: 622854.500 | Test loss: 1667184.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 697200 | Training Loss: 622745.812 | Test loss: 1666895.750\nIteration: 697400 | Training Loss: 622637.188 | Test loss: 1666608.875\nIteration: 697600 | Training Loss: 622528.688 | Test loss: 1666325.625\nIteration: 697800 | Training Loss: 622420.250 | Test loss: 1666032.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 698000 | Training Loss: 622311.875 | Test loss: 1665745.125\nIteration: 698200 | Training Loss: 622203.625 | Test loss: 1665457.250\nIteration: 698400 | Training Loss: 622095.438 | Test loss: 1665168.375\nIteration: 698600 | Training Loss: 621987.375 | Test loss: 1664885.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 698800 | Training Loss: 621879.375 | Test loss: 1664593.250\nIteration: 699000 | Training Loss: 621771.500 | Test loss: 1664305.500\nIteration: 699200 | Training Loss: 621663.688 | Test loss: 1664017.000\nIteration: 699400 | Training Loss: 621555.938 | Test loss: 1663729.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 699600 | Training Loss: 621448.312 | Test loss: 1663442.250\nIteration: 699800 | Training Loss: 621340.688 | Test loss: 1663155.625\nIteration: 700000 | Training Loss: 621233.250 | Test loss: 1662870.375\nIteration: 700200 | Training Loss: 621125.812 | Test loss: 1662581.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 700400 | Training Loss: 621018.562 | Test loss: 1662295.625\nIteration: 700600 | Training Loss: 620911.312 | Test loss: 1662008.500\nIteration: 700800 | Training Loss: 620804.188 | Test loss: 1661722.750\nIteration: 701000 | Training Loss: 620697.125 | Test loss: 1661438.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 701200 | Training Loss: 620590.250 | Test loss: 1661146.250\nIteration: 701400 | Training Loss: 620483.312 | Test loss: 1660865.125\nIteration: 701600 | Training Loss: 620376.562 | Test loss: 1660580.250\nIteration: 701800 | Training Loss: 620269.875 | Test loss: 1660290.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 702000 | Training Loss: 620163.250 | Test loss: 1660008.000\nIteration: 702200 | Training Loss: 620056.750 | Test loss: 1659726.500\nIteration: 702400 | Training Loss: 619950.375 | Test loss: 1659435.625\nIteration: 702600 | Training Loss: 619844.000 | Test loss: 1659150.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 702800 | Training Loss: 619737.812 | Test loss: 1658865.000\nIteration: 703000 | Training Loss: 619631.625 | Test loss: 1658578.375\nIteration: 703200 | Training Loss: 619525.500 | Test loss: 1658293.875\nIteration: 703400 | Training Loss: 619419.562 | Test loss: 1658006.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 703600 | Training Loss: 619313.625 | Test loss: 1657721.375\nIteration: 703800 | Training Loss: 619207.812 | Test loss: 1657436.875\nIteration: 704000 | Training Loss: 619102.062 | Test loss: 1657152.875\nIteration: 704200 | Training Loss: 618996.375 | Test loss: 1656863.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 704400 | Training Loss: 618890.875 | Test loss: 1656579.125\nIteration: 704600 | Training Loss: 618785.375 | Test loss: 1656293.500\nIteration: 704800 | Training Loss: 618680.000 | Test loss: 1656010.750\nIteration: 705000 | Training Loss: 618574.688 | Test loss: 1655723.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 705200 | Training Loss: 618469.438 | Test loss: 1655436.625\nIteration: 705400 | Training Loss: 618364.375 | Test loss: 1655151.375\nIteration: 705600 | Training Loss: 618259.312 | Test loss: 1654860.875\nIteration: 705800 | Training Loss: 618154.312 | Test loss: 1654572.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 706000 | Training Loss: 618049.438 | Test loss: 1654291.875\nIteration: 706200 | Training Loss: 617944.688 | Test loss: 1654004.750\nIteration: 706400 | Training Loss: 617839.938 | Test loss: 1653719.500\nIteration: 706600 | Training Loss: 617735.312 | Test loss: 1653426.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 706800 | Training Loss: 617630.750 | Test loss: 1653145.500\nIteration: 707000 | Training Loss: 617526.312 | Test loss: 1652858.375\nIteration: 707200 | Training Loss: 617421.938 | Test loss: 1652571.125\nIteration: 707400 | Training Loss: 617317.625 | Test loss: 1652286.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 707600 | Training Loss: 617213.438 | Test loss: 1652001.875\nIteration: 707800 | Training Loss: 617109.312 | Test loss: 1651709.625\nIteration: 708000 | Training Loss: 617005.312 | Test loss: 1651420.875\nIteration: 708200 | Training Loss: 616901.312 | Test loss: 1651135.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 708400 | Training Loss: 616797.438 | Test loss: 1650843.750\nIteration: 708600 | Training Loss: 616693.688 | Test loss: 1650560.500\nIteration: 708800 | Training Loss: 616590.000 | Test loss: 1650271.750\nIteration: 709000 | Training Loss: 616486.312 | Test loss: 1649982.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 709200 | Training Loss: 616382.750 | Test loss: 1649696.375\nIteration: 709400 | Training Loss: 616279.375 | Test loss: 1649407.625\nIteration: 709600 | Training Loss: 616175.938 | Test loss: 1649117.875\nIteration: 709800 | Training Loss: 616072.688 | Test loss: 1648834.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 710000 | Training Loss: 615969.438 | Test loss: 1648551.125\nIteration: 710200 | Training Loss: 615866.375 | Test loss: 1648259.750\nIteration: 710400 | Training Loss: 615763.312 | Test loss: 1647969.000\nIteration: 710600 | Training Loss: 615660.375 | Test loss: 1647685.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 710800 | Training Loss: 615557.500 | Test loss: 1647396.250\nIteration: 711000 | Training Loss: 615454.688 | Test loss: 1647111.000\nIteration: 711200 | Training Loss: 615352.000 | Test loss: 1646815.625\nIteration: 711400 | Training Loss: 615249.375 | Test loss: 1646534.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 711600 | Training Loss: 615146.812 | Test loss: 1646247.000\nIteration: 711800 | Training Loss: 615044.375 | Test loss: 1645957.250\nIteration: 712000 | Training Loss: 614942.062 | Test loss: 1645667.875\nIteration: 712200 | Training Loss: 614839.750 | Test loss: 1645386.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 712400 | Training Loss: 614737.562 | Test loss: 1645100.125\nIteration: 712600 | Training Loss: 614635.438 | Test loss: 1644809.125\nIteration: 712800 | Training Loss: 614533.438 | Test loss: 1644528.000\nIteration: 713000 | Training Loss: 614431.500 | Test loss: 1644240.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 713200 | Training Loss: 614329.688 | Test loss: 1643953.125\nIteration: 713400 | Training Loss: 614227.812 | Test loss: 1643671.000\nIteration: 713600 | Training Loss: 614126.188 | Test loss: 1643381.625\nIteration: 713800 | Training Loss: 614024.562 | Test loss: 1643098.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 714000 | Training Loss: 613923.000 | Test loss: 1642812.250\nIteration: 714200 | Training Loss: 613821.562 | Test loss: 1642527.250\nIteration: 714400 | Training Loss: 613720.250 | Test loss: 1642244.750\nIteration: 714600 | Training Loss: 613618.938 | Test loss: 1641960.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 714800 | Training Loss: 613517.812 | Test loss: 1641673.625\nIteration: 715000 | Training Loss: 613416.625 | Test loss: 1641387.000\nIteration: 715200 | Training Loss: 613315.625 | Test loss: 1641101.875\nIteration: 715400 | Training Loss: 613214.688 | Test loss: 1640819.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 715600 | Training Loss: 613113.875 | Test loss: 1640535.250\nIteration: 715800 | Training Loss: 613013.062 | Test loss: 1640251.375\nIteration: 716000 | Training Loss: 612912.375 | Test loss: 1639965.500\nIteration: 716200 | Training Loss: 612811.812 | Test loss: 1639688.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 716400 | Training Loss: 612711.250 | Test loss: 1639398.000\nIteration: 716600 | Training Loss: 612610.812 | Test loss: 1639112.875\nIteration: 716800 | Training Loss: 612510.500 | Test loss: 1638829.375\nIteration: 717000 | Training Loss: 612410.188 | Test loss: 1638544.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 717200 | Training Loss: 612310.062 | Test loss: 1638268.000\nIteration: 717400 | Training Loss: 612209.938 | Test loss: 1637984.875\nIteration: 717600 | Training Loss: 612109.938 | Test loss: 1637699.875\nIteration: 717800 | Training Loss: 612010.000 | Test loss: 1637415.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 718000 | Training Loss: 611910.188 | Test loss: 1637131.875\nIteration: 718200 | Training Loss: 611810.375 | Test loss: 1636854.125\nIteration: 718400 | Training Loss: 611710.750 | Test loss: 1636569.250\nIteration: 718600 | Training Loss: 611611.125 | Test loss: 1636279.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 718800 | Training Loss: 611511.625 | Test loss: 1636004.375\nIteration: 719000 | Training Loss: 611412.188 | Test loss: 1635722.000\nIteration: 719200 | Training Loss: 611312.812 | Test loss: 1635440.500\nIteration: 719400 | Training Loss: 611213.562 | Test loss: 1635154.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 719600 | Training Loss: 611114.375 | Test loss: 1634874.500\nIteration: 719800 | Training Loss: 611015.312 | Test loss: 1634595.000\nIteration: 720000 | Training Loss: 610916.312 | Test loss: 1634314.000\nIteration: 720200 | Training Loss: 610817.375 | Test loss: 1634033.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 720400 | Training Loss: 610718.500 | Test loss: 1633748.875\nIteration: 720600 | Training Loss: 610619.750 | Test loss: 1633470.375\nIteration: 720800 | Training Loss: 610521.125 | Test loss: 1633190.000\nIteration: 721000 | Training Loss: 610422.500 | Test loss: 1632909.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 721200 | Training Loss: 610324.062 | Test loss: 1632625.625\nIteration: 721400 | Training Loss: 610225.562 | Test loss: 1632352.125\nIteration: 721600 | Training Loss: 610127.250 | Test loss: 1632067.625\nIteration: 721800 | Training Loss: 610029.000 | Test loss: 1631791.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 722000 | Training Loss: 609930.875 | Test loss: 1631510.500\nIteration: 722200 | Training Loss: 609832.750 | Test loss: 1631230.000\nIteration: 722400 | Training Loss: 609734.812 | Test loss: 1630950.375\nIteration: 722600 | Training Loss: 609636.875 | Test loss: 1630667.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 722800 | Training Loss: 609539.000 | Test loss: 1630388.750\nIteration: 723000 | Training Loss: 609441.250 | Test loss: 1630110.000\nIteration: 723200 | Training Loss: 609343.625 | Test loss: 1629834.375\nIteration: 723400 | Training Loss: 609246.000 | Test loss: 1629559.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 723600 | Training Loss: 609148.562 | Test loss: 1629276.750\nIteration: 723800 | Training Loss: 609051.125 | Test loss: 1629004.625\nIteration: 724000 | Training Loss: 608953.812 | Test loss: 1628719.250\nIteration: 724200 | Training Loss: 608856.562 | Test loss: 1628444.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 724400 | Training Loss: 608759.375 | Test loss: 1628163.375\nIteration: 724600 | Training Loss: 608662.375 | Test loss: 1627885.250\nIteration: 724800 | Training Loss: 608565.312 | Test loss: 1627607.625\nIteration: 725000 | Training Loss: 608468.438 | Test loss: 1627331.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 725200 | Training Loss: 608371.625 | Test loss: 1627052.750\nIteration: 725400 | Training Loss: 608274.875 | Test loss: 1626776.500\nIteration: 725600 | Training Loss: 608178.250 | Test loss: 1626496.250\nIteration: 725800 | Training Loss: 608081.688 | Test loss: 1626221.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 726000 | Training Loss: 607985.188 | Test loss: 1625942.500\nIteration: 726200 | Training Loss: 607888.875 | Test loss: 1625672.750\nIteration: 726400 | Training Loss: 607792.500 | Test loss: 1625386.000\nIteration: 726600 | Training Loss: 607696.312 | Test loss: 1625117.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 726800 | Training Loss: 607600.125 | Test loss: 1624836.625\nIteration: 727000 | Training Loss: 607504.125 | Test loss: 1624566.750\nIteration: 727200 | Training Loss: 607408.125 | Test loss: 1624278.750\nIteration: 727400 | Training Loss: 607312.250 | Test loss: 1624007.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 727600 | Training Loss: 607216.438 | Test loss: 1623729.625\nIteration: 727800 | Training Loss: 607120.688 | Test loss: 1623455.250\nIteration: 728000 | Training Loss: 607025.000 | Test loss: 1623179.375\nIteration: 728200 | Training Loss: 606929.500 | Test loss: 1622903.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 728400 | Training Loss: 606834.062 | Test loss: 1622627.375\nIteration: 728600 | Training Loss: 606738.625 | Test loss: 1622352.750\nIteration: 728800 | Training Loss: 606643.312 | Test loss: 1622078.000\nIteration: 729000 | Training Loss: 606548.125 | Test loss: 1621801.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 729200 | Training Loss: 606452.938 | Test loss: 1621532.500\nIteration: 729400 | Training Loss: 606357.938 | Test loss: 1621249.375\nIteration: 729600 | Training Loss: 606262.938 | Test loss: 1620976.500\nIteration: 729800 | Training Loss: 606168.062 | Test loss: 1620705.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 730000 | Training Loss: 606073.312 | Test loss: 1620429.000\nIteration: 730200 | Training Loss: 605978.562 | Test loss: 1620155.500\nIteration: 730400 | Training Loss: 605883.938 | Test loss: 1619880.750\nIteration: 730600 | Training Loss: 605789.312 | Test loss: 1619607.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 730800 | Training Loss: 605694.875 | Test loss: 1619333.125\nIteration: 731000 | Training Loss: 605600.500 | Test loss: 1619060.375\nIteration: 731200 | Training Loss: 605506.188 | Test loss: 1618787.625\nIteration: 731400 | Training Loss: 605412.000 | Test loss: 1618513.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 731600 | Training Loss: 605317.875 | Test loss: 1618240.375\nIteration: 731800 | Training Loss: 605223.812 | Test loss: 1617965.625\nIteration: 732000 | Training Loss: 605129.875 | Test loss: 1617694.250\nIteration: 732200 | Training Loss: 605036.000 | Test loss: 1617421.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 732400 | Training Loss: 604942.188 | Test loss: 1617149.000\nIteration: 732600 | Training Loss: 604848.438 | Test loss: 1616875.625\nIteration: 732800 | Training Loss: 604754.875 | Test loss: 1616601.375\nIteration: 733000 | Training Loss: 604661.312 | Test loss: 1616336.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 733200 | Training Loss: 604567.812 | Test loss: 1616059.500\nIteration: 733400 | Training Loss: 604474.438 | Test loss: 1615789.375\nIteration: 733600 | Training Loss: 604381.188 | Test loss: 1615518.250\nIteration: 733800 | Training Loss: 604287.938 | Test loss: 1615244.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 734000 | Training Loss: 604194.812 | Test loss: 1614972.000\nIteration: 734200 | Training Loss: 604101.750 | Test loss: 1614702.375\nIteration: 734400 | Training Loss: 604008.812 | Test loss: 1614425.125\nIteration: 734600 | Training Loss: 603915.938 | Test loss: 1614160.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 734800 | Training Loss: 603823.188 | Test loss: 1613888.000\nIteration: 735000 | Training Loss: 603730.438 | Test loss: 1613618.125\nIteration: 735200 | Training Loss: 603637.812 | Test loss: 1613348.375\nIteration: 735400 | Training Loss: 603545.250 | Test loss: 1613077.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 735600 | Training Loss: 603452.812 | Test loss: 1612810.000\nIteration: 735800 | Training Loss: 603360.438 | Test loss: 1612537.000\nIteration: 736000 | Training Loss: 603268.188 | Test loss: 1612265.500\nIteration: 736200 | Training Loss: 603176.000 | Test loss: 1611995.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 736400 | Training Loss: 603083.812 | Test loss: 1611726.375\nIteration: 736600 | Training Loss: 602991.750 | Test loss: 1611456.625\nIteration: 736800 | Training Loss: 602899.812 | Test loss: 1611188.250\nIteration: 737000 | Training Loss: 602807.938 | Test loss: 1610919.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 737200 | Training Loss: 602716.188 | Test loss: 1610647.750\nIteration: 737400 | Training Loss: 602624.500 | Test loss: 1610378.625\nIteration: 737600 | Training Loss: 602532.875 | Test loss: 1610107.625\nIteration: 737800 | Training Loss: 602441.312 | Test loss: 1609842.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 738000 | Training Loss: 602349.875 | Test loss: 1609572.875\nIteration: 738200 | Training Loss: 602258.500 | Test loss: 1609304.000\nIteration: 738400 | Training Loss: 602167.250 | Test loss: 1609034.250\nIteration: 738600 | Training Loss: 602076.062 | Test loss: 1608763.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 738800 | Training Loss: 601984.938 | Test loss: 1608498.250\nIteration: 739000 | Training Loss: 601893.938 | Test loss: 1608229.375\nIteration: 739200 | Training Loss: 601803.000 | Test loss: 1607963.375\nIteration: 739400 | Training Loss: 601712.125 | Test loss: 1607697.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 739600 | Training Loss: 601621.312 | Test loss: 1607426.375\nIteration: 739800 | Training Loss: 601530.688 | Test loss: 1607164.500\nIteration: 740000 | Training Loss: 601440.062 | Test loss: 1606895.875\nIteration: 740200 | Training Loss: 601349.562 | Test loss: 1606628.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 740400 | Training Loss: 601259.188 | Test loss: 1606354.625\nIteration: 740600 | Training Loss: 601168.812 | Test loss: 1606081.000\nIteration: 740800 | Training Loss: 601078.625 | Test loss: 1605820.625\nIteration: 741000 | Training Loss: 600988.438 | Test loss: 1605554.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 741200 | Training Loss: 600898.375 | Test loss: 1605286.625\nIteration: 741400 | Training Loss: 600808.375 | Test loss: 1605021.625\nIteration: 741600 | Training Loss: 600718.438 | Test loss: 1604753.750\nIteration: 741800 | Training Loss: 600628.688 | Test loss: 1604487.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 742000 | Training Loss: 600538.938 | Test loss: 1604220.250\nIteration: 742200 | Training Loss: 600449.375 | Test loss: 1603961.125\nIteration: 742400 | Training Loss: 600359.875 | Test loss: 1603688.750\nIteration: 742600 | Training Loss: 600270.438 | Test loss: 1603419.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 742800 | Training Loss: 600181.062 | Test loss: 1603149.500\nIteration: 743000 | Training Loss: 600091.812 | Test loss: 1602889.000\nIteration: 743200 | Training Loss: 600002.562 | Test loss: 1602620.375\nIteration: 743400 | Training Loss: 599913.500 | Test loss: 1602357.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 743600 | Training Loss: 599824.438 | Test loss: 1602099.875\nIteration: 743800 | Training Loss: 599735.500 | Test loss: 1601827.125\nIteration: 744000 | Training Loss: 599646.625 | Test loss: 1601561.500\nIteration: 744200 | Training Loss: 599557.875 | Test loss: 1601295.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 744400 | Training Loss: 599469.125 | Test loss: 1601030.000\nIteration: 744600 | Training Loss: 599380.562 | Test loss: 1600765.625\nIteration: 744800 | Training Loss: 599292.062 | Test loss: 1600501.000\nIteration: 745000 | Training Loss: 599203.562 | Test loss: 1600234.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 745200 | Training Loss: 599115.250 | Test loss: 1599971.125\nIteration: 745400 | Training Loss: 599026.938 | Test loss: 1599705.250\nIteration: 745600 | Training Loss: 598938.750 | Test loss: 1599442.375\nIteration: 745800 | Training Loss: 598850.625 | Test loss: 1599183.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 746000 | Training Loss: 598762.562 | Test loss: 1598914.250\nIteration: 746200 | Training Loss: 598674.625 | Test loss: 1598652.500\nIteration: 746400 | Training Loss: 598586.750 | Test loss: 1598385.875\nIteration: 746600 | Training Loss: 598499.000 | Test loss: 1598126.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 746800 | Training Loss: 598411.250 | Test loss: 1597855.625\nIteration: 747000 | Training Loss: 598323.625 | Test loss: 1597593.125\nIteration: 747200 | Training Loss: 598236.125 | Test loss: 1597329.625\nIteration: 747400 | Training Loss: 598148.688 | Test loss: 1597071.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 747600 | Training Loss: 598061.312 | Test loss: 1596805.000\nIteration: 747800 | Training Loss: 597974.000 | Test loss: 1596539.125\nIteration: 748000 | Training Loss: 597886.812 | Test loss: 1596275.125\nIteration: 748200 | Training Loss: 597799.688 | Test loss: 1596013.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 748400 | Training Loss: 597712.688 | Test loss: 1595750.750\nIteration: 748600 | Training Loss: 597625.688 | Test loss: 1595486.000\nIteration: 748800 | Training Loss: 597538.812 | Test loss: 1595223.125\nIteration: 749000 | Training Loss: 597452.000 | Test loss: 1594966.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 749200 | Training Loss: 597365.312 | Test loss: 1594697.875\nIteration: 749400 | Training Loss: 597278.688 | Test loss: 1594442.250\nIteration: 749600 | Training Loss: 597192.188 | Test loss: 1594172.250\nIteration: 749800 | Training Loss: 597105.750 | Test loss: 1593909.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 750000 | Training Loss: 597019.375 | Test loss: 1593646.000\nIteration: 750200 | Training Loss: 596933.062 | Test loss: 1593386.000\nIteration: 750400 | Training Loss: 596846.875 | Test loss: 1593118.375\nIteration: 750600 | Training Loss: 596760.688 | Test loss: 1592857.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 750800 | Training Loss: 596674.688 | Test loss: 1592593.750\nIteration: 751000 | Training Loss: 596588.750 | Test loss: 1592329.625\nIteration: 751200 | Training Loss: 596502.875 | Test loss: 1592064.500\nIteration: 751400 | Training Loss: 596417.062 | Test loss: 1591803.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 751600 | Training Loss: 596331.375 | Test loss: 1591537.375\nIteration: 751800 | Training Loss: 596245.750 | Test loss: 1591268.375\nIteration: 752000 | Training Loss: 596160.188 | Test loss: 1591011.000\nIteration: 752200 | Training Loss: 596074.750 | Test loss: 1590745.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 752400 | Training Loss: 595989.375 | Test loss: 1590482.000\nIteration: 752600 | Training Loss: 595904.125 | Test loss: 1590216.750\nIteration: 752800 | Training Loss: 595818.875 | Test loss: 1589951.125\nIteration: 753000 | Training Loss: 595733.750 | Test loss: 1589686.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 753200 | Training Loss: 595648.688 | Test loss: 1589420.250\nIteration: 753400 | Training Loss: 595563.688 | Test loss: 1589154.125\nIteration: 753600 | Training Loss: 595478.812 | Test loss: 1588890.125\nIteration: 753800 | Training Loss: 595394.000 | Test loss: 1588622.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 754000 | Training Loss: 595309.312 | Test loss: 1588356.875\nIteration: 754200 | Training Loss: 595224.750 | Test loss: 1588091.375\nIteration: 754400 | Training Loss: 595140.188 | Test loss: 1587824.375\nIteration: 754600 | Training Loss: 595055.812 | Test loss: 1587552.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 754800 | Training Loss: 594971.438 | Test loss: 1587288.375\nIteration: 755000 | Training Loss: 594887.188 | Test loss: 1587025.000\nIteration: 755200 | Training Loss: 594802.938 | Test loss: 1586758.750\nIteration: 755400 | Training Loss: 594718.875 | Test loss: 1586491.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 755600 | Training Loss: 594634.812 | Test loss: 1586226.000\nIteration: 755800 | Training Loss: 594550.812 | Test loss: 1585955.125\nIteration: 756000 | Training Loss: 594466.938 | Test loss: 1585690.625\nIteration: 756200 | Training Loss: 594383.125 | Test loss: 1585424.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 756400 | Training Loss: 594299.438 | Test loss: 1585155.375\nIteration: 756600 | Training Loss: 594215.812 | Test loss: 1584890.000\nIteration: 756800 | Training Loss: 594132.188 | Test loss: 1584624.250\nIteration: 757000 | Training Loss: 594048.750 | Test loss: 1584358.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 757200 | Training Loss: 593965.375 | Test loss: 1584097.750\nIteration: 757400 | Training Loss: 593882.000 | Test loss: 1583825.125\nIteration: 757600 | Training Loss: 593798.750 | Test loss: 1583558.625\nIteration: 757800 | Training Loss: 593715.625 | Test loss: 1583293.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 758000 | Training Loss: 593632.500 | Test loss: 1583026.500\nIteration: 758200 | Training Loss: 593549.500 | Test loss: 1582760.750\nIteration: 758400 | Training Loss: 593466.562 | Test loss: 1582487.000\nIteration: 758600 | Training Loss: 593383.688 | Test loss: 1582216.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 758800 | Training Loss: 593300.938 | Test loss: 1581955.875\nIteration: 759000 | Training Loss: 593218.250 | Test loss: 1581688.375\nIteration: 759200 | Training Loss: 593135.625 | Test loss: 1581419.875\nIteration: 759400 | Training Loss: 593053.000 | Test loss: 1581151.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 759600 | Training Loss: 592970.625 | Test loss: 1580885.125\nIteration: 759800 | Training Loss: 592888.188 | Test loss: 1580615.500\nIteration: 760000 | Training Loss: 592805.875 | Test loss: 1580345.750\nIteration: 760200 | Training Loss: 592723.688 | Test loss: 1580075.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 760400 | Training Loss: 592641.500 | Test loss: 1579806.500\nIteration: 760600 | Training Loss: 592559.375 | Test loss: 1579537.625\nIteration: 760800 | Training Loss: 592477.438 | Test loss: 1579267.875\nIteration: 761000 | Training Loss: 592395.500 | Test loss: 1578998.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 761200 | Training Loss: 592313.625 | Test loss: 1578724.375\nIteration: 761400 | Training Loss: 592231.875 | Test loss: 1578459.500\nIteration: 761600 | Training Loss: 592150.188 | Test loss: 1578190.500\nIteration: 761800 | Training Loss: 592068.562 | Test loss: 1577919.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 762000 | Training Loss: 591987.062 | Test loss: 1577644.375\nIteration: 762200 | Training Loss: 591905.562 | Test loss: 1577374.875\nIteration: 762400 | Training Loss: 591824.125 | Test loss: 1577104.750\nIteration: 762600 | Training Loss: 591742.812 | Test loss: 1576835.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 762800 | Training Loss: 591661.562 | Test loss: 1576564.125\nIteration: 763000 | Training Loss: 591580.375 | Test loss: 1576292.750\nIteration: 763200 | Training Loss: 591499.250 | Test loss: 1576020.125\nIteration: 763400 | Training Loss: 591418.250 | Test loss: 1575753.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 763600 | Training Loss: 591337.250 | Test loss: 1575484.250\nIteration: 763800 | Training Loss: 591256.438 | Test loss: 1575215.500\nIteration: 764000 | Training Loss: 591175.688 | Test loss: 1574946.125\nIteration: 764200 | Training Loss: 591094.938 | Test loss: 1574679.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 764400 | Training Loss: 591014.312 | Test loss: 1574410.625\nIteration: 764600 | Training Loss: 590933.750 | Test loss: 1574144.125\nIteration: 764800 | Training Loss: 590853.250 | Test loss: 1573874.500\nIteration: 765000 | Training Loss: 590772.812 | Test loss: 1573606.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 765200 | Training Loss: 590692.438 | Test loss: 1573339.625\nIteration: 765400 | Training Loss: 590612.188 | Test loss: 1573071.375\nIteration: 765600 | Training Loss: 590532.000 | Test loss: 1572804.875\nIteration: 765800 | Training Loss: 590451.812 | Test loss: 1572537.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 766000 | Training Loss: 590371.750 | Test loss: 1572269.375\nIteration: 766200 | Training Loss: 590291.750 | Test loss: 1571997.375\nIteration: 766400 | Training Loss: 590211.875 | Test loss: 1571735.875\nIteration: 766600 | Training Loss: 590132.000 | Test loss: 1571469.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 766800 | Training Loss: 590052.250 | Test loss: 1571203.250\nIteration: 767000 | Training Loss: 589972.562 | Test loss: 1570935.375\nIteration: 767200 | Training Loss: 589892.938 | Test loss: 1570668.250\nIteration: 767400 | Training Loss: 589813.375 | Test loss: 1570405.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 767600 | Training Loss: 589733.875 | Test loss: 1570136.125\nIteration: 767800 | Training Loss: 589654.438 | Test loss: 1569878.250\nIteration: 768000 | Training Loss: 589575.125 | Test loss: 1569604.875\nIteration: 768200 | Training Loss: 589495.875 | Test loss: 1569336.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 768400 | Training Loss: 589416.688 | Test loss: 1569075.875\nIteration: 768600 | Training Loss: 589337.562 | Test loss: 1568805.500\nIteration: 768800 | Training Loss: 589258.562 | Test loss: 1568546.500\nIteration: 769000 | Training Loss: 589179.625 | Test loss: 1568282.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 769200 | Training Loss: 589100.688 | Test loss: 1568019.000\nIteration: 769400 | Training Loss: 589021.938 | Test loss: 1567754.750\nIteration: 769600 | Training Loss: 588943.125 | Test loss: 1567491.500\nIteration: 769800 | Training Loss: 588864.500 | Test loss: 1567220.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 770000 | Training Loss: 588785.875 | Test loss: 1566964.875\nIteration: 770200 | Training Loss: 588707.375 | Test loss: 1566700.250\nIteration: 770400 | Training Loss: 588628.938 | Test loss: 1566436.125\nIteration: 770600 | Training Loss: 588550.500 | Test loss: 1566172.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 770800 | Training Loss: 588472.188 | Test loss: 1565914.625\nIteration: 771000 | Training Loss: 588394.000 | Test loss: 1565652.125\nIteration: 771200 | Training Loss: 588315.812 | Test loss: 1565390.625\nIteration: 771400 | Training Loss: 588237.750 | Test loss: 1565128.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 771600 | Training Loss: 588159.625 | Test loss: 1564866.750\nIteration: 771800 | Training Loss: 588081.750 | Test loss: 1564610.750\nIteration: 772000 | Training Loss: 588003.875 | Test loss: 1564345.375\nIteration: 772200 | Training Loss: 587926.062 | Test loss: 1564084.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 772400 | Training Loss: 587848.375 | Test loss: 1563826.625\nIteration: 772600 | Training Loss: 587770.688 | Test loss: 1563567.875\nIteration: 772800 | Training Loss: 587693.125 | Test loss: 1563307.375\nIteration: 773000 | Training Loss: 587615.625 | Test loss: 1563046.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 773200 | Training Loss: 587538.188 | Test loss: 1562795.125\nIteration: 773400 | Training Loss: 587460.750 | Test loss: 1562529.875\nIteration: 773600 | Training Loss: 587383.438 | Test loss: 1562273.625\nIteration: 773800 | Training Loss: 587306.250 | Test loss: 1562016.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 774000 | Training Loss: 587229.062 | Test loss: 1561759.875\nIteration: 774200 | Training Loss: 587152.000 | Test loss: 1561500.875\nIteration: 774400 | Training Loss: 587074.938 | Test loss: 1561244.500\nIteration: 774600 | Training Loss: 586998.000 | Test loss: 1560991.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 774800 | Training Loss: 586921.188 | Test loss: 1560736.500\nIteration: 775000 | Training Loss: 586844.375 | Test loss: 1560481.625\nIteration: 775200 | Training Loss: 586767.625 | Test loss: 1560230.375\nIteration: 775400 | Training Loss: 586690.938 | Test loss: 1559973.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 775600 | Training Loss: 586614.375 | Test loss: 1559721.875\nIteration: 775800 | Training Loss: 586537.812 | Test loss: 1559467.375\nIteration: 776000 | Training Loss: 586461.375 | Test loss: 1559221.250\nIteration: 776200 | Training Loss: 586384.938 | Test loss: 1558964.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 776400 | Training Loss: 586308.688 | Test loss: 1558717.125\nIteration: 776600 | Training Loss: 586232.438 | Test loss: 1558468.750\nIteration: 776800 | Training Loss: 586156.250 | Test loss: 1558220.125\nIteration: 777000 | Training Loss: 586080.062 | Test loss: 1557974.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 777200 | Training Loss: 586004.062 | Test loss: 1557726.750\nIteration: 777400 | Training Loss: 585928.062 | Test loss: 1557482.125\nIteration: 777600 | Training Loss: 585852.125 | Test loss: 1557243.250\nIteration: 777800 | Training Loss: 585776.250 | Test loss: 1556996.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 778000 | Training Loss: 585700.438 | Test loss: 1556756.625\nIteration: 778200 | Training Loss: 585624.750 | Test loss: 1556519.250\nIteration: 778400 | Training Loss: 585549.062 | Test loss: 1556278.375\nIteration: 778600 | Training Loss: 585473.438 | Test loss: 1556040.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 778800 | Training Loss: 585397.938 | Test loss: 1555807.875\nIteration: 779000 | Training Loss: 585322.438 | Test loss: 1555574.875\nIteration: 779200 | Training Loss: 585247.000 | Test loss: 1555343.625\nIteration: 779400 | Training Loss: 585171.625 | Test loss: 1555115.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 779600 | Training Loss: 585096.375 | Test loss: 1554884.500\nIteration: 779800 | Training Loss: 585021.062 | Test loss: 1554660.125\nIteration: 780000 | Training Loss: 584945.938 | Test loss: 1554436.500\nIteration: 780200 | Training Loss: 584870.812 | Test loss: 1554214.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 780400 | Training Loss: 584795.688 | Test loss: 1553992.625\nIteration: 780600 | Training Loss: 584720.688 | Test loss: 1553777.250\nIteration: 780800 | Training Loss: 584645.812 | Test loss: 1553554.375\nIteration: 781000 | Training Loss: 584570.875 | Test loss: 1553337.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 781200 | Training Loss: 584496.000 | Test loss: 1553119.875\nIteration: 781400 | Training Loss: 584421.250 | Test loss: 1552900.500\nIteration: 781600 | Training Loss: 584346.562 | Test loss: 1552686.250\nIteration: 781800 | Training Loss: 584271.938 | Test loss: 1552470.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 782000 | Training Loss: 584197.250 | Test loss: 1552255.375\nIteration: 782200 | Training Loss: 584122.750 | Test loss: 1552037.875\nIteration: 782400 | Training Loss: 584048.250 | Test loss: 1551817.125\nIteration: 782600 | Training Loss: 583973.812 | Test loss: 1551604.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 782800 | Training Loss: 583899.438 | Test loss: 1551390.750\nIteration: 783000 | Training Loss: 583825.125 | Test loss: 1551173.000\nIteration: 783200 | Training Loss: 583750.875 | Test loss: 1550961.250\nIteration: 783400 | Training Loss: 583676.625 | Test loss: 1550740.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 783600 | Training Loss: 583602.562 | Test loss: 1550523.000\nIteration: 783800 | Training Loss: 583528.438 | Test loss: 1550310.125\nIteration: 784000 | Training Loss: 583454.375 | Test loss: 1550095.750\nIteration: 784200 | Training Loss: 583380.438 | Test loss: 1549880.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 784400 | Training Loss: 583306.562 | Test loss: 1549664.500\nIteration: 784600 | Training Loss: 583232.688 | Test loss: 1549450.500\nIteration: 784800 | Training Loss: 583158.875 | Test loss: 1549234.875\nIteration: 785000 | Training Loss: 583085.125 | Test loss: 1549018.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 785200 | Training Loss: 583011.500 | Test loss: 1548801.375\nIteration: 785400 | Training Loss: 582937.812 | Test loss: 1548590.375\nIteration: 785600 | Training Loss: 582864.250 | Test loss: 1548377.500\nIteration: 785800 | Training Loss: 582790.750 | Test loss: 1548164.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 786000 | Training Loss: 582717.312 | Test loss: 1547946.750\nIteration: 786200 | Training Loss: 582643.938 | Test loss: 1547731.500\nIteration: 786400 | Training Loss: 582570.625 | Test loss: 1547519.750\nIteration: 786600 | Training Loss: 582497.312 | Test loss: 1547304.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 786800 | Training Loss: 582424.125 | Test loss: 1547090.375\nIteration: 787000 | Training Loss: 582350.938 | Test loss: 1546873.250\nIteration: 787200 | Training Loss: 582277.875 | Test loss: 1546664.000\nIteration: 787400 | Training Loss: 582204.812 | Test loss: 1546446.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 787600 | Training Loss: 582131.812 | Test loss: 1546237.500\nIteration: 787800 | Training Loss: 582058.875 | Test loss: 1546018.125\nIteration: 788000 | Training Loss: 581986.000 | Test loss: 1545811.000\nIteration: 788200 | Training Loss: 581913.250 | Test loss: 1545592.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 788400 | Training Loss: 581840.438 | Test loss: 1545380.375\nIteration: 788600 | Training Loss: 581767.750 | Test loss: 1545167.375\nIteration: 788800 | Training Loss: 581695.188 | Test loss: 1544954.375\nIteration: 789000 | Training Loss: 581622.562 | Test loss: 1544742.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 789200 | Training Loss: 581550.062 | Test loss: 1544527.750\nIteration: 789400 | Training Loss: 581477.562 | Test loss: 1544315.125\nIteration: 789600 | Training Loss: 581405.125 | Test loss: 1544101.750\nIteration: 789800 | Training Loss: 581332.812 | Test loss: 1543887.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 790000 | Training Loss: 581260.562 | Test loss: 1543674.625\nIteration: 790200 | Training Loss: 581188.312 | Test loss: 1543461.750\nIteration: 790400 | Training Loss: 581116.125 | Test loss: 1543249.375\nIteration: 790600 | Training Loss: 581044.000 | Test loss: 1543040.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 790800 | Training Loss: 580971.938 | Test loss: 1542824.000\nIteration: 791000 | Training Loss: 580899.938 | Test loss: 1542613.625\nIteration: 791200 | Training Loss: 580828.000 | Test loss: 1542402.750\nIteration: 791400 | Training Loss: 580756.125 | Test loss: 1542184.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 791600 | Training Loss: 580684.312 | Test loss: 1541970.750\nIteration: 791800 | Training Loss: 580612.562 | Test loss: 1541762.625\nIteration: 792000 | Training Loss: 580540.750 | Test loss: 1541550.625\nIteration: 792200 | Training Loss: 580469.188 | Test loss: 1541340.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 792400 | Training Loss: 580397.562 | Test loss: 1541129.125\nIteration: 792600 | Training Loss: 580326.062 | Test loss: 1540917.250\nIteration: 792800 | Training Loss: 580254.562 | Test loss: 1540705.500\nIteration: 793000 | Training Loss: 580183.062 | Test loss: 1540493.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 793200 | Training Loss: 580111.750 | Test loss: 1540281.750\nIteration: 793400 | Training Loss: 580040.438 | Test loss: 1540069.250\nIteration: 793600 | Training Loss: 579969.188 | Test loss: 1539862.000\nIteration: 793800 | Training Loss: 579898.000 | Test loss: 1539648.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 794000 | Training Loss: 579826.875 | Test loss: 1539437.625\nIteration: 794200 | Training Loss: 579755.812 | Test loss: 1539224.000\nIteration: 794400 | Training Loss: 579684.750 | Test loss: 1539015.375\nIteration: 794600 | Training Loss: 579613.812 | Test loss: 1538804.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 794800 | Training Loss: 579542.875 | Test loss: 1538596.375\nIteration: 795000 | Training Loss: 579472.062 | Test loss: 1538385.375\nIteration: 795200 | Training Loss: 579401.250 | Test loss: 1538173.125\nIteration: 795400 | Training Loss: 579330.562 | Test loss: 1537961.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 795600 | Training Loss: 579259.875 | Test loss: 1537749.500\nIteration: 795800 | Training Loss: 579189.250 | Test loss: 1537540.250\nIteration: 796000 | Training Loss: 579118.688 | Test loss: 1537331.625\nIteration: 796200 | Training Loss: 579048.188 | Test loss: 1537122.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 796400 | Training Loss: 578977.750 | Test loss: 1536910.375\nIteration: 796600 | Training Loss: 578907.375 | Test loss: 1536704.000\nIteration: 796800 | Training Loss: 578837.062 | Test loss: 1536490.000\nIteration: 797000 | Training Loss: 578766.812 | Test loss: 1536279.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 797200 | Training Loss: 578696.562 | Test loss: 1536076.250\nIteration: 797400 | Training Loss: 578626.438 | Test loss: 1535860.875\nIteration: 797600 | Training Loss: 578556.375 | Test loss: 1535653.125\nIteration: 797800 | Training Loss: 578486.375 | Test loss: 1535446.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 798000 | Training Loss: 578416.375 | Test loss: 1535238.625\nIteration: 798200 | Training Loss: 578346.500 | Test loss: 1535027.000\nIteration: 798400 | Training Loss: 578276.625 | Test loss: 1534817.375\nIteration: 798600 | Training Loss: 578206.750 | Test loss: 1534604.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 798800 | Training Loss: 578137.062 | Test loss: 1534402.250\nIteration: 799000 | Training Loss: 578067.438 | Test loss: 1534192.875\nIteration: 799200 | Training Loss: 577997.938 | Test loss: 1533986.375\nIteration: 799400 | Training Loss: 577928.438 | Test loss: 1533777.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 799600 | Training Loss: 577859.062 | Test loss: 1533573.875\nIteration: 799800 | Training Loss: 577789.625 | Test loss: 1533366.500\nIteration: 800000 | Training Loss: 577720.375 | Test loss: 1533158.000\nIteration: 800200 | Training Loss: 577651.125 | Test loss: 1532951.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 800400 | Training Loss: 577581.938 | Test loss: 1532744.000\nIteration: 800600 | Training Loss: 577512.750 | Test loss: 1532540.375\nIteration: 800800 | Training Loss: 577443.688 | Test loss: 1532332.500\nIteration: 801000 | Training Loss: 577374.688 | Test loss: 1532127.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 801200 | Training Loss: 577305.688 | Test loss: 1531924.250\nIteration: 801400 | Training Loss: 577236.812 | Test loss: 1531713.875\nIteration: 801600 | Training Loss: 577167.875 | Test loss: 1531509.750\nIteration: 801800 | Training Loss: 577099.062 | Test loss: 1531303.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 802000 | Training Loss: 577030.375 | Test loss: 1531098.250\nIteration: 802200 | Training Loss: 576961.688 | Test loss: 1530895.000\nIteration: 802400 | Training Loss: 576893.000 | Test loss: 1530689.500\nIteration: 802600 | Training Loss: 576824.375 | Test loss: 1530480.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 802800 | Training Loss: 576755.875 | Test loss: 1530276.500\nIteration: 803000 | Training Loss: 576687.438 | Test loss: 1530067.125\nIteration: 803200 | Training Loss: 576619.000 | Test loss: 1529870.250\nIteration: 803400 | Training Loss: 576550.625 | Test loss: 1529660.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 803600 | Training Loss: 576482.312 | Test loss: 1529456.125\nIteration: 803800 | Training Loss: 576414.062 | Test loss: 1529248.750\nIteration: 804000 | Training Loss: 576345.875 | Test loss: 1529046.875\nIteration: 804200 | Training Loss: 576277.688 | Test loss: 1528839.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 804400 | Training Loss: 576209.688 | Test loss: 1528639.250\nIteration: 804600 | Training Loss: 576141.625 | Test loss: 1528429.500\nIteration: 804800 | Training Loss: 576073.625 | Test loss: 1528224.750\nIteration: 805000 | Training Loss: 576005.750 | Test loss: 1528018.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 805200 | Training Loss: 575937.875 | Test loss: 1527814.750\nIteration: 805400 | Training Loss: 575870.125 | Test loss: 1527612.375\nIteration: 805600 | Training Loss: 575802.312 | Test loss: 1527406.750\nIteration: 805800 | Training Loss: 575734.625 | Test loss: 1527203.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 806000 | Training Loss: 575667.000 | Test loss: 1527002.250\nIteration: 806200 | Training Loss: 575599.438 | Test loss: 1526791.125\nIteration: 806400 | Training Loss: 575531.938 | Test loss: 1526592.375\nIteration: 806600 | Training Loss: 575464.438 | Test loss: 1526383.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 806800 | Training Loss: 575397.000 | Test loss: 1526184.125\nIteration: 807000 | Training Loss: 575329.625 | Test loss: 1525979.625\nIteration: 807200 | Training Loss: 575262.375 | Test loss: 1525774.875\nIteration: 807400 | Training Loss: 575195.062 | Test loss: 1525572.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 807600 | Training Loss: 575127.938 | Test loss: 1525373.125\nIteration: 807800 | Training Loss: 575060.750 | Test loss: 1525165.625\nIteration: 808000 | Training Loss: 574993.688 | Test loss: 1524965.000\nIteration: 808200 | Training Loss: 574926.625 | Test loss: 1524759.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 808400 | Training Loss: 574859.688 | Test loss: 1524557.625\nIteration: 808600 | Training Loss: 574792.812 | Test loss: 1524351.625\nIteration: 808800 | Training Loss: 574725.938 | Test loss: 1524153.875\nIteration: 809000 | Training Loss: 574659.125 | Test loss: 1523948.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 809200 | Training Loss: 574592.375 | Test loss: 1523746.500\nIteration: 809400 | Training Loss: 574525.750 | Test loss: 1523545.500\nIteration: 809600 | Training Loss: 574459.125 | Test loss: 1523346.250\nIteration: 809800 | Training Loss: 574392.625 | Test loss: 1523150.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 810000 | Training Loss: 574326.125 | Test loss: 1522940.375\nIteration: 810200 | Training Loss: 574259.625 | Test loss: 1522745.625\nIteration: 810400 | Training Loss: 574193.312 | Test loss: 1522542.500\nIteration: 810600 | Training Loss: 574126.938 | Test loss: 1522342.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 810800 | Training Loss: 574060.688 | Test loss: 1522148.375\nIteration: 811000 | Training Loss: 573994.438 | Test loss: 1521941.125\nIteration: 811200 | Training Loss: 573928.312 | Test loss: 1521740.875\nIteration: 811400 | Training Loss: 573862.188 | Test loss: 1521545.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 811600 | Training Loss: 573796.125 | Test loss: 1521340.000\nIteration: 811800 | Training Loss: 573730.125 | Test loss: 1521141.500\nIteration: 812000 | Training Loss: 573664.188 | Test loss: 1520943.625\nIteration: 812200 | Training Loss: 573598.312 | Test loss: 1520741.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 812400 | Training Loss: 573532.438 | Test loss: 1520543.500\nIteration: 812600 | Training Loss: 573466.688 | Test loss: 1520340.500\nIteration: 812800 | Training Loss: 573400.938 | Test loss: 1520144.125\nIteration: 813000 | Training Loss: 573335.312 | Test loss: 1519938.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 813200 | Training Loss: 573269.688 | Test loss: 1519750.750\nIteration: 813400 | Training Loss: 573204.125 | Test loss: 1519548.375\nIteration: 813600 | Training Loss: 573138.625 | Test loss: 1519352.875\nIteration: 813800 | Training Loss: 573073.188 | Test loss: 1519154.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 814000 | Training Loss: 573007.750 | Test loss: 1518958.000\nIteration: 814200 | Training Loss: 572942.438 | Test loss: 1518761.750\nIteration: 814400 | Training Loss: 572877.188 | Test loss: 1518567.875\nIteration: 814600 | Training Loss: 572811.875 | Test loss: 1518374.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 814800 | Training Loss: 572746.750 | Test loss: 1518178.125\nIteration: 815000 | Training Loss: 572681.625 | Test loss: 1517979.875\nIteration: 815200 | Training Loss: 572616.500 | Test loss: 1517786.750\nIteration: 815400 | Training Loss: 572551.500 | Test loss: 1517591.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 815600 | Training Loss: 572486.500 | Test loss: 1517398.375\nIteration: 815800 | Training Loss: 572421.562 | Test loss: 1517207.750\nIteration: 816000 | Training Loss: 572356.688 | Test loss: 1517013.125\nIteration: 816200 | Training Loss: 572291.875 | Test loss: 1516820.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 816400 | Training Loss: 572227.062 | Test loss: 1516630.750\nIteration: 816600 | Training Loss: 572162.375 | Test loss: 1516444.875\nIteration: 816800 | Training Loss: 572097.688 | Test loss: 1516251.000\nIteration: 817000 | Training Loss: 572033.000 | Test loss: 1516064.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 817200 | Training Loss: 571968.438 | Test loss: 1515872.500\nIteration: 817400 | Training Loss: 571903.875 | Test loss: 1515687.125\nIteration: 817600 | Training Loss: 571839.375 | Test loss: 1515506.750\nIteration: 817800 | Training Loss: 571774.938 | Test loss: 1515319.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 818000 | Training Loss: 571710.500 | Test loss: 1515138.500\nIteration: 818200 | Training Loss: 571646.000 | Test loss: 1514960.750\nIteration: 818400 | Training Loss: 571581.750 | Test loss: 1514785.625\nIteration: 818600 | Training Loss: 571517.375 | Test loss: 1514612.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 818800 | Training Loss: 571453.062 | Test loss: 1514443.625\nIteration: 819000 | Training Loss: 571388.750 | Test loss: 1514271.875\nIteration: 819200 | Training Loss: 571324.500 | Test loss: 1514106.750\nIteration: 819400 | Training Loss: 571260.312 | Test loss: 1513943.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 819600 | Training Loss: 571196.000 | Test loss: 1513785.500\nIteration: 819800 | Training Loss: 571131.812 | Test loss: 1513626.375\nIteration: 820000 | Training Loss: 571067.625 | Test loss: 1513470.625\nIteration: 820200 | Training Loss: 571003.438 | Test loss: 1513315.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 820400 | Training Loss: 570939.312 | Test loss: 1513160.250\nIteration: 820600 | Training Loss: 570875.188 | Test loss: 1513006.500\nIteration: 820800 | Training Loss: 570811.000 | Test loss: 1512855.125\nIteration: 821000 | Training Loss: 570746.938 | Test loss: 1512702.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 821200 | Training Loss: 570682.875 | Test loss: 1512551.875\nIteration: 821400 | Training Loss: 570618.812 | Test loss: 1512398.500\nIteration: 821600 | Training Loss: 570554.750 | Test loss: 1512245.375\nIteration: 821800 | Training Loss: 570490.750 | Test loss: 1512094.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 822000 | Training Loss: 570426.750 | Test loss: 1511942.500\nIteration: 822200 | Training Loss: 570362.812 | Test loss: 1511792.000\nIteration: 822400 | Training Loss: 570298.812 | Test loss: 1511638.750\nIteration: 822600 | Training Loss: 570234.875 | Test loss: 1511496.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 822800 | Training Loss: 570171.000 | Test loss: 1511345.125\nIteration: 823000 | Training Loss: 570107.062 | Test loss: 1511189.250\nIteration: 823200 | Training Loss: 570043.250 | Test loss: 1511037.500\nIteration: 823400 | Training Loss: 569979.375 | Test loss: 1510888.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 823600 | Training Loss: 569915.500 | Test loss: 1510742.875\nIteration: 823800 | Training Loss: 569851.750 | Test loss: 1510590.125\nIteration: 824000 | Training Loss: 569787.938 | Test loss: 1510442.375\nIteration: 824200 | Training Loss: 569724.188 | Test loss: 1510292.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 824400 | Training Loss: 569660.438 | Test loss: 1510147.750\nIteration: 824600 | Training Loss: 569596.688 | Test loss: 1509996.750\nIteration: 824800 | Training Loss: 569532.938 | Test loss: 1509848.750\nIteration: 825000 | Training Loss: 569469.312 | Test loss: 1509700.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 825200 | Training Loss: 569405.625 | Test loss: 1509553.125\nIteration: 825400 | Training Loss: 569341.938 | Test loss: 1509412.125\nIteration: 825600 | Training Loss: 569278.375 | Test loss: 1509264.375\nIteration: 825800 | Training Loss: 569214.750 | Test loss: 1509120.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 826000 | Training Loss: 569151.125 | Test loss: 1508973.875\nIteration: 826200 | Training Loss: 569087.562 | Test loss: 1508830.000\nIteration: 826400 | Training Loss: 569024.000 | Test loss: 1508685.750\nIteration: 826600 | Training Loss: 568960.500 | Test loss: 1508546.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 826800 | Training Loss: 568896.938 | Test loss: 1508402.500\nIteration: 827000 | Training Loss: 568833.500 | Test loss: 1508265.750\nIteration: 827200 | Training Loss: 568770.000 | Test loss: 1508125.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 827400 | Training Loss: 568706.562 | Test loss: 1507986.125\nIteration: 827600 | Training Loss: 568643.125 | Test loss: 1507850.625\nIteration: 827800 | Training Loss: 568579.688 | Test loss: 1507715.500\nIteration: 828000 | Training Loss: 568516.312 | Test loss: 1507577.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 828200 | Training Loss: 568452.938 | Test loss: 1507447.375\nIteration: 828400 | Training Loss: 568389.562 | Test loss: 1507315.250\nIteration: 828600 | Training Loss: 568326.188 | Test loss: 1507187.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 828800 | Training Loss: 568262.875 | Test loss: 1507057.500\nIteration: 829000 | Training Loss: 568199.625 | Test loss: 1506930.500\nIteration: 829200 | Training Loss: 568136.250 | Test loss: 1506804.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 829400 | Training Loss: 568073.000 | Test loss: 1506680.125\nIteration: 829600 | Training Loss: 568009.750 | Test loss: 1506560.750\nIteration: 829800 | Training Loss: 567946.625 | Test loss: 1506434.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 830000 | Training Loss: 567883.500 | Test loss: 1506314.625\nIteration: 830200 | Training Loss: 567820.438 | Test loss: 1506186.500\nIteration: 830400 | Training Loss: 567757.375 | Test loss: 1506073.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 830600 | Training Loss: 567694.312 | Test loss: 1505946.625\nIteration: 830800 | Training Loss: 567631.250 | Test loss: 1505830.750\nIteration: 831000 | Training Loss: 567568.250 | Test loss: 1505712.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 831200 | Training Loss: 567505.250 | Test loss: 1505593.625\nIteration: 831400 | Training Loss: 567442.250 | Test loss: 1505475.375\nIteration: 831600 | Training Loss: 567379.312 | Test loss: 1505353.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 831800 | Training Loss: 567316.312 | Test loss: 1505233.750\nIteration: 832000 | Training Loss: 567253.438 | Test loss: 1505115.375\nIteration: 832200 | Training Loss: 567190.562 | Test loss: 1504993.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 832400 | Training Loss: 567127.625 | Test loss: 1504874.750\nIteration: 832600 | Training Loss: 567064.750 | Test loss: 1504753.000\nIteration: 832800 | Training Loss: 567001.875 | Test loss: 1504631.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 833000 | Training Loss: 566939.062 | Test loss: 1504511.375\nIteration: 833200 | Training Loss: 566876.250 | Test loss: 1504392.125\nIteration: 833400 | Training Loss: 566813.438 | Test loss: 1504274.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 833600 | Training Loss: 566750.625 | Test loss: 1504152.250\nIteration: 833800 | Training Loss: 566687.875 | Test loss: 1504032.125\nIteration: 834000 | Training Loss: 566625.125 | Test loss: 1503912.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 834200 | Training Loss: 566562.438 | Test loss: 1503793.125\nIteration: 834400 | Training Loss: 566499.688 | Test loss: 1503671.375\nIteration: 834600 | Training Loss: 566436.938 | Test loss: 1503552.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 834800 | Training Loss: 566374.312 | Test loss: 1503431.125\nIteration: 835000 | Training Loss: 566311.625 | Test loss: 1503312.375\nIteration: 835200 | Training Loss: 566248.938 | Test loss: 1503190.875\nIteration: 835400 | Training Loss: 566186.188 | Test loss: 1503071.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 835600 | Training Loss: 566123.438 | Test loss: 1502952.000\nIteration: 835800 | Training Loss: 566060.750 | Test loss: 1502830.125\nIteration: 836000 | Training Loss: 565998.000 | Test loss: 1502710.250\nIteration: 836200 | Training Loss: 565935.375 | Test loss: 1502589.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 836400 | Training Loss: 565872.688 | Test loss: 1502468.500\nIteration: 836600 | Training Loss: 565810.000 | Test loss: 1502348.500\nIteration: 836800 | Training Loss: 565747.438 | Test loss: 1502228.000\nIteration: 837000 | Training Loss: 565684.812 | Test loss: 1502105.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 837200 | Training Loss: 565622.188 | Test loss: 1501986.500\nIteration: 837400 | Training Loss: 565559.688 | Test loss: 1501869.375\nIteration: 837600 | Training Loss: 565497.062 | Test loss: 1501747.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 837800 | Training Loss: 565434.500 | Test loss: 1501627.000\nIteration: 838000 | Training Loss: 565372.000 | Test loss: 1501506.125\nIteration: 838200 | Training Loss: 565309.500 | Test loss: 1501386.125\nIteration: 838400 | Training Loss: 565247.000 | Test loss: 1501265.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 838600 | Training Loss: 565184.562 | Test loss: 1501145.875\nIteration: 838800 | Training Loss: 565122.125 | Test loss: 1501024.500\nIteration: 839000 | Training Loss: 565059.688 | Test loss: 1500904.875\nIteration: 839200 | Training Loss: 564997.250 | Test loss: 1500785.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 839400 | Training Loss: 564934.875 | Test loss: 1500664.250\nIteration: 839600 | Training Loss: 564872.500 | Test loss: 1500544.625\nIteration: 839800 | Training Loss: 564810.125 | Test loss: 1500424.875\nIteration: 840000 | Training Loss: 564747.812 | Test loss: 1500301.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 840200 | Training Loss: 564685.438 | Test loss: 1500186.500\nIteration: 840400 | Training Loss: 564623.125 | Test loss: 1500062.750\nIteration: 840600 | Training Loss: 564560.812 | Test loss: 1499952.750\nIteration: 840800 | Training Loss: 564498.562 | Test loss: 1499824.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 841000 | Training Loss: 564436.312 | Test loss: 1499703.250\nIteration: 841200 | Training Loss: 564374.125 | Test loss: 1499584.250\nIteration: 841400 | Training Loss: 564311.812 | Test loss: 1499465.000\nIteration: 841600 | Training Loss: 564249.625 | Test loss: 1499343.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 841800 | Training Loss: 564187.438 | Test loss: 1499224.625\nIteration: 842000 | Training Loss: 564125.250 | Test loss: 1499102.875\nIteration: 842200 | Training Loss: 564063.125 | Test loss: 1498986.750\nIteration: 842400 | Training Loss: 564001.000 | Test loss: 1498864.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 842600 | Training Loss: 563938.875 | Test loss: 1498745.625\nIteration: 842800 | Training Loss: 563876.812 | Test loss: 1498627.000\nIteration: 843000 | Training Loss: 563814.688 | Test loss: 1498505.125\nIteration: 843200 | Training Loss: 563752.625 | Test loss: 1498385.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 843400 | Training Loss: 563690.625 | Test loss: 1498264.750\nIteration: 843600 | Training Loss: 563628.562 | Test loss: 1498147.625\nIteration: 843800 | Training Loss: 563566.562 | Test loss: 1498024.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 844000 | Training Loss: 563504.562 | Test loss: 1497905.500\nIteration: 844200 | Training Loss: 563442.562 | Test loss: 1497788.125\nIteration: 844400 | Training Loss: 563380.625 | Test loss: 1497667.750\nIteration: 844600 | Training Loss: 563318.688 | Test loss: 1497551.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 844800 | Training Loss: 563256.688 | Test loss: 1497426.750\nIteration: 845000 | Training Loss: 563194.812 | Test loss: 1497309.750\nIteration: 845200 | Training Loss: 563132.938 | Test loss: 1497189.250\nIteration: 845400 | Training Loss: 563071.062 | Test loss: 1497070.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 845600 | Training Loss: 563009.188 | Test loss: 1496954.125\nIteration: 845800 | Training Loss: 562947.375 | Test loss: 1496831.375\nIteration: 846000 | Training Loss: 562885.562 | Test loss: 1496718.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 846200 | Training Loss: 562823.750 | Test loss: 1496592.500\nIteration: 846400 | Training Loss: 562762.000 | Test loss: 1496474.375\nIteration: 846600 | Training Loss: 562700.188 | Test loss: 1496352.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 846800 | Training Loss: 562638.438 | Test loss: 1496234.125\nIteration: 847000 | Training Loss: 562576.750 | Test loss: 1496116.000\nIteration: 847200 | Training Loss: 562515.000 | Test loss: 1495999.375\nIteration: 847400 | Training Loss: 562453.312 | Test loss: 1495869.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 847600 | Training Loss: 562391.625 | Test loss: 1495757.625\nIteration: 847800 | Training Loss: 562330.000 | Test loss: 1495638.625\nIteration: 848000 | Training Loss: 562268.312 | Test loss: 1495518.750\nIteration: 848200 | Training Loss: 562206.688 | Test loss: 1495403.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 848400 | Training Loss: 562145.062 | Test loss: 1495281.375\nIteration: 848600 | Training Loss: 562083.500 | Test loss: 1495161.625\nIteration: 848800 | Training Loss: 562021.938 | Test loss: 1495041.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 849000 | Training Loss: 561960.375 | Test loss: 1494923.250\nIteration: 849200 | Training Loss: 561898.875 | Test loss: 1494804.625\nIteration: 849400 | Training Loss: 561837.312 | Test loss: 1494684.000\nIteration: 849600 | Training Loss: 561775.812 | Test loss: 1494567.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 849800 | Training Loss: 561714.375 | Test loss: 1494446.625\nIteration: 850000 | Training Loss: 561652.875 | Test loss: 1494332.500\nIteration: 850200 | Training Loss: 561591.438 | Test loss: 1494209.125\nIteration: 850400 | Training Loss: 561529.938 | Test loss: 1494090.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 850600 | Training Loss: 561468.562 | Test loss: 1493970.875\nIteration: 850800 | Training Loss: 561407.188 | Test loss: 1493851.250\nIteration: 851000 | Training Loss: 561345.750 | Test loss: 1493732.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 851200 | Training Loss: 561284.438 | Test loss: 1493611.125\nIteration: 851400 | Training Loss: 561223.062 | Test loss: 1493495.500\nIteration: 851600 | Training Loss: 561161.750 | Test loss: 1493375.375\nIteration: 851800 | Training Loss: 561100.438 | Test loss: 1493258.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 852000 | Training Loss: 561039.188 | Test loss: 1493138.750\nIteration: 852200 | Training Loss: 560977.875 | Test loss: 1493017.000\nIteration: 852400 | Training Loss: 560916.688 | Test loss: 1492900.500\nIteration: 852600 | Training Loss: 560855.375 | Test loss: 1492783.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 852800 | Training Loss: 560794.188 | Test loss: 1492665.125\nIteration: 853000 | Training Loss: 560732.938 | Test loss: 1492544.750\nIteration: 853200 | Training Loss: 560671.812 | Test loss: 1492421.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 853400 | Training Loss: 560610.625 | Test loss: 1492306.875\nIteration: 853600 | Training Loss: 560549.438 | Test loss: 1492190.000\nIteration: 853800 | Training Loss: 560488.312 | Test loss: 1492069.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 854000 | Training Loss: 560427.188 | Test loss: 1491951.125\nIteration: 854200 | Training Loss: 560366.125 | Test loss: 1491832.500\nIteration: 854400 | Training Loss: 560305.062 | Test loss: 1491715.375\nIteration: 854600 | Training Loss: 560244.000 | Test loss: 1491598.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 854800 | Training Loss: 560182.938 | Test loss: 1491476.250\nIteration: 855000 | Training Loss: 560121.938 | Test loss: 1491357.000\nIteration: 855200 | Training Loss: 560060.875 | Test loss: 1491239.250\nIteration: 855400 | Training Loss: 559999.875 | Test loss: 1491124.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 855600 | Training Loss: 559938.938 | Test loss: 1491000.750\nIteration: 855800 | Training Loss: 559878.000 | Test loss: 1490883.875\nIteration: 856000 | Training Loss: 559817.062 | Test loss: 1490767.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 856200 | Training Loss: 559756.125 | Test loss: 1490647.500\nIteration: 856400 | Training Loss: 559695.250 | Test loss: 1490529.125\nIteration: 856600 | Training Loss: 559634.375 | Test loss: 1490411.500\nIteration: 856800 | Training Loss: 559573.500 | Test loss: 1490285.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 857000 | Training Loss: 559512.688 | Test loss: 1490174.125\nIteration: 857200 | Training Loss: 559451.812 | Test loss: 1490055.750\nIteration: 857400 | Training Loss: 559391.000 | Test loss: 1489936.250\nIteration: 857600 | Training Loss: 559330.188 | Test loss: 1489818.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 857800 | Training Loss: 559269.375 | Test loss: 1489700.500\nIteration: 858000 | Training Loss: 559208.688 | Test loss: 1489582.000\nIteration: 858200 | Training Loss: 559147.938 | Test loss: 1489463.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 858400 | Training Loss: 559087.188 | Test loss: 1489343.000\nIteration: 858600 | Training Loss: 559026.500 | Test loss: 1489227.375\nIteration: 858800 | Training Loss: 558965.812 | Test loss: 1489108.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 859000 | Training Loss: 558905.125 | Test loss: 1488995.000\nIteration: 859200 | Training Loss: 558844.500 | Test loss: 1488872.000\nIteration: 859400 | Training Loss: 558783.812 | Test loss: 1488754.625\nIteration: 859600 | Training Loss: 558723.250 | Test loss: 1488637.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 859800 | Training Loss: 558662.625 | Test loss: 1488518.500\nIteration: 860000 | Training Loss: 558602.000 | Test loss: 1488401.375\nIteration: 860200 | Training Loss: 558541.438 | Test loss: 1488282.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 860400 | Training Loss: 558480.938 | Test loss: 1488165.000\nIteration: 860600 | Training Loss: 558420.375 | Test loss: 1488044.750\nIteration: 860800 | Training Loss: 558359.875 | Test loss: 1487927.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 861000 | Training Loss: 558299.375 | Test loss: 1487809.875\nIteration: 861200 | Training Loss: 558238.875 | Test loss: 1487692.375\nIteration: 861400 | Training Loss: 558178.438 | Test loss: 1487568.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 861600 | Training Loss: 558118.000 | Test loss: 1487456.000\nIteration: 861800 | Training Loss: 558057.562 | Test loss: 1487338.125\nIteration: 862000 | Training Loss: 557997.125 | Test loss: 1487224.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 862200 | Training Loss: 557936.750 | Test loss: 1487106.500\nIteration: 862400 | Training Loss: 557876.375 | Test loss: 1486984.625\nIteration: 862600 | Training Loss: 557816.000 | Test loss: 1486864.750\nIteration: 862800 | Training Loss: 557755.688 | Test loss: 1486752.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 863000 | Training Loss: 557695.312 | Test loss: 1486636.500\nIteration: 863200 | Training Loss: 557635.000 | Test loss: 1486512.500\nIteration: 863400 | Training Loss: 557574.750 | Test loss: 1486395.625\nIteration: 863600 | Training Loss: 557514.438 | Test loss: 1486278.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 863800 | Training Loss: 557454.250 | Test loss: 1486163.875\nIteration: 864000 | Training Loss: 557394.000 | Test loss: 1486042.625\nIteration: 864200 | Training Loss: 557333.812 | Test loss: 1485923.625\nIteration: 864400 | Training Loss: 557273.562 | Test loss: 1485808.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 864600 | Training Loss: 557213.375 | Test loss: 1485688.250\nIteration: 864800 | Training Loss: 557153.188 | Test loss: 1485570.000\nIteration: 865000 | Training Loss: 557093.062 | Test loss: 1485455.375\nIteration: 865200 | Training Loss: 557032.938 | Test loss: 1485335.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 865400 | Training Loss: 556972.812 | Test loss: 1485215.375\nIteration: 865600 | Training Loss: 556912.750 | Test loss: 1485096.750\nIteration: 865800 | Training Loss: 556852.688 | Test loss: 1484983.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 866000 | Training Loss: 556792.562 | Test loss: 1484864.375\nIteration: 866200 | Training Loss: 556732.562 | Test loss: 1484748.000\nIteration: 866400 | Training Loss: 556672.562 | Test loss: 1484630.750\nIteration: 866600 | Training Loss: 556612.500 | Test loss: 1484512.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 866800 | Training Loss: 556552.500 | Test loss: 1484395.000\nIteration: 867000 | Training Loss: 556492.562 | Test loss: 1484276.125\nIteration: 867200 | Training Loss: 556432.625 | Test loss: 1484159.375\nIteration: 867400 | Training Loss: 556372.688 | Test loss: 1484042.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 867600 | Training Loss: 556312.750 | Test loss: 1483923.875\nIteration: 867800 | Training Loss: 556252.812 | Test loss: 1483807.375\nIteration: 868000 | Training Loss: 556192.875 | Test loss: 1483694.125\nIteration: 868200 | Training Loss: 556132.938 | Test loss: 1483572.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 868400 | Training Loss: 556073.062 | Test loss: 1483452.875\nIteration: 868600 | Training Loss: 556013.250 | Test loss: 1483339.750\nIteration: 868800 | Training Loss: 555953.375 | Test loss: 1483213.250\nIteration: 869000 | Training Loss: 555893.500 | Test loss: 1483105.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 869200 | Training Loss: 555833.750 | Test loss: 1482986.500\nIteration: 869400 | Training Loss: 555773.875 | Test loss: 1482870.000\nIteration: 869600 | Training Loss: 555714.062 | Test loss: 1482750.250\nIteration: 869800 | Training Loss: 555654.312 | Test loss: 1482633.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 870000 | Training Loss: 555594.562 | Test loss: 1482516.875\nIteration: 870200 | Training Loss: 555534.812 | Test loss: 1482398.000\nIteration: 870400 | Training Loss: 555475.125 | Test loss: 1482279.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 870600 | Training Loss: 555415.438 | Test loss: 1482163.750\nIteration: 870800 | Training Loss: 555355.750 | Test loss: 1482048.250\nIteration: 871000 | Training Loss: 555296.062 | Test loss: 1481929.750\nIteration: 871200 | Training Loss: 555236.438 | Test loss: 1481813.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 871400 | Training Loss: 555176.812 | Test loss: 1481693.125\nIteration: 871600 | Training Loss: 555117.188 | Test loss: 1481583.125\nIteration: 871800 | Training Loss: 555057.562 | Test loss: 1481460.625\nIteration: 872000 | Training Loss: 554998.000 | Test loss: 1481342.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 872200 | Training Loss: 554938.438 | Test loss: 1481226.375\nIteration: 872400 | Training Loss: 554878.938 | Test loss: 1481108.500\nIteration: 872600 | Training Loss: 554819.375 | Test loss: 1480992.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 872800 | Training Loss: 554759.875 | Test loss: 1480873.375\nIteration: 873000 | Training Loss: 554700.375 | Test loss: 1480757.875\nIteration: 873200 | Training Loss: 554640.875 | Test loss: 1480639.375\nIteration: 873400 | Training Loss: 554581.438 | Test loss: 1480518.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 873600 | Training Loss: 554522.000 | Test loss: 1480405.125\nIteration: 873800 | Training Loss: 554462.625 | Test loss: 1480289.000\nIteration: 874000 | Training Loss: 554403.188 | Test loss: 1480172.750\nIteration: 874200 | Training Loss: 554343.750 | Test loss: 1480054.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 874400 | Training Loss: 554284.438 | Test loss: 1479937.375\nIteration: 874600 | Training Loss: 554225.125 | Test loss: 1479821.500\nIteration: 874800 | Training Loss: 554165.750 | Test loss: 1479703.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 875000 | Training Loss: 554106.438 | Test loss: 1479586.375\nIteration: 875200 | Training Loss: 554047.188 | Test loss: 1479469.250\nIteration: 875400 | Training Loss: 553987.875 | Test loss: 1479354.875\nIteration: 875600 | Training Loss: 553928.625 | Test loss: 1479237.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 875800 | Training Loss: 553869.375 | Test loss: 1479122.500\nIteration: 876000 | Training Loss: 553810.188 | Test loss: 1479003.375\nIteration: 876200 | Training Loss: 553750.938 | Test loss: 1478884.500\nIteration: 876400 | Training Loss: 553691.750 | Test loss: 1478769.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 876600 | Training Loss: 553632.562 | Test loss: 1478651.500\nIteration: 876800 | Training Loss: 553573.438 | Test loss: 1478538.125\nIteration: 877000 | Training Loss: 553514.250 | Test loss: 1478417.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 877200 | Training Loss: 553455.188 | Test loss: 1478304.750\nIteration: 877400 | Training Loss: 553396.062 | Test loss: 1478184.000\nIteration: 877600 | Training Loss: 553337.000 | Test loss: 1478068.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 877800 | Training Loss: 553277.938 | Test loss: 1477951.625\nIteration: 878000 | Training Loss: 553218.875 | Test loss: 1477833.625\nIteration: 878200 | Training Loss: 553159.812 | Test loss: 1477715.875\nIteration: 878400 | Training Loss: 553100.875 | Test loss: 1477600.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 878600 | Training Loss: 553041.875 | Test loss: 1477482.125\nIteration: 878800 | Training Loss: 552982.812 | Test loss: 1477367.250\nIteration: 879000 | Training Loss: 552923.938 | Test loss: 1477251.625\nIteration: 879200 | Training Loss: 552864.938 | Test loss: 1477135.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 879400 | Training Loss: 552806.000 | Test loss: 1477018.500\nIteration: 879600 | Training Loss: 552747.125 | Test loss: 1476905.250\nIteration: 879800 | Training Loss: 552688.188 | Test loss: 1476785.750\nIteration: 880000 | Training Loss: 552629.375 | Test loss: 1476670.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 880200 | Training Loss: 552570.562 | Test loss: 1476552.000\nIteration: 880400 | Training Loss: 552511.688 | Test loss: 1476436.500\nIteration: 880600 | Training Loss: 552452.875 | Test loss: 1476318.500\nIteration: 880800 | Training Loss: 552394.000 | Test loss: 1476202.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 881000 | Training Loss: 552335.250 | Test loss: 1476086.125\nIteration: 881200 | Training Loss: 552276.500 | Test loss: 1475969.375\nIteration: 881400 | Training Loss: 552217.750 | Test loss: 1475854.375\nIteration: 881600 | Training Loss: 552159.000 | Test loss: 1475738.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 881800 | Training Loss: 552100.312 | Test loss: 1475620.250\nIteration: 882000 | Training Loss: 552041.625 | Test loss: 1475504.625\nIteration: 882200 | Training Loss: 551982.938 | Test loss: 1475388.250\nIteration: 882400 | Training Loss: 551924.250 | Test loss: 1475273.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 882600 | Training Loss: 551865.625 | Test loss: 1475156.875\nIteration: 882800 | Training Loss: 551807.000 | Test loss: 1475036.750\nIteration: 883000 | Training Loss: 551748.375 | Test loss: 1474917.625\nIteration: 883200 | Training Loss: 551689.750 | Test loss: 1474808.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 883400 | Training Loss: 551631.188 | Test loss: 1474693.875\nIteration: 883600 | Training Loss: 551572.625 | Test loss: 1474576.375\nIteration: 883800 | Training Loss: 551514.125 | Test loss: 1474460.125\nIteration: 884000 | Training Loss: 551455.562 | Test loss: 1474345.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 884200 | Training Loss: 551397.125 | Test loss: 1474227.625\nIteration: 884400 | Training Loss: 551338.625 | Test loss: 1474111.500\nIteration: 884600 | Training Loss: 551280.188 | Test loss: 1473990.875\nIteration: 884800 | Training Loss: 551221.688 | Test loss: 1473880.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 885000 | Training Loss: 551163.250 | Test loss: 1473758.875\nIteration: 885200 | Training Loss: 551104.875 | Test loss: 1473648.125\nIteration: 885400 | Training Loss: 551046.438 | Test loss: 1473531.500\nIteration: 885600 | Training Loss: 550988.062 | Test loss: 1473419.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 885800 | Training Loss: 550929.750 | Test loss: 1473301.125\nIteration: 886000 | Training Loss: 550871.375 | Test loss: 1473185.500\nIteration: 886200 | Training Loss: 550813.000 | Test loss: 1473067.250\nIteration: 886400 | Training Loss: 550754.750 | Test loss: 1472947.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 886600 | Training Loss: 550696.438 | Test loss: 1472837.125\nIteration: 886800 | Training Loss: 550638.188 | Test loss: 1472722.375\nIteration: 887000 | Training Loss: 550579.875 | Test loss: 1472608.750\nIteration: 887200 | Training Loss: 550521.625 | Test loss: 1472491.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 887400 | Training Loss: 550463.375 | Test loss: 1472380.000\nIteration: 887600 | Training Loss: 550405.125 | Test loss: 1472260.625\nIteration: 887800 | Training Loss: 550347.000 | Test loss: 1472142.750\nIteration: 888000 | Training Loss: 550288.812 | Test loss: 1472027.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 888200 | Training Loss: 550230.688 | Test loss: 1471912.125\nIteration: 888400 | Training Loss: 550172.500 | Test loss: 1471796.000\nIteration: 888600 | Training Loss: 550114.438 | Test loss: 1471681.500\nIteration: 888800 | Training Loss: 550056.312 | Test loss: 1471566.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 889000 | Training Loss: 549998.250 | Test loss: 1471450.250\nIteration: 889200 | Training Loss: 549940.188 | Test loss: 1471337.500\nIteration: 889400 | Training Loss: 549882.125 | Test loss: 1471220.125\nIteration: 889600 | Training Loss: 549824.062 | Test loss: 1471097.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 889800 | Training Loss: 549766.062 | Test loss: 1470987.000\nIteration: 890000 | Training Loss: 549708.062 | Test loss: 1470872.750\nIteration: 890200 | Training Loss: 549650.062 | Test loss: 1470758.875\nIteration: 890400 | Training Loss: 549592.062 | Test loss: 1470643.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 890600 | Training Loss: 549534.188 | Test loss: 1470527.375\nIteration: 890800 | Training Loss: 549476.250 | Test loss: 1470414.750\nIteration: 891000 | Training Loss: 549418.312 | Test loss: 1470294.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 891200 | Training Loss: 549360.375 | Test loss: 1470181.000\nIteration: 891400 | Training Loss: 549302.500 | Test loss: 1470065.000\nIteration: 891600 | Training Loss: 549244.688 | Test loss: 1469950.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 891800 | Training Loss: 549186.875 | Test loss: 1469831.375\nIteration: 892000 | Training Loss: 549129.000 | Test loss: 1469725.375\nIteration: 892200 | Training Loss: 549071.188 | Test loss: 1469605.500\nIteration: 892400 | Training Loss: 549013.438 | Test loss: 1469491.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 892600 | Training Loss: 548955.688 | Test loss: 1469375.250\nIteration: 892800 | Training Loss: 548897.875 | Test loss: 1469260.500\nIteration: 893000 | Training Loss: 548840.125 | Test loss: 1469147.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 893200 | Training Loss: 548782.438 | Test loss: 1469027.625\nIteration: 893400 | Training Loss: 548724.750 | Test loss: 1468915.875\nIteration: 893600 | Training Loss: 548667.062 | Test loss: 1468801.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 893800 | Training Loss: 548609.438 | Test loss: 1468690.250\nIteration: 894000 | Training Loss: 548551.750 | Test loss: 1468569.750\nIteration: 894200 | Training Loss: 548494.125 | Test loss: 1468454.875\nIteration: 894400 | Training Loss: 548436.500 | Test loss: 1468342.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 894600 | Training Loss: 548378.875 | Test loss: 1468226.500\nIteration: 894800 | Training Loss: 548321.375 | Test loss: 1468109.750\nIteration: 895000 | Training Loss: 548263.750 | Test loss: 1467996.125\nIteration: 895200 | Training Loss: 548206.250 | Test loss: 1467881.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 895400 | Training Loss: 548148.688 | Test loss: 1467766.000\nIteration: 895600 | Training Loss: 548091.250 | Test loss: 1467652.750\nIteration: 895800 | Training Loss: 548033.688 | Test loss: 1467533.875\nIteration: 896000 | Training Loss: 547976.250 | Test loss: 1467425.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 896200 | Training Loss: 547918.750 | Test loss: 1467306.500\nIteration: 896400 | Training Loss: 547861.375 | Test loss: 1467193.125\nIteration: 896600 | Training Loss: 547803.938 | Test loss: 1467077.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 896800 | Training Loss: 547746.562 | Test loss: 1466957.750\nIteration: 897000 | Training Loss: 547689.125 | Test loss: 1466847.500\nIteration: 897200 | Training Loss: 547631.750 | Test loss: 1466733.750\nIteration: 897400 | Training Loss: 547574.438 | Test loss: 1466622.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 897600 | Training Loss: 547517.125 | Test loss: 1466505.500\nIteration: 897800 | Training Loss: 547459.812 | Test loss: 1466391.875\nIteration: 898000 | Training Loss: 547402.500 | Test loss: 1466277.500\nIteration: 898200 | Training Loss: 547345.250 | Test loss: 1466161.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 898400 | Training Loss: 547287.938 | Test loss: 1466049.125\nIteration: 898600 | Training Loss: 547230.688 | Test loss: 1465935.125\nIteration: 898800 | Training Loss: 547173.500 | Test loss: 1465817.125\nIteration: 899000 | Training Loss: 547116.250 | Test loss: 1465706.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 899200 | Training Loss: 547059.062 | Test loss: 1465596.250\nIteration: 899400 | Training Loss: 547001.875 | Test loss: 1465473.375\nIteration: 899600 | Training Loss: 546944.750 | Test loss: 1465362.500\nIteration: 899800 | Training Loss: 546887.625 | Test loss: 1465247.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 900000 | Training Loss: 546830.500 | Test loss: 1465132.000\nIteration: 900200 | Training Loss: 546773.375 | Test loss: 1465019.750\nIteration: 900400 | Training Loss: 546716.312 | Test loss: 1464903.125\nIteration: 900600 | Training Loss: 546659.250 | Test loss: 1464788.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 900800 | Training Loss: 546602.188 | Test loss: 1464675.375\nIteration: 901000 | Training Loss: 546545.125 | Test loss: 1464564.875\nIteration: 901200 | Training Loss: 546488.188 | Test loss: 1464446.875\nIteration: 901400 | Training Loss: 546431.188 | Test loss: 1464333.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 901600 | Training Loss: 546374.188 | Test loss: 1464219.125\nIteration: 901800 | Training Loss: 546317.250 | Test loss: 1464105.250\nIteration: 902000 | Training Loss: 546260.250 | Test loss: 1463992.625\nIteration: 902200 | Training Loss: 546203.312 | Test loss: 1463872.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 902400 | Training Loss: 546146.438 | Test loss: 1463764.875\nIteration: 902600 | Training Loss: 546089.562 | Test loss: 1463651.875\nIteration: 902800 | Training Loss: 546032.625 | Test loss: 1463532.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 903000 | Training Loss: 545975.812 | Test loss: 1463421.250\nIteration: 903200 | Training Loss: 545918.938 | Test loss: 1463307.375\nIteration: 903400 | Training Loss: 545862.125 | Test loss: 1463193.375\nIteration: 903600 | Training Loss: 545805.312 | Test loss: 1463079.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 903800 | Training Loss: 545748.562 | Test loss: 1462964.125\nIteration: 904000 | Training Loss: 545691.750 | Test loss: 1462852.000\nIteration: 904200 | Training Loss: 545635.000 | Test loss: 1462739.125\nIteration: 904400 | Training Loss: 545578.250 | Test loss: 1462624.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 904600 | Training Loss: 545521.562 | Test loss: 1462507.875\nIteration: 904800 | Training Loss: 545464.875 | Test loss: 1462396.125\nIteration: 905000 | Training Loss: 545408.188 | Test loss: 1462281.000\nIteration: 905200 | Training Loss: 545351.500 | Test loss: 1462171.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 905400 | Training Loss: 545294.875 | Test loss: 1462056.625\nIteration: 905600 | Training Loss: 545238.250 | Test loss: 1461938.375\nIteration: 905800 | Training Loss: 545181.625 | Test loss: 1461820.875\nIteration: 906000 | Training Loss: 545125.000 | Test loss: 1461712.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 906200 | Training Loss: 545068.438 | Test loss: 1461601.625\nIteration: 906400 | Training Loss: 545011.875 | Test loss: 1461486.000\nIteration: 906600 | Training Loss: 544955.375 | Test loss: 1461376.750\nIteration: 906800 | Training Loss: 544898.875 | Test loss: 1461258.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 907000 | Training Loss: 544842.375 | Test loss: 1461146.750\nIteration: 907200 | Training Loss: 544785.875 | Test loss: 1461031.125\nIteration: 907400 | Training Loss: 544729.375 | Test loss: 1460918.000\nIteration: 907600 | Training Loss: 544672.938 | Test loss: 1460803.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 907800 | Training Loss: 544616.500 | Test loss: 1460695.750\nIteration: 908000 | Training Loss: 544560.062 | Test loss: 1460575.750\nIteration: 908200 | Training Loss: 544503.625 | Test loss: 1460463.500\nIteration: 908400 | Training Loss: 544447.250 | Test loss: 1460352.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 908600 | Training Loss: 544390.938 | Test loss: 1460236.625\nIteration: 908800 | Training Loss: 544334.625 | Test loss: 1460123.875\nIteration: 909000 | Training Loss: 544278.250 | Test loss: 1460010.000\nIteration: 909200 | Training Loss: 544221.938 | Test loss: 1459894.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 909400 | Training Loss: 544165.625 | Test loss: 1459781.000\nIteration: 909600 | Training Loss: 544109.312 | Test loss: 1459669.875\nIteration: 909800 | Training Loss: 544053.062 | Test loss: 1459554.125\nIteration: 910000 | Training Loss: 543996.812 | Test loss: 1459442.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 910200 | Training Loss: 543940.688 | Test loss: 1459325.500\nIteration: 910400 | Training Loss: 543884.438 | Test loss: 1459212.375\nIteration: 910600 | Training Loss: 543828.250 | Test loss: 1459102.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 910800 | Training Loss: 543772.062 | Test loss: 1458988.000\nIteration: 911000 | Training Loss: 543715.875 | Test loss: 1458873.125\nIteration: 911200 | Training Loss: 543659.750 | Test loss: 1458761.750\nIteration: 911400 | Training Loss: 543603.625 | Test loss: 1458649.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 911600 | Training Loss: 543547.562 | Test loss: 1458535.625\nIteration: 911800 | Training Loss: 543491.438 | Test loss: 1458419.625\nIteration: 912000 | Training Loss: 543435.375 | Test loss: 1458311.750\nIteration: 912200 | Training Loss: 543379.375 | Test loss: 1458194.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 912400 | Training Loss: 543323.312 | Test loss: 1458078.250\nIteration: 912600 | Training Loss: 543267.312 | Test loss: 1457969.750\nIteration: 912800 | Training Loss: 543211.375 | Test loss: 1457859.250\nIteration: 913000 | Training Loss: 543155.375 | Test loss: 1457742.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 913200 | Training Loss: 543099.375 | Test loss: 1457629.875\nIteration: 913400 | Training Loss: 543043.438 | Test loss: 1457515.625\nIteration: 913600 | Training Loss: 542987.438 | Test loss: 1457404.500\nIteration: 913800 | Training Loss: 542931.562 | Test loss: 1457293.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 914000 | Training Loss: 542875.688 | Test loss: 1457179.250\nIteration: 914200 | Training Loss: 542819.812 | Test loss: 1457064.750\nIteration: 914400 | Training Loss: 542764.000 | Test loss: 1456947.250\nIteration: 914600 | Training Loss: 542708.125 | Test loss: 1456835.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 914800 | Training Loss: 542652.312 | Test loss: 1456730.625\nIteration: 915000 | Training Loss: 542596.500 | Test loss: 1456613.000\nIteration: 915200 | Training Loss: 542540.688 | Test loss: 1456500.250\nIteration: 915400 | Training Loss: 542484.938 | Test loss: 1456387.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 915600 | Training Loss: 542429.188 | Test loss: 1456276.125\nIteration: 915800 | Training Loss: 542373.438 | Test loss: 1456164.000\nIteration: 916000 | Training Loss: 542317.750 | Test loss: 1456051.000\nIteration: 916200 | Training Loss: 542262.062 | Test loss: 1455943.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 916400 | Training Loss: 542206.375 | Test loss: 1455823.125\nIteration: 916600 | Training Loss: 542150.688 | Test loss: 1455713.375\nIteration: 916800 | Training Loss: 542095.062 | Test loss: 1455596.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 917000 | Training Loss: 542039.438 | Test loss: 1455483.500\nIteration: 917200 | Training Loss: 541983.812 | Test loss: 1455372.875\nIteration: 917400 | Training Loss: 541928.188 | Test loss: 1455260.250\nIteration: 917600 | Training Loss: 541872.625 | Test loss: 1455144.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 917800 | Training Loss: 541817.125 | Test loss: 1455035.000\nIteration: 918000 | Training Loss: 541761.625 | Test loss: 1454920.750\nIteration: 918200 | Training Loss: 541706.000 | Test loss: 1454804.375\nIteration: 918400 | Training Loss: 541650.562 | Test loss: 1454694.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 918600 | Training Loss: 541595.062 | Test loss: 1454583.250\nIteration: 918800 | Training Loss: 541539.562 | Test loss: 1454472.375\nIteration: 919000 | Training Loss: 541484.188 | Test loss: 1454357.375\nIteration: 919200 | Training Loss: 541428.750 | Test loss: 1454244.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 919400 | Training Loss: 541373.250 | Test loss: 1454134.750\nIteration: 919600 | Training Loss: 541317.875 | Test loss: 1454018.875\nIteration: 919800 | Training Loss: 541262.500 | Test loss: 1453912.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 920000 | Training Loss: 541207.188 | Test loss: 1453791.625\nIteration: 920200 | Training Loss: 541151.812 | Test loss: 1453680.625\nIteration: 920400 | Training Loss: 541096.438 | Test loss: 1453568.875\nIteration: 920600 | Training Loss: 541041.125 | Test loss: 1453458.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 920800 | Training Loss: 540985.875 | Test loss: 1453343.750\nIteration: 921000 | Training Loss: 540930.625 | Test loss: 1453229.625\nIteration: 921200 | Training Loss: 540875.312 | Test loss: 1453118.500\nIteration: 921400 | Training Loss: 540820.062 | Test loss: 1453005.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 921600 | Training Loss: 540764.875 | Test loss: 1452893.000\nIteration: 921800 | Training Loss: 540709.688 | Test loss: 1452782.125\nIteration: 922000 | Training Loss: 540654.500 | Test loss: 1452668.875\nIteration: 922200 | Training Loss: 540599.312 | Test loss: 1452561.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 922400 | Training Loss: 540544.125 | Test loss: 1452443.625\nIteration: 922600 | Training Loss: 540489.062 | Test loss: 1452331.000\nIteration: 922800 | Training Loss: 540433.938 | Test loss: 1452219.000\nIteration: 923000 | Training Loss: 540378.750 | Test loss: 1452106.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 923200 | Training Loss: 540323.688 | Test loss: 1451996.250\nIteration: 923400 | Training Loss: 540268.688 | Test loss: 1451886.125\nIteration: 923600 | Training Loss: 540213.625 | Test loss: 1451775.500\nIteration: 923800 | Training Loss: 540158.562 | Test loss: 1451659.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 924000 | Training Loss: 540103.625 | Test loss: 1451549.375\nIteration: 924200 | Training Loss: 540048.562 | Test loss: 1451433.375\nIteration: 924400 | Training Loss: 539993.625 | Test loss: 1451326.875\nIteration: 924600 | Training Loss: 539938.625 | Test loss: 1451211.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 924800 | Training Loss: 539883.688 | Test loss: 1451098.250\nIteration: 925000 | Training Loss: 539828.812 | Test loss: 1450983.750\nIteration: 925200 | Training Loss: 539773.875 | Test loss: 1450875.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 925400 | Training Loss: 539719.000 | Test loss: 1450762.375\nIteration: 925600 | Training Loss: 539664.062 | Test loss: 1450650.375\nIteration: 925800 | Training Loss: 539609.250 | Test loss: 1450538.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 926000 | Training Loss: 539554.375 | Test loss: 1450429.250\nIteration: 926200 | Training Loss: 539499.625 | Test loss: 1450315.250\nIteration: 926400 | Training Loss: 539444.812 | Test loss: 1450203.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 926600 | Training Loss: 539390.000 | Test loss: 1450084.625\nIteration: 926800 | Training Loss: 539335.250 | Test loss: 1449976.875\nIteration: 927000 | Training Loss: 539280.500 | Test loss: 1449863.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 927200 | Training Loss: 539225.750 | Test loss: 1449753.750\nIteration: 927400 | Training Loss: 539171.062 | Test loss: 1449642.250\nIteration: 927600 | Training Loss: 539116.375 | Test loss: 1449529.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 927800 | Training Loss: 539061.688 | Test loss: 1449414.625\nIteration: 928000 | Training Loss: 539007.062 | Test loss: 1449305.625\nIteration: 928200 | Training Loss: 538952.375 | Test loss: 1449190.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 928400 | Training Loss: 538897.750 | Test loss: 1449081.750\nIteration: 928600 | Training Loss: 538843.125 | Test loss: 1448966.125\nIteration: 928800 | Training Loss: 538788.562 | Test loss: 1448859.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 929000 | Training Loss: 538734.000 | Test loss: 1448747.250\nIteration: 929200 | Training Loss: 538679.438 | Test loss: 1448631.250\nIteration: 929400 | Training Loss: 538624.875 | Test loss: 1448517.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 929600 | Training Loss: 538570.375 | Test loss: 1448412.000\nIteration: 929800 | Training Loss: 538515.812 | Test loss: 1448299.250\nIteration: 930000 | Training Loss: 538461.375 | Test loss: 1448186.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 930200 | Training Loss: 538406.938 | Test loss: 1448074.875\nIteration: 930400 | Training Loss: 538352.500 | Test loss: 1447961.125\nIteration: 930600 | Training Loss: 538298.062 | Test loss: 1447848.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 930800 | Training Loss: 538243.625 | Test loss: 1447739.750\nIteration: 931000 | Training Loss: 538189.188 | Test loss: 1447626.750\nIteration: 931200 | Training Loss: 538134.875 | Test loss: 1447513.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 931400 | Training Loss: 538080.500 | Test loss: 1447404.625\nIteration: 931600 | Training Loss: 538026.125 | Test loss: 1447294.250\nIteration: 931800 | Training Loss: 537971.812 | Test loss: 1447181.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 932000 | Training Loss: 537917.500 | Test loss: 1447068.625\nIteration: 932200 | Training Loss: 537863.188 | Test loss: 1446961.250\nIteration: 932400 | Training Loss: 537808.938 | Test loss: 1446847.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 932600 | Training Loss: 537754.688 | Test loss: 1446734.750\nIteration: 932800 | Training Loss: 537700.438 | Test loss: 1446623.625\nIteration: 933000 | Training Loss: 537646.250 | Test loss: 1446512.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 933200 | Training Loss: 537592.062 | Test loss: 1446402.750\nIteration: 933400 | Training Loss: 537537.812 | Test loss: 1446291.250\nIteration: 933600 | Training Loss: 537483.688 | Test loss: 1446178.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 933800 | Training Loss: 537429.562 | Test loss: 1446064.875\nIteration: 934000 | Training Loss: 537375.375 | Test loss: 1445954.125\nIteration: 934200 | Training Loss: 537321.250 | Test loss: 1445836.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 934400 | Training Loss: 537267.125 | Test loss: 1445730.375\nIteration: 934600 | Training Loss: 537213.125 | Test loss: 1445622.000\nIteration: 934800 | Training Loss: 537159.062 | Test loss: 1445510.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 935000 | Training Loss: 537105.000 | Test loss: 1445397.750\nIteration: 935200 | Training Loss: 537050.938 | Test loss: 1445286.250\nIteration: 935400 | Training Loss: 536996.938 | Test loss: 1445172.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 935600 | Training Loss: 536942.938 | Test loss: 1445064.625\nIteration: 935800 | Training Loss: 536889.000 | Test loss: 1444953.875\nIteration: 936000 | Training Loss: 536835.062 | Test loss: 1444839.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 936200 | Training Loss: 536781.062 | Test loss: 1444729.750\nIteration: 936400 | Training Loss: 536727.188 | Test loss: 1444618.750\nIteration: 936600 | Training Loss: 536673.250 | Test loss: 1444508.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 936800 | Training Loss: 536619.375 | Test loss: 1444396.125\nIteration: 937000 | Training Loss: 536565.500 | Test loss: 1444283.250\nIteration: 937200 | Training Loss: 536511.688 | Test loss: 1444175.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 937400 | Training Loss: 536457.812 | Test loss: 1444063.125\nIteration: 937600 | Training Loss: 536404.000 | Test loss: 1443956.125\nIteration: 937800 | Training Loss: 536350.188 | Test loss: 1443839.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 938000 | Training Loss: 536296.438 | Test loss: 1443729.000\nIteration: 938200 | Training Loss: 536242.688 | Test loss: 1443612.625\nIteration: 938400 | Training Loss: 536188.938 | Test loss: 1443504.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 938600 | Training Loss: 536135.188 | Test loss: 1443397.375\nIteration: 938800 | Training Loss: 536081.500 | Test loss: 1443284.250\nIteration: 939000 | Training Loss: 536027.812 | Test loss: 1443176.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 939200 | Training Loss: 535974.125 | Test loss: 1443063.375\nIteration: 939400 | Training Loss: 535920.438 | Test loss: 1442960.125\nIteration: 939600 | Training Loss: 535866.812 | Test loss: 1442844.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 939800 | Training Loss: 535813.188 | Test loss: 1442734.250\nIteration: 940000 | Training Loss: 535759.625 | Test loss: 1442623.750\nIteration: 940200 | Training Loss: 535706.000 | Test loss: 1442514.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 940400 | Training Loss: 535652.438 | Test loss: 1442406.875\nIteration: 940600 | Training Loss: 535598.875 | Test loss: 1442291.625\nIteration: 940800 | Training Loss: 535545.312 | Test loss: 1442179.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 941000 | Training Loss: 535491.812 | Test loss: 1442070.000\nIteration: 941200 | Training Loss: 535438.312 | Test loss: 1441957.125\nIteration: 941400 | Training Loss: 535384.812 | Test loss: 1441850.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 941600 | Training Loss: 535331.375 | Test loss: 1441734.250\nIteration: 941800 | Training Loss: 535277.938 | Test loss: 1441627.250\nIteration: 942000 | Training Loss: 535224.500 | Test loss: 1441522.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 942200 | Training Loss: 535171.062 | Test loss: 1441405.375\nIteration: 942400 | Training Loss: 535117.688 | Test loss: 1441291.250\nIteration: 942600 | Training Loss: 535064.312 | Test loss: 1441184.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 942800 | Training Loss: 535010.938 | Test loss: 1441072.750\nIteration: 943000 | Training Loss: 534957.625 | Test loss: 1440962.875\nIteration: 943200 | Training Loss: 534904.312 | Test loss: 1440857.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 943400 | Training Loss: 534850.938 | Test loss: 1440741.375\nIteration: 943600 | Training Loss: 534797.688 | Test loss: 1440631.125\nIteration: 943800 | Training Loss: 534744.375 | Test loss: 1440523.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 944000 | Training Loss: 534691.188 | Test loss: 1440412.875\nIteration: 944200 | Training Loss: 534637.938 | Test loss: 1440303.000\nIteration: 944400 | Training Loss: 534584.688 | Test loss: 1440193.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 944600 | Training Loss: 534531.500 | Test loss: 1440081.750\nIteration: 944800 | Training Loss: 534478.312 | Test loss: 1439973.500\nIteration: 945000 | Training Loss: 534425.125 | Test loss: 1439863.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 945200 | Training Loss: 534372.000 | Test loss: 1439750.500\nIteration: 945400 | Training Loss: 534318.938 | Test loss: 1439642.375\nIteration: 945600 | Training Loss: 534265.750 | Test loss: 1439535.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 945800 | Training Loss: 534212.688 | Test loss: 1439423.250\nIteration: 946000 | Training Loss: 534159.562 | Test loss: 1439314.750\nIteration: 946200 | Training Loss: 534106.562 | Test loss: 1439203.625\nIteration: 946400 | Training Loss: 534053.500 | Test loss: 1439097.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 946600 | Training Loss: 534000.438 | Test loss: 1438982.125\nIteration: 946800 | Training Loss: 533947.500 | Test loss: 1438873.250\nIteration: 947000 | Training Loss: 533894.500 | Test loss: 1438762.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 947200 | Training Loss: 533841.500 | Test loss: 1438653.625\nIteration: 947400 | Training Loss: 533788.562 | Test loss: 1438546.125\nIteration: 947600 | Training Loss: 533735.625 | Test loss: 1438433.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 947800 | Training Loss: 533682.688 | Test loss: 1438323.875\nIteration: 948000 | Training Loss: 533629.812 | Test loss: 1438213.750\nIteration: 948200 | Training Loss: 533576.938 | Test loss: 1438101.125\nIteration: 948400 | Training Loss: 533524.062 | Test loss: 1437992.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 948600 | Training Loss: 533471.250 | Test loss: 1437883.000\nIteration: 948800 | Training Loss: 533418.375 | Test loss: 1437773.125\nIteration: 949000 | Training Loss: 533365.562 | Test loss: 1437666.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 949200 | Training Loss: 533312.750 | Test loss: 1437552.625\nIteration: 949400 | Training Loss: 533260.000 | Test loss: 1437445.000\nIteration: 949600 | Training Loss: 533207.250 | Test loss: 1437337.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 949800 | Training Loss: 533154.500 | Test loss: 1437223.500\nIteration: 950000 | Training Loss: 533101.750 | Test loss: 1437113.250\nIteration: 950200 | Training Loss: 533049.062 | Test loss: 1437005.000\nIteration: 950400 | Training Loss: 532996.375 | Test loss: 1436897.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 950600 | Training Loss: 532943.688 | Test loss: 1436786.875\nIteration: 950800 | Training Loss: 532891.062 | Test loss: 1436682.750\nIteration: 951000 | Training Loss: 532838.438 | Test loss: 1436570.000\nIteration: 951200 | Training Loss: 532785.812 | Test loss: 1436459.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 951400 | Training Loss: 532733.188 | Test loss: 1436347.250\nIteration: 951600 | Training Loss: 532680.625 | Test loss: 1436239.750\nIteration: 951800 | Training Loss: 532628.000 | Test loss: 1436131.125\nIteration: 952000 | Training Loss: 532575.500 | Test loss: 1436015.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 952200 | Training Loss: 532523.000 | Test loss: 1435909.625\nIteration: 952400 | Training Loss: 532470.438 | Test loss: 1435799.250\nIteration: 952600 | Training Loss: 532417.938 | Test loss: 1435689.000\nIteration: 952800 | Training Loss: 532365.500 | Test loss: 1435581.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 953000 | Training Loss: 532313.000 | Test loss: 1435473.875\nIteration: 953200 | Training Loss: 532260.625 | Test loss: 1435362.250\nIteration: 953400 | Training Loss: 532208.188 | Test loss: 1435255.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 953600 | Training Loss: 532155.812 | Test loss: 1435141.750\nIteration: 953800 | Training Loss: 532103.375 | Test loss: 1435037.000\nIteration: 954000 | Training Loss: 532051.000 | Test loss: 1434922.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 954200 | Training Loss: 531998.688 | Test loss: 1434818.625\nIteration: 954400 | Training Loss: 531946.312 | Test loss: 1434709.750\nIteration: 954600 | Training Loss: 531894.000 | Test loss: 1434596.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 954800 | Training Loss: 531841.688 | Test loss: 1434488.000\nIteration: 955000 | Training Loss: 531789.438 | Test loss: 1434382.250\nIteration: 955200 | Training Loss: 531737.125 | Test loss: 1434271.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 955400 | Training Loss: 531684.938 | Test loss: 1434162.375\nIteration: 955600 | Training Loss: 531632.688 | Test loss: 1434054.875\nIteration: 955800 | Training Loss: 531580.500 | Test loss: 1433943.375\nIteration: 956000 | Training Loss: 531528.312 | Test loss: 1433837.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 956200 | Training Loss: 531476.125 | Test loss: 1433726.375\nIteration: 956400 | Training Loss: 531423.938 | Test loss: 1433613.125\nIteration: 956600 | Training Loss: 531371.812 | Test loss: 1433507.875\nIteration: 956800 | Training Loss: 531319.688 | Test loss: 1433398.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 957000 | Training Loss: 531267.625 | Test loss: 1433291.625\nIteration: 957200 | Training Loss: 531215.500 | Test loss: 1433182.625\nIteration: 957400 | Training Loss: 531163.438 | Test loss: 1433074.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 957600 | Training Loss: 531111.375 | Test loss: 1432962.625\nIteration: 957800 | Training Loss: 531059.375 | Test loss: 1432855.500\nIteration: 958000 | Training Loss: 531007.312 | Test loss: 1432748.000\nIteration: 958200 | Training Loss: 530955.375 | Test loss: 1432640.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 958400 | Training Loss: 530903.375 | Test loss: 1432525.750\nIteration: 958600 | Training Loss: 530851.375 | Test loss: 1432421.625\nIteration: 958800 | Training Loss: 530799.438 | Test loss: 1432315.875\nIteration: 959000 | Training Loss: 530747.500 | Test loss: 1432201.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 959200 | Training Loss: 530695.625 | Test loss: 1432094.375\nIteration: 959400 | Training Loss: 530643.750 | Test loss: 1431987.125\nIteration: 959600 | Training Loss: 530591.812 | Test loss: 1431878.750\nIteration: 959800 | Training Loss: 530540.000 | Test loss: 1431767.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 960000 | Training Loss: 530488.188 | Test loss: 1431659.875\nIteration: 960200 | Training Loss: 530436.312 | Test loss: 1431549.000\nIteration: 960400 | Training Loss: 530384.500 | Test loss: 1431442.250\nIteration: 960600 | Training Loss: 530332.750 | Test loss: 1431333.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 960800 | Training Loss: 530281.000 | Test loss: 1431223.500\nIteration: 961000 | Training Loss: 530229.250 | Test loss: 1431116.375\nIteration: 961200 | Training Loss: 530177.500 | Test loss: 1431010.625\nIteration: 961400 | Training Loss: 530125.812 | Test loss: 1430899.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 961600 | Training Loss: 530074.125 | Test loss: 1430791.500\nIteration: 961800 | Training Loss: 530022.438 | Test loss: 1430681.125\nIteration: 962000 | Training Loss: 529970.812 | Test loss: 1430571.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 962200 | Training Loss: 529919.125 | Test loss: 1430466.375\nIteration: 962400 | Training Loss: 529867.438 | Test loss: 1430355.500\nIteration: 962600 | Training Loss: 529815.875 | Test loss: 1430250.125\nIteration: 962800 | Training Loss: 529764.250 | Test loss: 1430134.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 963000 | Training Loss: 529712.750 | Test loss: 1430034.500\nIteration: 963200 | Training Loss: 529661.125 | Test loss: 1429923.500\nIteration: 963400 | Training Loss: 529609.625 | Test loss: 1429818.375\nIteration: 963600 | Training Loss: 529558.062 | Test loss: 1429707.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 963800 | Training Loss: 529506.625 | Test loss: 1429603.875\nIteration: 964000 | Training Loss: 529455.125 | Test loss: 1429490.375\nIteration: 964200 | Training Loss: 529403.688 | Test loss: 1429382.500\nIteration: 964400 | Training Loss: 529352.250 | Test loss: 1429276.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 964600 | Training Loss: 529300.812 | Test loss: 1429164.125\nIteration: 964800 | Training Loss: 529249.375 | Test loss: 1429055.000\nIteration: 965000 | Training Loss: 529198.000 | Test loss: 1428954.500\nIteration: 965200 | Training Loss: 529146.625 | Test loss: 1428843.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 965400 | Training Loss: 529095.250 | Test loss: 1428735.875\nIteration: 965600 | Training Loss: 529043.875 | Test loss: 1428623.250\nIteration: 965800 | Training Loss: 528992.562 | Test loss: 1428519.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 966000 | Training Loss: 528941.312 | Test loss: 1428410.000\nIteration: 966200 | Training Loss: 528890.000 | Test loss: 1428305.000\nIteration: 966400 | Training Loss: 528838.688 | Test loss: 1428193.000\nIteration: 966600 | Training Loss: 528787.438 | Test loss: 1428088.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 966800 | Training Loss: 528736.250 | Test loss: 1427979.250\nIteration: 967000 | Training Loss: 528685.000 | Test loss: 1427871.000\nIteration: 967200 | Training Loss: 528633.875 | Test loss: 1427765.625\nIteration: 967400 | Training Loss: 528582.625 | Test loss: 1427657.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 967600 | Training Loss: 528531.500 | Test loss: 1427547.625\nIteration: 967800 | Training Loss: 528480.312 | Test loss: 1427441.250\nIteration: 968000 | Training Loss: 528429.188 | Test loss: 1427331.500\nIteration: 968200 | Training Loss: 528378.062 | Test loss: 1427223.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 968400 | Training Loss: 528327.000 | Test loss: 1427125.625\nIteration: 968600 | Training Loss: 528275.875 | Test loss: 1427011.500\nIteration: 968800 | Training Loss: 528224.812 | Test loss: 1426897.875\nIteration: 969000 | Training Loss: 528173.812 | Test loss: 1426795.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 969200 | Training Loss: 528122.812 | Test loss: 1426685.250\nIteration: 969400 | Training Loss: 528071.812 | Test loss: 1426576.750\nIteration: 969600 | Training Loss: 528020.812 | Test loss: 1426469.625\nIteration: 969800 | Training Loss: 527969.875 | Test loss: 1426364.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 970000 | Training Loss: 527918.875 | Test loss: 1426254.750\nIteration: 970200 | Training Loss: 527868.000 | Test loss: 1426148.750\nIteration: 970400 | Training Loss: 527817.062 | Test loss: 1426041.500\nIteration: 970600 | Training Loss: 527766.188 | Test loss: 1425935.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 970800 | Training Loss: 527715.312 | Test loss: 1425826.875\nIteration: 971000 | Training Loss: 527664.438 | Test loss: 1425720.750\nIteration: 971200 | Training Loss: 527613.562 | Test loss: 1425611.625\nIteration: 971400 | Training Loss: 527562.750 | Test loss: 1425503.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 971600 | Training Loss: 527511.938 | Test loss: 1425397.000\nIteration: 971800 | Training Loss: 527461.125 | Test loss: 1425285.000\nIteration: 972000 | Training Loss: 527410.375 | Test loss: 1425180.500\nIteration: 972200 | Training Loss: 527359.625 | Test loss: 1425073.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 972400 | Training Loss: 527308.938 | Test loss: 1424968.375\nIteration: 972600 | Training Loss: 527258.188 | Test loss: 1424857.875\nIteration: 972800 | Training Loss: 527207.500 | Test loss: 1424753.875\nIteration: 973000 | Training Loss: 527156.812 | Test loss: 1424645.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 973200 | Training Loss: 527106.125 | Test loss: 1424534.875\nIteration: 973400 | Training Loss: 527055.438 | Test loss: 1424431.000\nIteration: 973600 | Training Loss: 527004.875 | Test loss: 1424321.250\nIteration: 973800 | Training Loss: 526954.250 | Test loss: 1424213.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 974000 | Training Loss: 526903.625 | Test loss: 1424103.750\nIteration: 974200 | Training Loss: 526853.062 | Test loss: 1424000.500\nIteration: 974400 | Training Loss: 526802.562 | Test loss: 1423887.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 974600 | Training Loss: 526752.000 | Test loss: 1423788.125\nIteration: 974800 | Training Loss: 526701.500 | Test loss: 1423680.375\nIteration: 975000 | Training Loss: 526650.938 | Test loss: 1423569.125\nIteration: 975200 | Training Loss: 526600.438 | Test loss: 1423466.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 975400 | Training Loss: 526550.000 | Test loss: 1423360.250\nIteration: 975600 | Training Loss: 526499.500 | Test loss: 1423252.625\nIteration: 975800 | Training Loss: 526449.125 | Test loss: 1423147.000\nIteration: 976000 | Training Loss: 526398.688 | Test loss: 1423040.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 976200 | Training Loss: 526348.312 | Test loss: 1422939.375\nIteration: 976400 | Training Loss: 526297.875 | Test loss: 1422828.000\nIteration: 976600 | Training Loss: 526247.562 | Test loss: 1422711.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 976800 | Training Loss: 526197.188 | Test loss: 1422612.375\nIteration: 977000 | Training Loss: 526146.875 | Test loss: 1422502.500\nIteration: 977200 | Training Loss: 526096.562 | Test loss: 1422398.000\nIteration: 977400 | Training Loss: 526046.312 | Test loss: 1422293.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 977600 | Training Loss: 525996.000 | Test loss: 1422184.500\nIteration: 977800 | Training Loss: 525945.750 | Test loss: 1422075.125\nIteration: 978000 | Training Loss: 525895.562 | Test loss: 1421969.875\nIteration: 978200 | Training Loss: 525845.312 | Test loss: 1421860.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 978400 | Training Loss: 525795.125 | Test loss: 1421758.125\nIteration: 978600 | Training Loss: 525744.938 | Test loss: 1421653.125\nIteration: 978800 | Training Loss: 525694.750 | Test loss: 1421544.625\nIteration: 979000 | Training Loss: 525644.562 | Test loss: 1421435.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 979200 | Training Loss: 525594.500 | Test loss: 1421330.250\nIteration: 979400 | Training Loss: 525544.375 | Test loss: 1421227.000\nIteration: 979600 | Training Loss: 525494.250 | Test loss: 1421116.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 979800 | Training Loss: 525444.188 | Test loss: 1421010.875\nIteration: 980000 | Training Loss: 525394.125 | Test loss: 1420904.750\nIteration: 980200 | Training Loss: 525344.125 | Test loss: 1420802.750\nIteration: 980400 | Training Loss: 525294.062 | Test loss: 1420694.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 980600 | Training Loss: 525244.062 | Test loss: 1420583.750\nIteration: 980800 | Training Loss: 525194.062 | Test loss: 1420478.750\nIteration: 981000 | Training Loss: 525144.125 | Test loss: 1420378.750\nIteration: 981200 | Training Loss: 525094.188 | Test loss: 1420266.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 981400 | Training Loss: 525044.188 | Test loss: 1420160.000\nIteration: 981600 | Training Loss: 524994.375 | Test loss: 1420056.375\nIteration: 981800 | Training Loss: 524944.375 | Test loss: 1419948.125\nIteration: 982000 | Training Loss: 524894.562 | Test loss: 1419840.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 982200 | Training Loss: 524844.688 | Test loss: 1419733.250\nIteration: 982400 | Training Loss: 524794.812 | Test loss: 1419628.750\nIteration: 982600 | Training Loss: 524745.000 | Test loss: 1419524.875\nIteration: 982800 | Training Loss: 524695.250 | Test loss: 1419415.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 983000 | Training Loss: 524645.438 | Test loss: 1419310.125\nIteration: 983200 | Training Loss: 524595.688 | Test loss: 1419200.875\nIteration: 983400 | Training Loss: 524545.875 | Test loss: 1419099.250\nIteration: 983600 | Training Loss: 524496.125 | Test loss: 1418989.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 983800 | Training Loss: 524446.438 | Test loss: 1418886.375\nIteration: 984000 | Training Loss: 524396.750 | Test loss: 1418780.625\nIteration: 984200 | Training Loss: 524347.062 | Test loss: 1418672.125\nIteration: 984400 | Training Loss: 524297.375 | Test loss: 1418566.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 984600 | Training Loss: 524247.750 | Test loss: 1418460.375\nIteration: 984800 | Training Loss: 524198.125 | Test loss: 1418355.375\nIteration: 985000 | Training Loss: 524148.500 | Test loss: 1418248.250\nIteration: 985200 | Training Loss: 524098.938 | Test loss: 1418144.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 985400 | Training Loss: 524049.375 | Test loss: 1418037.250\nIteration: 985600 | Training Loss: 523999.781 | Test loss: 1417925.875\nIteration: 985800 | Training Loss: 523950.281 | Test loss: 1417827.625\nIteration: 986000 | Training Loss: 523900.750 | Test loss: 1417713.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 986200 | Training Loss: 523851.250 | Test loss: 1417612.875\nIteration: 986400 | Training Loss: 523801.750 | Test loss: 1417512.750\nIteration: 986600 | Training Loss: 523752.281 | Test loss: 1417399.625\nIteration: 986800 | Training Loss: 523702.844 | Test loss: 1417291.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 987000 | Training Loss: 523653.438 | Test loss: 1417188.625\nIteration: 987200 | Training Loss: 523604.031 | Test loss: 1417079.750\nIteration: 987400 | Training Loss: 523554.625 | Test loss: 1416978.500\nIteration: 987600 | Training Loss: 523505.281 | Test loss: 1416870.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 987800 | Training Loss: 523455.844 | Test loss: 1416765.625\nIteration: 988000 | Training Loss: 523406.531 | Test loss: 1416661.000\nIteration: 988200 | Training Loss: 523357.219 | Test loss: 1416555.000\nIteration: 988400 | Training Loss: 523307.906 | Test loss: 1416451.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 988600 | Training Loss: 523258.656 | Test loss: 1416345.250\nIteration: 988800 | Training Loss: 523209.375 | Test loss: 1416237.500\nIteration: 989000 | Training Loss: 523160.156 | Test loss: 1416134.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 989200 | Training Loss: 523110.875 | Test loss: 1416026.500\nIteration: 989400 | Training Loss: 523061.656 | Test loss: 1415925.875\nIteration: 989600 | Training Loss: 523012.469 | Test loss: 1415815.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 989800 | Training Loss: 522963.312 | Test loss: 1415714.250\nIteration: 990000 | Training Loss: 522914.156 | Test loss: 1415611.125\nIteration: 990200 | Training Loss: 522865.000 | Test loss: 1415495.875\nIteration: 990400 | Training Loss: 522815.844 | Test loss: 1415394.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 990600 | Training Loss: 522766.781 | Test loss: 1415292.000\nIteration: 990800 | Training Loss: 522717.750 | Test loss: 1415182.250\nIteration: 991000 | Training Loss: 522668.625 | Test loss: 1415082.125\nIteration: 991200 | Training Loss: 522619.625 | Test loss: 1414974.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 991400 | Training Loss: 522570.562 | Test loss: 1414861.000\nIteration: 991600 | Training Loss: 522521.562 | Test loss: 1414763.875\nIteration: 991800 | Training Loss: 522472.594 | Test loss: 1414657.125\nIteration: 992000 | Training Loss: 522423.594 | Test loss: 1414549.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 992200 | Training Loss: 522374.594 | Test loss: 1414451.250\nIteration: 992400 | Training Loss: 522325.688 | Test loss: 1414338.500\nIteration: 992600 | Training Loss: 522276.750 | Test loss: 1414238.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 992800 | Training Loss: 522227.844 | Test loss: 1414133.625\nIteration: 993000 | Training Loss: 522178.938 | Test loss: 1414026.625\nIteration: 993200 | Training Loss: 522130.094 | Test loss: 1413921.625\nIteration: 993400 | Training Loss: 522081.219 | Test loss: 1413817.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 993600 | Training Loss: 522032.375 | Test loss: 1413709.000\nIteration: 993800 | Training Loss: 521983.594 | Test loss: 1413607.875\nIteration: 994000 | Training Loss: 521934.781 | Test loss: 1413501.625\nIteration: 994200 | Training Loss: 521886.000 | Test loss: 1413396.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 994400 | Training Loss: 521837.250 | Test loss: 1413293.750\nIteration: 994600 | Training Loss: 521788.500 | Test loss: 1413186.125\nIteration: 994800 | Training Loss: 521739.750 | Test loss: 1413081.250\nIteration: 995000 | Training Loss: 521691.031 | Test loss: 1412981.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 995200 | Training Loss: 521642.312 | Test loss: 1412873.875\nIteration: 995400 | Training Loss: 521593.625 | Test loss: 1412766.375\nIteration: 995600 | Training Loss: 521544.938 | Test loss: 1412662.125\nIteration: 995800 | Training Loss: 521496.312 | Test loss: 1412557.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 996000 | Training Loss: 521447.656 | Test loss: 1412451.375\nIteration: 996200 | Training Loss: 521399.031 | Test loss: 1412351.625\nIteration: 996400 | Training Loss: 521350.438 | Test loss: 1412240.750\nIteration: 996600 | Training Loss: 521301.875 | Test loss: 1412140.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 996800 | Training Loss: 521253.281 | Test loss: 1412034.000\nIteration: 997000 | Training Loss: 521204.750 | Test loss: 1411929.125\nIteration: 997200 | Training Loss: 521156.250 | Test loss: 1411822.500\nIteration: 997400 | Training Loss: 521107.719 | Test loss: 1411718.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 997600 | Training Loss: 521059.219 | Test loss: 1411613.375\nIteration: 997800 | Training Loss: 521010.750 | Test loss: 1411512.000\nIteration: 998000 | Training Loss: 520962.344 | Test loss: 1411403.375\nIteration: 998200 | Training Loss: 520913.938 | Test loss: 1411298.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 998400 | Training Loss: 520865.531 | Test loss: 1411198.250\nIteration: 998600 | Training Loss: 520817.156 | Test loss: 1411095.750\nIteration: 998800 | Training Loss: 520768.812 | Test loss: 1410987.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 999000 | Training Loss: 520720.500 | Test loss: 1410884.625\nIteration: 999200 | Training Loss: 520672.188 | Test loss: 1410777.750\nIteration: 999400 | Training Loss: 520623.875 | Test loss: 1410670.875\nIteration: 999600 | Training Loss: 520575.594 | Test loss: 1410572.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 999800 | Training Loss: 520527.344 | Test loss: 1410463.625\nIteration: 1000000 | Training Loss: 520479.094 | Test loss: 1410356.000\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "\n",
    "train_loss_list = []\n",
    "test_loss_list = []\n",
    "\n",
    "num_batch_updates = 1000000\n",
    "for i in range(num_batch_updates):\n",
    "    \n",
    "    y_train_pred = model(X_train)\n",
    "    loss = criterion(y_train_pred, y_train)\n",
    "    \n",
    "    train_loss = loss.item()\n",
    "    test_loss = criterion(model(X_test), y_test).item()\n",
    "    \n",
    "    train_loss_list.append(train_loss)\n",
    "    test_loss_list.append(test_loss)\n",
    "    \n",
    "    if (i + 1) % 200 == 0:\n",
    "        print(f'Iteration: {i + 1:>05d} | Training Loss: {train_loss:.3f} | Test loss: {test_loss:.3f}')\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(1, figsize=(10,  6))\n",
    "plt.plot(train_loss_list, c='b', label='train loss')\n",
    "plt.plot(test_loss_list, c='r', label='test_loss')\n",
    "plt.legend(loc='best')\n",
    "plt.ylim(0, 3000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x142eb3f60>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = model(X_test)\n",
    "y_pred = y_pred.detach().numpy()\n",
    " \n",
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(np.array(y_test))\n",
    "plt.plot(y_pred)\n",
    "plt.legend([\"Label\", \"Predicted\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}