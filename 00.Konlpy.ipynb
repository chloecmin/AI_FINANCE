{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POS Tagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 형태소(Morpheme)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Smallest independent unit in any natural language<br>\n",
    "- 의미를 가진 최소단위(the most basic unit of meaning)이며, 더 쪼개면 의미를 잃어버리는 단위<br>\n",
    "  '길동'과 같은 단어는 '길'과 '동'으로 쪼갤 경우 본래 의미를 손실-> '길동'은 형태소<br>\n",
    "- morphemes = stems(어근) + affixes(접사)<br>\n",
    "- 뜻을 가진 최소단위<br>\n",
    "  \n",
    "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 형태소(Morpheme) 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 형태소 분석(POS-tagging)이란 원시말뭉치를 형태소 단위로 쪼개고 각 형태소에 품사 정보를 부착하는 작업"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. POS Tagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- KoNLPy 는 Python에서 한국어 텍스트의 전처리를 할 수 있도록 토크나이징 / 품사 태깅 / 명사 추출을 하는 Packages입니다.\n",
    "- 트위터 형태소 분석기, 한나눔, 꼬꼬마, 코모란, 한국어-매캅 등 다양한 종류의 공개된 한국어 형태소 분석기들이 KoNLPy에 들어있습니다. <br>\n",
    "  각 형태소 분석기마다 구현된 언어가 다릅니다. 특히 자바로 구현된 형태소 분석기들을 사용하기 위해서 JPype1을 먼저 설치하여야 합니다.\n",
    "- <b>꼬꼬마</b>는 세종품사태그(https://goo.gl/hwS12b) 에 가장 가깝고 분석 범주 또한 가장 많습니다. \n",
    "- <b>트위터</b>는 꼬꼬마 대비 분석 범주가 다소 적은 편이지만 이모티콘이나 해쉬태그 같은 인터넷 텍스트에 특화된 범주가 추가된 점이 눈에 띕니다. \n",
    "- <b>코모란</b>은 분석 범주 개수로는 꼬꼬마와 트위터 중간에 위치하고, 개발자 분께서 지속적으로 업데이트를 해주시고 계신 점이 강점이라고 할 수 있겠습니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 빠른 분석이 중요할 때 : 트위터\n",
    "- 정확한 품사 정보가 필요할 때 : 꼬꼬마\n",
    "- 정확성, 시간 모두 중요할 때 : 코모란"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\"><img src=\"img/029_text_ml_pos_taggers.png\" alt=\"Drawing\" style=\"width: 650px; height: 400px; align:center\"/></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Kkma, Twitter, Hannanum\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "taggers = [('kkma', Kkma()), ('twitter', Twitter()), ('hannanum', Hannanum())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- twitter가 이름이 Okt로 변경되었음을 확인 할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tagger name = kkma      \tclass_name = <class 'konlpy.tag._kkma.Kkma'>\n",
      "tagger name = twitter   \tclass_name = <class 'konlpy.tag._okt.Okt'>\n",
      "tagger name = hannanum  \tclass_name = <class 'konlpy.tag._hannanum.Hannanum'>\n"
     ]
    }
   ],
   "source": [
    "for name, tagger in taggers:\n",
    "    print('tagger name = {:10}\\tclass_name = {}'.format(name, tagger.__class__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos_tagger name = hannanum\n",
      "[('이', 'N'),\n",
      " ('이', 'J'),\n",
      " ('건', 'E'),\n",
      " ('테스트', 'N'),\n",
      " ('문장', 'N'),\n",
      " ('이', 'J'),\n",
      " ('ㅂ니다', 'E')]\n",
      "CPU times: user 26.3 ms, sys: 98.5 ms, total: 125 ms\n",
      "Wall time: 244 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print('pos_tagger name = %s' % taggers[2][0])\n",
    "pprint(taggers[2][1].pos('이건 테스트 문장입니다'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "패키지마다 품사표가 좀 다릅니다. 각 품사표를 확인하고 싶다면 [KoNLPy][konlpy_page]의 [품사 태그 비교표][tag_table]를 보셔도 좋고, 아래와 같이 각 형태소 분석기의 태그셋을 확인하셔도 좋습니다\n",
    "\n",
    "[konlpy_page]: http://konlpy.org/ko/v0.4.4/morph/\n",
    "[tag_table]: https://docs.google.com/spreadsheets/d/1OGAjUvalBuX-oZvZ_-9tEfYD2gQe7hTGsgUpiiBSXI8/edit#gid=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos_tagger name = twitter\n",
      "{'EC': '연결 어미',\n",
      " 'ECD': '의존적 연결 어미',\n",
      " 'ECE': '대등 연결 어미',\n",
      " 'ECS': '보조적 연결 어미',\n",
      " 'EF': '종결 어미',\n",
      " 'EFA': '청유형 종결 어미',\n",
      " 'EFI': '감탄형 종결 어미',\n",
      " 'EFN': '평서형 종결 어미',\n",
      " 'EFO': '명령형 종결 어미',\n",
      " 'EFQ': '의문형 종결 어미',\n",
      " 'EFR': '존칭형 종결 어미',\n",
      " 'EP': '선어말 어미',\n",
      " 'EPH': '존칭 선어말 어미',\n",
      " 'EPP': '공손 선어말 어미',\n",
      " 'EPT': '시제 선어말 어미',\n",
      " 'ET': '전성 어미',\n",
      " 'ETD': '관형형 전성 어미',\n",
      " 'ETN': '명사형 전성 어미',\n",
      " 'IC': '감탄사',\n",
      " 'JC': '접속 조사',\n",
      " 'JK': '조사',\n",
      " 'JKC': '보격 조사',\n",
      " 'JKG': '관형격 조사',\n",
      " 'JKI': '호격 조사',\n",
      " 'JKM': '부사격 조사',\n",
      " 'JKO': '목적격 조사',\n",
      " 'JKQ': '인용격 조사',\n",
      " 'JKS': '주격 조사',\n",
      " 'JX': '보조사',\n",
      " 'MA': '부사',\n",
      " 'MAC': '접속 부사',\n",
      " 'MAG': '일반 부사',\n",
      " 'MD': '관형사',\n",
      " 'MDN': '수 관형사',\n",
      " 'MDT': '일반 관형사',\n",
      " 'NN': '명사',\n",
      " 'NNB': '일반 의존 명사',\n",
      " 'NNG': '보통명사',\n",
      " 'NNM': '단위 의존 명사',\n",
      " 'NNP': '고유명사',\n",
      " 'NP': '대명사',\n",
      " 'NR': '수사',\n",
      " 'OH': '한자',\n",
      " 'OL': '외국어',\n",
      " 'ON': '숫자',\n",
      " 'SE': '줄임표',\n",
      " 'SF': '마침표, 물음표, 느낌표',\n",
      " 'SO': '붙임표(물결,숨김,빠짐)',\n",
      " 'SP': '쉼표,가운뎃점,콜론,빗금',\n",
      " 'SS': '따옴표,괄호표,줄표',\n",
      " 'SW': '기타기호 (논리수학기호,화폐기호)',\n",
      " 'UN': '명사추정범주',\n",
      " 'VA': '형용사',\n",
      " 'VC': '지정사',\n",
      " 'VCN': \"부정 지정사, 형용사 '아니다'\",\n",
      " 'VCP': \"긍정 지정사, 서술격 조사 '이다'\",\n",
      " 'VV': '동사',\n",
      " 'VX': '보조 용언',\n",
      " 'VXA': '보조 형용사',\n",
      " 'VXV': '보조 동사',\n",
      " 'XP': '접두사',\n",
      " 'XPN': '체언 접두사',\n",
      " 'XPV': '용언 접두사',\n",
      " 'XR': '어근',\n",
      " 'XSA': '형용사 파생 접미사',\n",
      " 'XSN': '명사파생 접미사',\n",
      " 'XSV': '동사 파생 접미사'}\n"
     ]
    }
   ],
   "source": [
    "print('pos_tagger name = %s' % taggers[1][0])\n",
    "pprint(taggers[0][1].tagset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos_tagger name = hannanum\n",
      "{'EC': '연결 어미',\n",
      " 'ECD': '의존적 연결 어미',\n",
      " 'ECE': '대등 연결 어미',\n",
      " 'ECS': '보조적 연결 어미',\n",
      " 'EF': '종결 어미',\n",
      " 'EFA': '청유형 종결 어미',\n",
      " 'EFI': '감탄형 종결 어미',\n",
      " 'EFN': '평서형 종결 어미',\n",
      " 'EFO': '명령형 종결 어미',\n",
      " 'EFQ': '의문형 종결 어미',\n",
      " 'EFR': '존칭형 종결 어미',\n",
      " 'EP': '선어말 어미',\n",
      " 'EPH': '존칭 선어말 어미',\n",
      " 'EPP': '공손 선어말 어미',\n",
      " 'EPT': '시제 선어말 어미',\n",
      " 'ET': '전성 어미',\n",
      " 'ETD': '관형형 전성 어미',\n",
      " 'ETN': '명사형 전성 어미',\n",
      " 'IC': '감탄사',\n",
      " 'JC': '접속 조사',\n",
      " 'JK': '조사',\n",
      " 'JKC': '보격 조사',\n",
      " 'JKG': '관형격 조사',\n",
      " 'JKI': '호격 조사',\n",
      " 'JKM': '부사격 조사',\n",
      " 'JKO': '목적격 조사',\n",
      " 'JKQ': '인용격 조사',\n",
      " 'JKS': '주격 조사',\n",
      " 'JX': '보조사',\n",
      " 'MA': '부사',\n",
      " 'MAC': '접속 부사',\n",
      " 'MAG': '일반 부사',\n",
      " 'MD': '관형사',\n",
      " 'MDN': '수 관형사',\n",
      " 'MDT': '일반 관형사',\n",
      " 'NN': '명사',\n",
      " 'NNB': '일반 의존 명사',\n",
      " 'NNG': '보통명사',\n",
      " 'NNM': '단위 의존 명사',\n",
      " 'NNP': '고유명사',\n",
      " 'NP': '대명사',\n",
      " 'NR': '수사',\n",
      " 'OH': '한자',\n",
      " 'OL': '외국어',\n",
      " 'ON': '숫자',\n",
      " 'SE': '줄임표',\n",
      " 'SF': '마침표, 물음표, 느낌표',\n",
      " 'SO': '붙임표(물결,숨김,빠짐)',\n",
      " 'SP': '쉼표,가운뎃점,콜론,빗금',\n",
      " 'SS': '따옴표,괄호표,줄표',\n",
      " 'SW': '기타기호 (논리수학기호,화폐기호)',\n",
      " 'UN': '명사추정범주',\n",
      " 'VA': '형용사',\n",
      " 'VC': '지정사',\n",
      " 'VCN': \"부정 지정사, 형용사 '아니다'\",\n",
      " 'VCP': \"긍정 지정사, 서술격 조사 '이다'\",\n",
      " 'VV': '동사',\n",
      " 'VX': '보조 용언',\n",
      " 'VXA': '보조 형용사',\n",
      " 'VXV': '보조 동사',\n",
      " 'XP': '접두사',\n",
      " 'XPN': '체언 접두사',\n",
      " 'XPV': '용언 접두사',\n",
      " 'XR': '어근',\n",
      " 'XSA': '형용사 파생 접미사',\n",
      " 'XSN': '명사파생 접미사',\n",
      " 'XSV': '동사 파생 접미사'}\n"
     ]
    }
   ],
   "source": [
    "print('pos_tagger name = %s' % taggers[2][0])\n",
    "pprint(taggers[0][1].tagset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = [\n",
    "'마이크로소프트(MS) 윈도우7 보안 업데이트 중단이 코 앞으로 다가왔지만, 아직도 많은 PC가 윈도우7으로 구동되고 있다. 때문에 이전에 겪었던 윈도우XP 보안 업데이트 중단에 따른 보안 대란이 한 차례 더 재현될 전망이다',\n",
    "'MS는 내년 2020년 1월 14일 윈도우7을 위한 보안 업데이트 지원을 중단한다. 약 300일 정도 남았다. 업데이트 지원이 중단되어도 윈도우7을 사용할 순 있지만, 이후 새로 발견된 보안 취약점으로 악성코드가 침입하는 것을 감수해야 한다.',\n",
    "'원래 MS는 운영체제에서 보안 취약점이 발견되면 해당 취약점으로 악성코드가 침투하지 못하도록 관련 보안 업데이트/패치를 제공했다. 하지만 내년 1월 14일 이후로는 이들 업데이트가 더 이상 제공되지 않는다. 최신 바이러스, 악성코드, 랜섬웨어 공격에 PC가 무방비로 노출되는 셈이다.',\n",
    "'윈도우7의 높은 보급율이 문제다. 국내 PC 10대 가운데 3대는 여전히 윈도우7이 깔려 있다. 보안면에서 상대적으로 안전한 최신 운영체제인 윈도우10은 10대 중 2대에 불과하다. 내년이면 국민 10명 가운데 7명이 온갖 보안위협에 직면하게 된다.',\n",
    "'특히 악성코드가 PC에 침입하면 심각한 피해를 야기할 수 있는 공공기관이나 의료시설, 공장 등에 윈도우7 탑재 PC가 상당히 많다. 윈도우 라이선스나 소프트웨어 호환성 문제 등으로, 당장 윈도우7에서 벗어나지 못하는 실정이기 때문이다.',\n",
    "'MS는 오는 4월부터 윈도우7 관련 보안 지원이 곧 종료된다는 공지를 사용자의 PC에 팝업 창으로 띄울 계획이다. 사용자들에게 경각심을 심어주기 위해서다. 윈도우7 보급율이 높아 내려진 결정이다.',\n",
    "'윈도우7 PC는 윈도우10 PC로 업그레이드해야 한다.윈도우7 PC는 윈도우10 PC로 업그레이드해야 한다. ',\n",
    "'보안 위협을 피하는 가장 확실한 방법은 역시, 운영체제를 최신 버전인 윈도우10으로 업그레이드하는 것이다. MS는 처음 윈도우10이 출시됐을 때 홍보 차원에서 무료 업그레이드 서비스를 제공한 바있다. 현재 무료 업그레이드 서비스는 종료됐고, 재개할 계획은 없다. 따라서 윈도우10을 이용하려면 MS 스토어나 온라인 마켓에서 윈도우10 정품을 구매해야 한다. 물론 소프트웨어 호환성도 이제는 적극 대응해야 할 때다.',\n",
    "'MS 관계자는 \"윈도우10은 최신 운영체제임에도 윈도우7보다 가볍고 빠르다. 보안성도 훨씬 우수하고 호환성 문제 등도 모두 해결되었다\"며, \"남은 1년 기간 동안 윈도우7 PC를 윈도우10 PC로 업그레이드해, 보안 위협으로부터 PC와 파일, 데이터, 자신 등을 지키기를 적극 권장한다\"고 말했다.'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tagger name = kkma, 8.36 secs\n",
      "tagger name = twitter, 2.33 secs\n",
      "tagger name = hannanum, 0.218 secs\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "tokens = []\n",
    "\n",
    "for name, tagger in taggers:\n",
    "    \n",
    "    process_time = time.time()    \n",
    "    tokens.append([pos for sent in sents for pos in tagger.pos(sent)])    \n",
    "    process_time = time.time() - process_time # POS Tagger당 Processing Time\n",
    "    \n",
    "    print('tagger name = {}, {:.3} secs'.format(name, process_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 아래 token분리된 내용을 보면 마이크로소프트가 '마이크로'와 '소프트'로 분리된 것을 확인 할 수 있습니다. 이는 형태소 분석기(Kkma)가 학습할때 '마이크로소프트가' 없었기 때문입니다.\n",
    "- 이를 out of vocabulary problem라 하여, 알려지지 않은 단어를 제대로 인식하지 못하는 문제입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('마이크로', 'NNG'), ('소프트', 'NNG'), ('(', 'SS'), ('MS', 'OL'), (')', 'SS'), ('윈도우', 'NNG'), ('7', 'NR'), ('보', 'NNB'), ('안', 'NNG'), ('업데이트', 'NNG'), ('중단', 'NNG'), ('이', 'JKS'), ('코', 'NNG'), ('앞', 'NNG'), ('으로', 'JKM'), ('다가오', 'VV'), ('았', 'EPT'), ('지만', 'ECE'), (',', 'SP'), ('아직', 'MAG'), ('도', 'JX'), ('많', 'VA'), ('은', 'ETD'), ('PC', 'OL'), ('가', 'JKS'), ('윈도우', 'NNG'), ('7', 'NR'), ('으로', 'JKM'), ('구동', 'NNP'), ('되', 'XSV')] ...  635 tokens\n"
     ]
    }
   ],
   "source": [
    "print(tokens[0][:30], '... ', '{} tokens'.format(len(tokens[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 각 단어의 출현 회수를 카운팅 하는 방법은 다음과 같은 방법이 있습니다.<br>\n",
    "  (1) dict를 이용하는 방법<br>\n",
    "  (2) defaultdict을 이용하는 방법<br>\n",
    "  (3) collections.Counter를 이용하는 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- token 내용을 확인 합니다.<br>\n",
    "- 데이터가 word, 품사(POS) 순으로 저장되어 있음을 확인할 수 있습니다.(Kkma로 POS처리된 50개 데이터만 확인 합니다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('마이크로', 'NNG'), ('소프트', 'NNG'), ('(', 'SS'), ('MS', 'OL'), (')', 'SS'), ('윈도우', 'NNG'), ('7', 'NR'), ('보', 'NNB'), ('안', 'NNG'), ('업데이트', 'NNG'), ('중단', 'NNG'), ('이', 'JKS'), ('코', 'NNG'), ('앞', 'NNG'), ('으로', 'JKM'), ('다가오', 'VV'), ('았', 'EPT'), ('지만', 'ECE'), (',', 'SP'), ('아직', 'MAG'), ('도', 'JX'), ('많', 'VA'), ('은', 'ETD'), ('PC', 'OL'), ('가', 'JKS'), ('윈도우', 'NNG'), ('7', 'NR'), ('으로', 'JKM'), ('구동', 'NNP'), ('되', 'XSV'), ('고', 'ECE'), ('있', 'VXV'), ('다', 'EFN'), ('.', 'SF'), ('때문', 'NNB'), ('에', 'JKM'), ('이전', 'NNG'), ('에', 'JKM'), ('겪', 'VV'), ('었', 'EPT'), ('더', 'EPT'), ('ㄴ', 'ETD'), ('윈도우', 'NNG'), ('XP', 'OL'), ('보안', 'NNG'), ('업데이트', 'NNG'), ('중단', 'NNG'), ('에', 'JKM'), ('따르', 'VV'), ('ㄴ', 'ETD')]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "print(tokens[0][:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- counter는 dict이므로 keys(), values, items()를 가집니다. <br>\n",
    "- 이 때 items()의 return은 [(key, value), (key, value), ...] 형태<br>\n",
    "- 정렬 대상 (key, value)를 x로 볼 때, x의 1번째 값 x[1]을 기준으로 정렬하라는 의미이며, 순서는 1, 2, 3, ..의 오름차순이 아닌 역순으로 하라는 의미"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('윈도우', 'NNG'), 20),\n",
      " (('보안', 'NNG'), 9),\n",
      " (('업데이트', 'NNG'), 6),\n",
      " (('업그레이드', 'NNG'), 6),\n",
      " (('윈도', 'NNG'), 5),\n",
      " (('우', 'NNG'), 5),\n",
      " (('중단', 'NNG'), 4),\n",
      " (('악성', 'NNG'), 4),\n",
      " (('코드', 'NNG'), 4),\n",
      " (('운영', 'NNG'), 4),\n",
      " (('체제', 'NNG'), 4),\n",
      " (('최신', 'NNG'), 4),\n",
      " (('대', 'NNM'), 4)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from pprint import pprint\n",
    "\n",
    "# Kkma Tokenizer\n",
    "counter = Counter(tokens[0]) \n",
    "# word = (word, POS), freq = frequency\n",
    "counter = {word:freq for word, freq in counter.items() if (freq>=4) and (word[1][:2] == 'NN')} \n",
    "\n",
    "# frequency를 가지고 sorting를 하게 됩니다.\n",
    "pprint(sorted(counter.items(), key=lambda x:x[1], reverse=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 전체 POS Tagger를 통해서 POS 분석을 한 결과를 출력합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Part of speech tagger: kkma\n",
      "[(('윈도우', 'NNG'), 20),\n",
      " (('7', 'NR'), 15),\n",
      " (('10', 'NR'), 12),\n",
      " (('보안', 'NNG'), 9),\n",
      " (('업데이트', 'NNG'), 6),\n",
      " (('업그레이드', 'NNG'), 6),\n",
      " (('윈도', 'NNG'), 5),\n",
      " (('우', 'NNG'), 5),\n",
      " (('중단', 'NNG'), 4),\n",
      " (('악성', 'NNG'), 4),\n",
      " (('코드', 'NNG'), 4),\n",
      " (('운영', 'NNG'), 4),\n",
      " (('체제', 'NNG'), 4),\n",
      " (('최신', 'NNG'), 4),\n",
      " (('대', 'NNM'), 4)]\n",
      "\n",
      "\n",
      "Part of speech tagger: twitter\n",
      "[(('윈도우', 'Noun'), 25),\n",
      " (('7', 'Number'), 15),\n",
      " (('보안', 'Noun'), 12),\n",
      " (('10', 'Number'), 12),\n",
      " (('업데이트', 'Noun'), 6),\n",
      " (('업그레이드', 'Noun'), 6),\n",
      " (('중단', 'Noun'), 4),\n",
      " (('악성코드', 'Noun'), 4),\n",
      " (('운영체제', 'Noun'), 4),\n",
      " (('최신', 'Noun'), 4),\n",
      " (('등', 'Noun'), 4)]\n",
      "\n",
      "\n",
      "Part of speech tagger: hannanum\n",
      "[(('윈도우7', 'N'), 14),\n",
      " (('보안', 'N'), 10),\n",
      " (('윈도우10', 'N'), 8),\n",
      " (('업데이트', 'N'), 5),\n",
      " (('중단', 'N'), 4),\n",
      " (('악성코드', 'N'), 4),\n",
      " (('운영체제', 'N'), 4),\n",
      " (('최신', 'N'), 4),\n",
      " (('등', 'N'), 4)]\n"
     ]
    }
   ],
   "source": [
    "for (name, _), _tokens in zip(taggers, tokens):\n",
    "    print('\\n\\nPart of speech tagger: {}'.format(name))\n",
    "    counter = Counter(_tokens)\n",
    "    counter = {word:freq for word, freq in counter.items() if (freq >= 4) and (word[1][:1] == 'N')} # 4회 이상 출현 단어중, POS가 N으로 시작하는\n",
    "    pprint(sorted(counter.items(), key=lambda x:x[1], reverse=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 모든 데이터에 적합한 한국어 형태소 분석기는 '아직'까지는 없습니다. 그리고 한국어로 기술되었다고 하더라도, 차용한 글자만 한글일 뿐, 한국어는 아닌 언어들도 많이 있습니다. 특히 도메인 특수 용어들의 처리는 POS처리에 있어서 어려운 영역에 속합니다.\n",
    "- 주어진 시간 안에 작업이 끝날 수 있는지와 주어진 데이터에 대한 형태소 분석기의 경향, 정성적 품질을 확인하고 사용하여야 합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 기타 POS Tagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 최근에는 딥러닝을 이용하여 품사태깅을 하는 시도들이 있습니다. 얼마전 Kakao의 Khaiii(\"Kakao Hangul Analyzer III\")같은 사례들이 있습니다.\n",
    "&nbsp;https://github.com/kakao/khaiii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
